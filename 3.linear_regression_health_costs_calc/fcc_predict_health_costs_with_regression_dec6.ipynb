{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef165cc0-df7f-4e21-8451-1b1bc187d68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "# from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "00f9044c-1f11-4d9e-f5a4-2986fee3625c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 05:19:06--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv.4’\n",
            "\n",
            "insurance.csv.4     100%[===================>]  49.09K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-12-28 05:19:06 (6.88 MB/s) - ‘insurance.csv.4’ saved [50264/50264]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27a87382-443b-424d-ad43-28e9b6078e00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27a87382-443b-424d-ad43-28e9b6078e00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27a87382-443b-424d-ad43-28e9b6078e00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27a87382-443b-424d-ad43-28e9b6078e00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ebf22cc-4d6d-4a5e-ae05-5e6760911b29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ebf22cc-4d6d-4a5e-ae05-5e6760911b29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ebf22cc-4d6d-4a5e-ae05-5e6760911b29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b3420ceb-6510-4306-8683-8a8da7dd1ad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex   bmi  children smoker     region  expenses\n",
              "0   19  female  27.9         0    yes  southwest  16884.92\n",
              "1   18    male  33.8         1     no  southeast   1725.55\n",
              "2   28    male  33.0         3     no  southeast   4449.46\n",
              "3   33    male  22.7         0     no  northwest  21984.47\n",
              "4   32    male  28.9         0     no  northwest   3866.86"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-098a688f-50b1-4d79-825a-4dc02a12a210\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-098a688f-50b1-4d79-825a-4dc02a12a210')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-098a688f-50b1-4d79-825a-4dc02a12a210 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-098a688f-50b1-4d79-825a-4dc02a12a210');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03176b50-2e26-429c-a302-422d67791e99\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03176b50-2e26-429c-a302-422d67791e99')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03176b50-2e26-429c-a302-422d67791e99 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Avoid repeated and unnecessary importations of the dataset\n",
        "# from fCC's Static Assets.\n",
        "df = dataset.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Any necessity to impute any value?\n",
        "df.isna()\\\n",
        "  .sum()"
      ],
      "metadata": {
        "id": "ANxsGAlEQ-xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb64d6aa-730a-49df-bd97-56b073a9d0ca"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "bmi         0\n",
              "children    0\n",
              "smoker      0\n",
              "region      0\n",
              "expenses    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical values to be parsed as numerical ones\n",
        "categoricals = ['sex',\n",
        "                'smoker',\n",
        "                'region']\n",
        "df = pd.get_dummies(dataset,\n",
        "                    columns = categoricals,\n",
        "                    drop_first = True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IB2o-ili7HMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "41398c3d-5152-4796-c540-eba38351a811"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age   bmi  children  expenses  sex_male  smoker_yes  region_northwest  \\\n",
              "0   19  27.9         0  16884.92         0           1                 0   \n",
              "1   18  33.8         1   1725.55         1           0                 0   \n",
              "2   28  33.0         3   4449.46         1           0                 0   \n",
              "3   33  22.7         0  21984.47         1           0                 1   \n",
              "4   32  28.9         0   3866.86         1           0                 1   \n",
              "\n",
              "   region_southeast  region_southwest  \n",
              "0                 0                 1  \n",
              "1                 1                 0  \n",
              "2                 1                 0  \n",
              "3                 0                 0  \n",
              "4                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cabe5c2c-8992-4f38-a6c1-b1ac7dda6c08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cabe5c2c-8992-4f38-a6c1-b1ac7dda6c08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cabe5c2c-8992-4f38-a6c1-b1ac7dda6c08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cabe5c2c-8992-4f38-a6c1-b1ac7dda6c08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b56a150-5bfb-470c-bfcf-ac89eb6ea853\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b56a150-5bfb-470c-bfcf-ac89eb6ea853')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b56a150-5bfb-470c-bfcf-ac89eb6ea853 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the train dataset, create a random sample which contains 80% of the observations\n",
        "train_dataset = df.sample(frac = .8,\n",
        "                          random_state = 0)\n",
        "\n",
        "# Assign the test dataset\n",
        "test_dataset = df.drop(train_dataset.index)\n",
        "\n",
        "# Pop off the 'expenses' colmuns\n",
        "train_labels = train_dataset.pop('expenses')\n",
        "test_labels = test_dataset.pop('expenses')\n"
      ],
      "metadata": {
        "id": "Yi4E5nn37X60"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add output layers\n",
        "input_shape = len(train_dataset.keys())\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "    layers.Dense(128,\n",
        "                 activation = 'relu',\n",
        "                 input_shape = [input_shape]),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.Dense(16, activation = 'relu'),\n",
        "    layers.Dense(1, activation = 'relu')\n",
        "  ]\n",
        "    )\n",
        "\n",
        "# Compile the model:\n",
        "# Implement an 'Adaptive Moment Estimation' algorithm\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate = .008\n",
        ")\n",
        "\n",
        "model.compile(loss = 'mae',\n",
        "              optimizer = optimizer,\n",
        "              metrics = ['mae','mse'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "vw7IQ9E02at4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166229b3-4621-40d1-e0a5-eeb9bbf5760e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 128)               1152      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16193 (63.25 KB)\n",
            "Trainable params: 16193 (63.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Trian the model\n",
        "# https://keras.io/api/callbacks/model_checkpoint/:\n",
        "\n",
        "EPOCHS = 500\n",
        "checkpoint_filepath = './tmp/ckpt/fcchealthcosts.model.keras'\n",
        "\n",
        "checkpoint_callback  = [tf.keras.callbacks\\\n",
        "                        .ModelCheckpoint(filepath = checkpoint_filepath,\n",
        "                                         monitor = 'val_loss',\n",
        "                                         verbose = 1,\n",
        "                                         save_best_only = True,\n",
        "                                         mode = 'min'\n",
        "                                         )\n",
        "]\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit:\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    train_labels,\n",
        "                    epochs = EPOCHS,\n",
        "                    verbose = 1,\n",
        "                    validation_split = .2,\n",
        "                    shuffle = False,\n",
        "                    callbacks = checkpoint_callback\n",
        ")\n"
      ],
      "metadata": {
        "id": "mxjqcCZ537I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6727a8-8aa0-4d76-d066-2c9dbd8ced81"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1547.2360 - mae: 1547.2360 - mse: 18566160.0000\n",
            "Epoch 1: val_loss improved from inf to 1746.26208, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1632.2297 - mae: 1632.2297 - mse: 20224076.0000 - val_loss: 1746.2621 - val_mae: 1746.2621 - val_mse: 22509900.0000\n",
            "Epoch 2/500\n",
            " 8/27 [=======>......................] - ETA: 0s - loss: 1561.5537 - mae: 1561.5537 - mse: 17442662.0000\n",
            "Epoch 2: val_loss did not improve from 1746.26208\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1569.2274 - mae: 1569.2274 - mse: 19557758.0000 - val_loss: 1766.1056 - val_mae: 1766.1056 - val_mse: 22806028.0000\n",
            "Epoch 3/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1562.3274 - mae: 1562.3274 - mse: 19037714.0000\n",
            "Epoch 3: val_loss did not improve from 1746.26208\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1578.4083 - mae: 1578.4083 - mse: 19953708.0000 - val_loss: 1839.8920 - val_mae: 1839.8920 - val_mse: 23610954.0000\n",
            "Epoch 4/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1472.4641 - mae: 1472.4641 - mse: 18373336.0000\n",
            "Epoch 4: val_loss did not improve from 1746.26208\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1528.4874 - mae: 1528.4874 - mse: 19505562.0000 - val_loss: 1793.5841 - val_mae: 1793.5841 - val_mse: 23572198.0000\n",
            "Epoch 5/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1524.4795 - mae: 1524.4795 - mse: 18742550.0000\n",
            "Epoch 5: val_loss improved from 1746.26208 to 1737.05188, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1547.2096 - mae: 1547.2096 - mse: 19470724.0000 - val_loss: 1737.0519 - val_mae: 1737.0519 - val_mse: 21731348.0000\n",
            "Epoch 6/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1471.2555 - mae: 1471.2555 - mse: 18175988.0000\n",
            "Epoch 6: val_loss did not improve from 1737.05188\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1516.0382 - mae: 1516.0382 - mse: 19197680.0000 - val_loss: 1843.4167 - val_mae: 1843.4167 - val_mse: 22520202.0000\n",
            "Epoch 7/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1510.1440 - mae: 1510.1440 - mse: 18438460.0000\n",
            "Epoch 7: val_loss improved from 1737.05188 to 1714.21631, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1570.6028 - mae: 1570.6028 - mse: 19623458.0000 - val_loss: 1714.2163 - val_mae: 1714.2163 - val_mse: 22306084.0000\n",
            "Epoch 8/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1548.5631 - mae: 1548.5631 - mse: 18751552.0000\n",
            "Epoch 8: val_loss did not improve from 1714.21631\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1563.6360 - mae: 1563.6360 - mse: 19488162.0000 - val_loss: 1720.3324 - val_mae: 1720.3324 - val_mse: 21254050.0000\n",
            "Epoch 9/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 680.4377 - mae: 680.4377 - mse: 5295258.5000\n",
            "Epoch 9: val_loss did not improve from 1714.21631\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1604.4310 - mae: 1604.4310 - mse: 19339120.0000 - val_loss: 1818.6151 - val_mae: 1818.6151 - val_mse: 20330012.0000\n",
            "Epoch 10/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 934.3646 - mae: 934.3646 - mse: 5447416.0000\n",
            "Epoch 10: val_loss did not improve from 1714.21631\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1542.7018 - mae: 1542.7018 - mse: 19202048.0000 - val_loss: 1717.1832 - val_mae: 1717.1832 - val_mse: 22032198.0000\n",
            "Epoch 11/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 602.1674 - mae: 602.1674 - mse: 5187481.0000\n",
            "Epoch 11: val_loss did not improve from 1714.21631\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1520.4380 - mae: 1520.4380 - mse: 19408466.0000 - val_loss: 1742.8896 - val_mae: 1742.8896 - val_mse: 21810448.0000\n",
            "Epoch 12/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 626.6956 - mae: 626.6956 - mse: 5341602.0000\n",
            "Epoch 12: val_loss did not improve from 1714.21631\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1522.8818 - mae: 1522.8818 - mse: 19268728.0000 - val_loss: 1774.8459 - val_mae: 1774.8459 - val_mse: 21631950.0000\n",
            "Epoch 13/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 739.8845 - mae: 739.8845 - mse: 5526521.0000\n",
            "Epoch 13: val_loss improved from 1714.21631 to 1710.71277, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1600.7654 - mae: 1600.7654 - mse: 19415382.0000 - val_loss: 1710.7128 - val_mae: 1710.7128 - val_mse: 21862566.0000\n",
            "Epoch 14/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1447.3925 - mae: 1447.3925 - mse: 18078270.0000\n",
            "Epoch 14: val_loss did not improve from 1710.71277\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1513.0156 - mae: 1513.0156 - mse: 19243904.0000 - val_loss: 1793.4484 - val_mae: 1793.4484 - val_mse: 22201884.0000\n",
            "Epoch 15/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 701.3656 - mae: 701.3656 - mse: 5068835.0000\n",
            "Epoch 15: val_loss did not improve from 1710.71277\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1592.2959 - mae: 1592.2959 - mse: 19629014.0000 - val_loss: 1836.0426 - val_mae: 1836.0426 - val_mse: 21490976.0000\n",
            "Epoch 16/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 738.1020 - mae: 738.1020 - mse: 5207993.0000\n",
            "Epoch 16: val_loss improved from 1710.71277 to 1704.70752, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1493.8098 - mae: 1493.8098 - mse: 19101728.0000 - val_loss: 1704.7075 - val_mae: 1704.7075 - val_mse: 22676140.0000\n",
            "Epoch 17/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 571.5367 - mae: 571.5367 - mse: 5274746.0000\n",
            "Epoch 17: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1530.6409 - mae: 1530.6409 - mse: 19416152.0000 - val_loss: 1791.4943 - val_mae: 1791.4943 - val_mse: 20745728.0000\n",
            "Epoch 18/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 706.1161 - mae: 706.1161 - mse: 5172825.5000\n",
            "Epoch 18: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1532.0034 - mae: 1532.0034 - mse: 19400330.0000 - val_loss: 1771.0724 - val_mae: 1771.0724 - val_mse: 21896220.0000\n",
            "Epoch 19/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 621.1396 - mae: 621.1396 - mse: 4964678.0000\n",
            "Epoch 19: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1519.7051 - mae: 1519.7051 - mse: 19045438.0000 - val_loss: 1806.0371 - val_mae: 1806.0371 - val_mse: 23322116.0000\n",
            "Epoch 20/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 681.7433 - mae: 681.7433 - mse: 5252574.0000\n",
            "Epoch 20: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1512.4309 - mae: 1512.4309 - mse: 19389186.0000 - val_loss: 1734.9822 - val_mae: 1734.9822 - val_mse: 22857058.0000\n",
            "Epoch 21/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 514.0287 - mae: 514.0287 - mse: 5098077.0000\n",
            "Epoch 21: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1473.2428 - mae: 1473.2428 - mse: 19290810.0000 - val_loss: 1777.3322 - val_mae: 1777.3322 - val_mse: 22856754.0000\n",
            "Epoch 22/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 572.2618 - mae: 572.2618 - mse: 5265398.0000\n",
            "Epoch 22: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1514.1050 - mae: 1514.1050 - mse: 19035572.0000 - val_loss: 1744.4232 - val_mae: 1744.4232 - val_mse: 21005176.0000\n",
            "Epoch 23/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 723.0359 - mae: 723.0359 - mse: 5342943.5000\n",
            "Epoch 23: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1466.4940 - mae: 1466.4940 - mse: 19114594.0000 - val_loss: 1808.9495 - val_mae: 1808.9495 - val_mse: 19864852.0000\n",
            "Epoch 24/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 772.7191 - mae: 772.7191 - mse: 4899891.5000\n",
            "Epoch 24: val_loss did not improve from 1704.70752\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1584.8610 - mae: 1584.8610 - mse: 19516018.0000 - val_loss: 1711.6158 - val_mae: 1711.6158 - val_mse: 22241252.0000\n",
            "Epoch 25/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 584.3869 - mae: 584.3869 - mse: 5272439.5000\n",
            "Epoch 25: val_loss improved from 1704.70752 to 1704.30457, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1537.1606 - mae: 1537.1606 - mse: 19507616.0000 - val_loss: 1704.3046 - val_mae: 1704.3046 - val_mse: 21604924.0000\n",
            "Epoch 26/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 578.5936 - mae: 578.5936 - mse: 5243741.5000\n",
            "Epoch 26: val_loss improved from 1704.30457 to 1631.14758, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1473.8168 - mae: 1473.8168 - mse: 19035264.0000 - val_loss: 1631.1476 - val_mae: 1631.1476 - val_mse: 21166146.0000\n",
            "Epoch 27/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 520.0588 - mae: 520.0588 - mse: 5138623.0000\n",
            "Epoch 27: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1477.4688 - mae: 1477.4688 - mse: 19096682.0000 - val_loss: 1648.6180 - val_mae: 1648.6180 - val_mse: 21654872.0000\n",
            "Epoch 28/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 520.7057 - mae: 520.7057 - mse: 5170720.0000\n",
            "Epoch 28: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1495.1073 - mae: 1495.1073 - mse: 19066020.0000 - val_loss: 1675.5015 - val_mae: 1675.5015 - val_mse: 20999312.0000\n",
            "Epoch 29/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 582.0779 - mae: 582.0779 - mse: 5007263.0000\n",
            "Epoch 29: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1465.3773 - mae: 1465.3773 - mse: 18913142.0000 - val_loss: 1764.3112 - val_mae: 1764.3112 - val_mse: 24084110.0000\n",
            "Epoch 30/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 529.4847 - mae: 529.4847 - mse: 5226751.0000\n",
            "Epoch 30: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1499.5211 - mae: 1499.5211 - mse: 19373262.0000 - val_loss: 1758.7942 - val_mae: 1758.7942 - val_mse: 23588288.0000\n",
            "Epoch 31/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 540.9147 - mae: 540.9147 - mse: 5266344.0000\n",
            "Epoch 31: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1571.3832 - mae: 1571.3832 - mse: 19473330.0000 - val_loss: 1738.9050 - val_mae: 1738.9050 - val_mse: 21503950.0000\n",
            "Epoch 32/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 578.2253 - mae: 578.2253 - mse: 5161751.5000\n",
            "Epoch 32: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1491.4152 - mae: 1491.4152 - mse: 19070954.0000 - val_loss: 1800.2922 - val_mae: 1800.2922 - val_mse: 22525732.0000\n",
            "Epoch 33/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 637.5720 - mae: 637.5720 - mse: 5155997.0000\n",
            "Epoch 33: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1520.7856 - mae: 1520.7856 - mse: 19234150.0000 - val_loss: 1890.4757 - val_mae: 1890.4757 - val_mse: 21549800.0000\n",
            "Epoch 34/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 818.0573 - mae: 818.0573 - mse: 5089613.0000\n",
            "Epoch 34: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1559.2297 - mae: 1559.2297 - mse: 19311650.0000 - val_loss: 1798.9824 - val_mae: 1798.9824 - val_mse: 21488338.0000\n",
            "Epoch 35/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 714.1845 - mae: 714.1845 - mse: 5079154.0000\n",
            "Epoch 35: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1584.6464 - mae: 1584.6464 - mse: 19442848.0000 - val_loss: 1684.3185 - val_mae: 1684.3185 - val_mse: 20755002.0000\n",
            "Epoch 36/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 589.8169 - mae: 589.8169 - mse: 5114306.0000\n",
            "Epoch 36: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1518.5657 - mae: 1518.5657 - mse: 19613328.0000 - val_loss: 1638.7664 - val_mae: 1638.7664 - val_mse: 20763626.0000\n",
            "Epoch 37/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 516.6506 - mae: 516.6506 - mse: 5151025.0000\n",
            "Epoch 37: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1499.9305 - mae: 1499.9305 - mse: 19472022.0000 - val_loss: 1762.8762 - val_mae: 1762.8762 - val_mse: 20890844.0000\n",
            "Epoch 38/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 703.9413 - mae: 703.9413 - mse: 5227498.5000\n",
            "Epoch 38: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1521.5054 - mae: 1521.5054 - mse: 19467308.0000 - val_loss: 1631.4552 - val_mae: 1631.4552 - val_mse: 20332580.0000\n",
            "Epoch 39/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 594.1594 - mae: 594.1594 - mse: 5101063.5000\n",
            "Epoch 39: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1491.4509 - mae: 1491.4509 - mse: 19518500.0000 - val_loss: 1719.5188 - val_mae: 1719.5188 - val_mse: 23093838.0000\n",
            "Epoch 40/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 558.4694 - mae: 558.4694 - mse: 5166006.5000\n",
            "Epoch 40: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1519.9976 - mae: 1519.9976 - mse: 19382164.0000 - val_loss: 1701.1809 - val_mae: 1701.1809 - val_mse: 20597106.0000\n",
            "Epoch 41/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 721.1213 - mae: 721.1213 - mse: 5175987.0000\n",
            "Epoch 41: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1652.7872 - mae: 1652.7872 - mse: 19874526.0000 - val_loss: 1822.1653 - val_mae: 1822.1653 - val_mse: 22344568.0000\n",
            "Epoch 42/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 708.0472 - mae: 708.0472 - mse: 5572440.0000\n",
            "Epoch 42: val_loss did not improve from 1631.14758\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1579.2015 - mae: 1579.2015 - mse: 19653458.0000 - val_loss: 1971.4932 - val_mae: 1971.4932 - val_mse: 25379634.0000\n",
            "Epoch 43/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 725.4730 - mae: 725.4730 - mse: 5640315.5000\n",
            "Epoch 43: val_loss improved from 1631.14758 to 1624.89465, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1533.0741 - mae: 1533.0741 - mse: 19892874.0000 - val_loss: 1624.8947 - val_mae: 1624.8947 - val_mse: 20286760.0000\n",
            "Epoch 44/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 601.5411 - mae: 601.5411 - mse: 5026039.5000\n",
            "Epoch 44: val_loss improved from 1624.89465 to 1624.86182, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1483.5768 - mae: 1483.5768 - mse: 19117422.0000 - val_loss: 1624.8618 - val_mae: 1624.8618 - val_mse: 20958082.0000\n",
            "Epoch 45/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 507.3830 - mae: 507.3830 - mse: 5221099.5000\n",
            "Epoch 45: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1508.4613 - mae: 1508.4613 - mse: 19082790.0000 - val_loss: 2214.6050 - val_mae: 2214.6050 - val_mse: 25741670.0000\n",
            "Epoch 46/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 988.5441 - mae: 988.5441 - mse: 6303948.0000\n",
            "Epoch 46: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1444.2744 - mae: 1444.2744 - mse: 19079636.0000 - val_loss: 1700.8474 - val_mae: 1700.8474 - val_mse: 22130886.0000\n",
            "Epoch 47/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 580.4984 - mae: 580.4984 - mse: 5359814.0000\n",
            "Epoch 47: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1454.4058 - mae: 1454.4058 - mse: 19057474.0000 - val_loss: 1814.2665 - val_mae: 1814.2665 - val_mse: 23174252.0000\n",
            "Epoch 48/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 555.2901 - mae: 555.2901 - mse: 5341315.5000\n",
            "Epoch 48: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1550.2285 - mae: 1550.2285 - mse: 19535306.0000 - val_loss: 2169.0789 - val_mae: 2169.0789 - val_mse: 23914674.0000\n",
            "Epoch 49/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 1024.7924 - mae: 1024.7924 - mse: 6257488.5000\n",
            "Epoch 49: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1684.0468 - mae: 1684.0468 - mse: 19538824.0000 - val_loss: 1787.7048 - val_mae: 1787.7048 - val_mse: 22052166.0000\n",
            "Epoch 50/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 696.2130 - mae: 696.2130 - mse: 5620426.5000\n",
            "Epoch 50: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1484.8480 - mae: 1484.8480 - mse: 18976540.0000 - val_loss: 1669.5834 - val_mae: 1669.5834 - val_mse: 21101768.0000\n",
            "Epoch 51/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 544.4742 - mae: 544.4742 - mse: 5096128.5000\n",
            "Epoch 51: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1648.4147 - mae: 1648.4147 - mse: 19508708.0000 - val_loss: 1986.9761 - val_mae: 1986.9761 - val_mse: 22460392.0000\n",
            "Epoch 52/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 878.2945 - mae: 878.2945 - mse: 5951846.0000\n",
            "Epoch 52: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1546.8966 - mae: 1546.8966 - mse: 19108348.0000 - val_loss: 1694.9916 - val_mae: 1694.9916 - val_mse: 20868852.0000\n",
            "Epoch 53/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 650.4153 - mae: 650.4153 - mse: 5149056.0000\n",
            "Epoch 53: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1473.3752 - mae: 1473.3752 - mse: 19025974.0000 - val_loss: 1647.0513 - val_mae: 1647.0513 - val_mse: 21428024.0000\n",
            "Epoch 54/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 579.2615 - mae: 579.2615 - mse: 5252962.0000\n",
            "Epoch 54: val_loss did not improve from 1624.86182\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1471.2655 - mae: 1471.2655 - mse: 18955894.0000 - val_loss: 1796.8118 - val_mae: 1796.8118 - val_mse: 22804624.0000\n",
            "Epoch 55/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 628.9386 - mae: 628.9386 - mse: 5386079.5000\n",
            "Epoch 55: val_loss improved from 1624.86182 to 1601.42456, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1438.3584 - mae: 1438.3584 - mse: 18811954.0000 - val_loss: 1601.4246 - val_mae: 1601.4246 - val_mse: 21353496.0000\n",
            "Epoch 56/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 526.7634 - mae: 526.7634 - mse: 5248643.5000\n",
            "Epoch 56: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1452.2271 - mae: 1452.2271 - mse: 18931960.0000 - val_loss: 1659.0275 - val_mae: 1659.0275 - val_mse: 20733736.0000\n",
            "Epoch 57/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1509.3046 - mae: 1509.3046 - mse: 18600802.0000\n",
            "Epoch 57: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1524.9711 - mae: 1524.9711 - mse: 19093224.0000 - val_loss: 1741.2128 - val_mae: 1741.2128 - val_mse: 23417786.0000\n",
            "Epoch 58/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1453.6133 - mae: 1453.6133 - mse: 18548098.0000\n",
            "Epoch 58: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1486.3673 - mae: 1486.3673 - mse: 19332462.0000 - val_loss: 1682.2047 - val_mae: 1682.2047 - val_mse: 22904322.0000\n",
            "Epoch 59/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1346.3667 - mae: 1346.3667 - mse: 17901858.0000\n",
            "Epoch 59: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1417.3553 - mae: 1417.3553 - mse: 18914216.0000 - val_loss: 1616.4388 - val_mae: 1616.4388 - val_mse: 21596432.0000\n",
            "Epoch 60/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1486.7903 - mae: 1486.7903 - mse: 18037898.0000\n",
            "Epoch 60: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1541.4156 - mae: 1541.4156 - mse: 19143394.0000 - val_loss: 1804.9336 - val_mae: 1804.9336 - val_mse: 23525816.0000\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1496.2041 - mae: 1496.2041 - mse: 19031674.0000\n",
            "Epoch 61: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1496.2041 - mae: 1496.2041 - mse: 19031674.0000 - val_loss: 1689.7671 - val_mae: 1689.7671 - val_mse: 21705726.0000\n",
            "Epoch 62/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1338.2935 - mae: 1338.2935 - mse: 17846482.0000\n",
            "Epoch 62: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1400.1947 - mae: 1400.1947 - mse: 18907528.0000 - val_loss: 1820.2522 - val_mae: 1820.2522 - val_mse: 23886398.0000\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1540.6489 - mae: 1540.6489 - mse: 19226752.0000\n",
            "Epoch 63: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1540.6489 - mae: 1540.6489 - mse: 19226752.0000 - val_loss: 1709.0769 - val_mae: 1709.0769 - val_mse: 22500716.0000\n",
            "Epoch 64/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1472.3740 - mae: 1472.3740 - mse: 18249310.0000\n",
            "Epoch 64: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1518.5724 - mae: 1518.5724 - mse: 19262314.0000 - val_loss: 1660.6294 - val_mae: 1660.6294 - val_mse: 21668904.0000\n",
            "Epoch 65/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1475.5488 - mae: 1475.5488 - mse: 18255328.0000\n",
            "Epoch 65: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1514.2250 - mae: 1514.2250 - mse: 19299928.0000 - val_loss: 1910.7612 - val_mae: 1910.7612 - val_mse: 24964110.0000\n",
            "Epoch 66/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1485.1759 - mae: 1485.1759 - mse: 17855108.0000\n",
            "Epoch 66: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1533.1818 - mae: 1533.1818 - mse: 18947032.0000 - val_loss: 1738.5990 - val_mae: 1738.5990 - val_mse: 23517440.0000\n",
            "Epoch 67/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 560.5528 - mae: 560.5528 - mse: 5060507.0000\n",
            "Epoch 67: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1466.3364 - mae: 1466.3364 - mse: 18907408.0000 - val_loss: 1857.5704 - val_mae: 1857.5704 - val_mse: 22541516.0000\n",
            "Epoch 68/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1450.2386 - mae: 1450.2386 - mse: 17897402.0000\n",
            "Epoch 68: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1497.0739 - mae: 1497.0739 - mse: 19041710.0000 - val_loss: 1697.5255 - val_mae: 1697.5255 - val_mse: 21895298.0000\n",
            "Epoch 69/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 574.1320 - mae: 574.1320 - mse: 5120271.0000\n",
            "Epoch 69: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1443.2606 - mae: 1443.2606 - mse: 18898660.0000 - val_loss: 1688.1049 - val_mae: 1688.1049 - val_mse: 22116606.0000\n",
            "Epoch 70/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1459.6310 - mae: 1459.6310 - mse: 18911218.0000\n",
            "Epoch 70: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1476.6123 - mae: 1476.6123 - mse: 19403848.0000 - val_loss: 1792.5664 - val_mae: 1792.5664 - val_mse: 23529682.0000\n",
            "Epoch 71/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 625.7043 - mae: 625.7043 - mse: 5388516.0000\n",
            "Epoch 71: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1422.8163 - mae: 1422.8163 - mse: 18908932.0000 - val_loss: 1675.2834 - val_mae: 1675.2834 - val_mse: 21917210.0000\n",
            "Epoch 72/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 539.1401 - mae: 539.1401 - mse: 5257973.5000\n",
            "Epoch 72: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1487.7773 - mae: 1487.7773 - mse: 19104282.0000 - val_loss: 1768.4752 - val_mae: 1768.4752 - val_mse: 21715592.0000\n",
            "Epoch 73/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1496.3701 - mae: 1496.3701 - mse: 18149424.0000\n",
            "Epoch 73: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1551.3845 - mae: 1551.3845 - mse: 19241096.0000 - val_loss: 2072.3245 - val_mae: 2072.3245 - val_mse: 24020046.0000\n",
            "Epoch 74/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 918.4954 - mae: 918.4954 - mse: 6190557.0000\n",
            "Epoch 74: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1471.7373 - mae: 1471.7373 - mse: 18930756.0000 - val_loss: 1669.1897 - val_mae: 1669.1897 - val_mse: 22089970.0000\n",
            "Epoch 75/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1556.8042 - mae: 1556.8042 - mse: 19472680.0000\n",
            "Epoch 75: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1577.0833 - mae: 1577.0833 - mse: 19971002.0000 - val_loss: 1752.8807 - val_mae: 1752.8807 - val_mse: 22715294.0000\n",
            "Epoch 76/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 647.7668 - mae: 647.7668 - mse: 5438748.5000\n",
            "Epoch 76: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1545.0836 - mae: 1545.0836 - mse: 19456220.0000 - val_loss: 1742.2075 - val_mae: 1742.2075 - val_mse: 23543708.0000\n",
            "Epoch 77/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 505.7638 - mae: 505.7638 - mse: 5184765.0000\n",
            "Epoch 77: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1427.8375 - mae: 1427.8375 - mse: 18957248.0000 - val_loss: 1697.2535 - val_mae: 1697.2535 - val_mse: 22903518.0000\n",
            "Epoch 78/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 491.5527 - mae: 491.5527 - mse: 5078636.5000\n",
            "Epoch 78: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1492.6099 - mae: 1492.6099 - mse: 19195308.0000 - val_loss: 1820.8138 - val_mae: 1820.8138 - val_mse: 24715484.0000\n",
            "Epoch 79/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1381.3311 - mae: 1381.3311 - mse: 17911118.0000\n",
            "Epoch 79: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1427.1318 - mae: 1427.1318 - mse: 19013514.0000 - val_loss: 1778.5519 - val_mae: 1778.5519 - val_mse: 24422118.0000\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1533.5818 - mae: 1533.5818 - mse: 19624800.0000\n",
            "Epoch 80: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1533.5818 - mae: 1533.5818 - mse: 19624800.0000 - val_loss: 1714.7461 - val_mae: 1714.7461 - val_mse: 21561086.0000\n",
            "Epoch 81/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1414.9313 - mae: 1414.9313 - mse: 17885240.0000\n",
            "Epoch 81: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1500.2544 - mae: 1500.2544 - mse: 19504466.0000 - val_loss: 1715.4187 - val_mae: 1715.4187 - val_mse: 22811906.0000\n",
            "Epoch 82/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1365.6089 - mae: 1365.6089 - mse: 17341800.0000\n",
            "Epoch 82: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1473.9708 - mae: 1473.9708 - mse: 19168746.0000 - val_loss: 1670.7368 - val_mae: 1670.7368 - val_mse: 21525512.0000\n",
            "Epoch 83/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1312.8171 - mae: 1312.8171 - mse: 17262234.0000\n",
            "Epoch 83: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1404.7128 - mae: 1404.7128 - mse: 18936108.0000 - val_loss: 1719.2041 - val_mae: 1719.2041 - val_mse: 23593620.0000\n",
            "Epoch 84/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1377.7719 - mae: 1377.7719 - mse: 17607956.0000\n",
            "Epoch 84: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1483.4211 - mae: 1483.4211 - mse: 19365882.0000 - val_loss: 1751.0657 - val_mae: 1751.0657 - val_mse: 21958462.0000\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1441.1310 - mae: 1441.1310 - mse: 19020518.0000\n",
            "Epoch 85: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1441.1310 - mae: 1441.1310 - mse: 19020518.0000 - val_loss: 1639.8110 - val_mae: 1639.8110 - val_mse: 22118892.0000\n",
            "Epoch 86/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 495.3330 - mae: 495.3330 - mse: 5127430.0000\n",
            "Epoch 86: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1398.8472 - mae: 1398.8472 - mse: 18825720.0000 - val_loss: 1641.7379 - val_mae: 1641.7379 - val_mse: 21832192.0000\n",
            "Epoch 87/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 487.3978 - mae: 487.3978 - mse: 5143676.0000\n",
            "Epoch 87: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1421.3274 - mae: 1421.3274 - mse: 18763858.0000 - val_loss: 1652.3511 - val_mae: 1652.3511 - val_mse: 22224824.0000\n",
            "Epoch 88/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1338.5536 - mae: 1338.5536 - mse: 17846180.0000\n",
            "Epoch 88: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1395.0663 - mae: 1395.0663 - mse: 18940894.0000 - val_loss: 1692.4396 - val_mae: 1692.4396 - val_mse: 22619730.0000\n",
            "Epoch 89/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 519.2849 - mae: 519.2849 - mse: 5188482.0000\n",
            "Epoch 89: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1403.2484 - mae: 1403.2484 - mse: 19015714.0000 - val_loss: 1691.9995 - val_mae: 1691.9995 - val_mse: 22455330.0000\n",
            "Epoch 90/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1254.7419 - mae: 1254.7419 - mse: 15859131.0000\n",
            "Epoch 90: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1412.0854 - mae: 1412.0854 - mse: 18914194.0000 - val_loss: 1709.5653 - val_mae: 1709.5653 - val_mse: 22656314.0000\n",
            "Epoch 91/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1413.2701 - mae: 1413.2701 - mse: 16770037.0000\n",
            "Epoch 91: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1494.2512 - mae: 1494.2512 - mse: 18969252.0000 - val_loss: 1773.1102 - val_mae: 1773.1102 - val_mse: 22433792.0000\n",
            "Epoch 92/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1462.6871 - mae: 1462.6871 - mse: 18289542.0000\n",
            "Epoch 92: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1501.0304 - mae: 1501.0304 - mse: 19344612.0000 - val_loss: 1725.7573 - val_mae: 1725.7573 - val_mse: 22845358.0000\n",
            "Epoch 93/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 539.7341 - mae: 539.7341 - mse: 5101137.5000\n",
            "Epoch 93: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1432.2676 - mae: 1432.2676 - mse: 19224206.0000 - val_loss: 1950.8484 - val_mae: 1950.8484 - val_mse: 24058656.0000\n",
            "Epoch 94/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 738.0700 - mae: 738.0700 - mse: 5608505.0000\n",
            "Epoch 94: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1500.2246 - mae: 1500.2246 - mse: 19045218.0000 - val_loss: 1742.4886 - val_mae: 1742.4886 - val_mse: 22594296.0000\n",
            "Epoch 95/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 556.2859 - mae: 556.2859 - mse: 5026676.5000\n",
            "Epoch 95: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1477.7427 - mae: 1477.7427 - mse: 19021670.0000 - val_loss: 1761.0508 - val_mae: 1761.0508 - val_mse: 23176480.0000\n",
            "Epoch 96/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 552.1030 - mae: 552.1030 - mse: 5201380.0000\n",
            "Epoch 96: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1519.3416 - mae: 1519.3416 - mse: 18843974.0000 - val_loss: 1741.9514 - val_mae: 1741.9514 - val_mse: 22365450.0000\n",
            "Epoch 97/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 571.2542 - mae: 571.2542 - mse: 5093832.5000\n",
            "Epoch 97: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1472.2648 - mae: 1472.2648 - mse: 18847988.0000 - val_loss: 1709.8595 - val_mae: 1709.8595 - val_mse: 23211052.0000\n",
            "Epoch 98/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 521.2240 - mae: 521.2240 - mse: 5060398.0000\n",
            "Epoch 98: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1437.0094 - mae: 1437.0094 - mse: 18987688.0000 - val_loss: 1771.3365 - val_mae: 1771.3365 - val_mse: 22590760.0000\n",
            "Epoch 99/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 582.0784 - mae: 582.0784 - mse: 4937853.0000\n",
            "Epoch 99: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1445.7153 - mae: 1445.7153 - mse: 18916692.0000 - val_loss: 1756.9419 - val_mae: 1756.9419 - val_mse: 23205230.0000\n",
            "Epoch 100/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 565.6157 - mae: 565.6157 - mse: 5034629.5000\n",
            "Epoch 100: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1611.3958 - mae: 1611.3958 - mse: 19333644.0000 - val_loss: 1877.9724 - val_mae: 1877.9724 - val_mse: 22305476.0000\n",
            "Epoch 101/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 840.1776 - mae: 840.1776 - mse: 5883930.0000\n",
            "Epoch 101: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1539.7621 - mae: 1539.7621 - mse: 19728286.0000 - val_loss: 1649.1288 - val_mae: 1649.1288 - val_mse: 21344352.0000\n",
            "Epoch 102/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 513.8669 - mae: 513.8669 - mse: 5183893.0000\n",
            "Epoch 102: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1459.2786 - mae: 1459.2786 - mse: 19067270.0000 - val_loss: 1621.5505 - val_mae: 1621.5505 - val_mse: 21577242.0000\n",
            "Epoch 103/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 523.4535 - mae: 523.4535 - mse: 5191603.0000\n",
            "Epoch 103: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1418.2059 - mae: 1418.2059 - mse: 19101878.0000 - val_loss: 1637.2977 - val_mae: 1637.2977 - val_mse: 21995376.0000\n",
            "Epoch 104/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 544.5815 - mae: 544.5815 - mse: 5206532.5000\n",
            "Epoch 104: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1401.0317 - mae: 1401.0317 - mse: 18961386.0000 - val_loss: 1738.9382 - val_mae: 1738.9382 - val_mse: 24159026.0000\n",
            "Epoch 105/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 503.7526 - mae: 503.7526 - mse: 5236823.5000\n",
            "Epoch 105: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1458.8574 - mae: 1458.8574 - mse: 19017924.0000 - val_loss: 1929.1191 - val_mae: 1929.1191 - val_mse: 24532744.0000\n",
            "Epoch 106/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 727.5972 - mae: 727.5972 - mse: 5683782.5000\n",
            "Epoch 106: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1478.3616 - mae: 1478.3616 - mse: 18981264.0000 - val_loss: 1703.1136 - val_mae: 1703.1136 - val_mse: 22420440.0000\n",
            "Epoch 107/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 574.6400 - mae: 574.6400 - mse: 5100201.5000\n",
            "Epoch 107: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1457.2275 - mae: 1457.2275 - mse: 18801340.0000 - val_loss: 2041.3251 - val_mae: 2041.3251 - val_mse: 21751500.0000\n",
            "Epoch 108/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1530.2073 - mae: 1530.2073 - mse: 18597022.0000\n",
            "Epoch 108: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1545.7018 - mae: 1545.7018 - mse: 19093952.0000 - val_loss: 1616.2452 - val_mae: 1616.2452 - val_mse: 21067616.0000\n",
            "Epoch 109/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 607.8621 - mae: 607.8621 - mse: 5375032.0000\n",
            "Epoch 109: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1433.0403 - mae: 1433.0402 - mse: 19053280.0000 - val_loss: 1741.2147 - val_mae: 1741.2147 - val_mse: 21784486.0000\n",
            "Epoch 110/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 697.5746 - mae: 697.5746 - mse: 5584803.5000\n",
            "Epoch 110: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1477.0237 - mae: 1477.0237 - mse: 19464666.0000 - val_loss: 1625.5310 - val_mae: 1625.5310 - val_mse: 21445450.0000\n",
            "Epoch 111/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 657.7044 - mae: 657.7044 - mse: 5419928.5000\n",
            "Epoch 111: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1426.3804 - mae: 1426.3804 - mse: 19076832.0000 - val_loss: 1693.1095 - val_mae: 1693.1095 - val_mse: 22969766.0000\n",
            "Epoch 112/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 545.2609 - mae: 545.2609 - mse: 5270524.5000\n",
            "Epoch 112: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1424.1206 - mae: 1424.1206 - mse: 19011360.0000 - val_loss: 1735.7394 - val_mae: 1735.7394 - val_mse: 22279684.0000\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1376.4219 - mae: 1376.4219 - mse: 18842608.0000\n",
            "Epoch 113: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1376.4219 - mae: 1376.4219 - mse: 18842608.0000 - val_loss: 1644.2023 - val_mae: 1644.2023 - val_mse: 21708832.0000\n",
            "Epoch 114/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 549.3342 - mae: 549.3342 - mse: 5048325.5000\n",
            "Epoch 114: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1381.6758 - mae: 1381.6758 - mse: 18912916.0000 - val_loss: 1768.2683 - val_mae: 1768.2683 - val_mse: 23340778.0000\n",
            "Epoch 115/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 586.8110 - mae: 586.8110 - mse: 5219036.5000\n",
            "Epoch 115: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1413.3195 - mae: 1413.3195 - mse: 18871188.0000 - val_loss: 1925.6136 - val_mae: 1925.6136 - val_mse: 23926216.0000\n",
            "Epoch 116/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 696.1728 - mae: 696.1728 - mse: 5564142.5000\n",
            "Epoch 116: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1440.4835 - mae: 1440.4835 - mse: 18901622.0000 - val_loss: 1759.0862 - val_mae: 1759.0862 - val_mse: 24328848.0000\n",
            "Epoch 117/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 503.1822 - mae: 503.1822 - mse: 5034868.5000\n",
            "Epoch 117: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1442.3779 - mae: 1442.3779 - mse: 18973360.0000 - val_loss: 1765.4226 - val_mae: 1765.4226 - val_mse: 23144154.0000\n",
            "Epoch 118/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 596.1714 - mae: 596.1714 - mse: 5420625.0000\n",
            "Epoch 118: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1508.6624 - mae: 1508.6624 - mse: 19274396.0000 - val_loss: 1738.4287 - val_mae: 1738.4287 - val_mse: 22098892.0000\n",
            "Epoch 119/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 653.4512 - mae: 653.4512 - mse: 5356340.5000\n",
            "Epoch 119: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1614.8004 - mae: 1614.8004 - mse: 20511464.0000 - val_loss: 1962.2056 - val_mae: 1962.2056 - val_mse: 24536528.0000\n",
            "Epoch 120/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1513.2777 - mae: 1513.2777 - mse: 18666538.0000\n",
            "Epoch 120: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1566.5522 - mae: 1566.5522 - mse: 19697610.0000 - val_loss: 1861.0709 - val_mae: 1861.0709 - val_mse: 23035270.0000\n",
            "Epoch 121/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 760.5378 - mae: 760.5378 - mse: 6068145.5000\n",
            "Epoch 121: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1473.7113 - mae: 1473.7113 - mse: 19090966.0000 - val_loss: 1673.8021 - val_mae: 1673.8021 - val_mse: 21787710.0000\n",
            "Epoch 122/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 598.1655 - mae: 598.1655 - mse: 5114564.0000\n",
            "Epoch 122: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1478.2618 - mae: 1478.2618 - mse: 18968388.0000 - val_loss: 2043.0314 - val_mae: 2043.0312 - val_mse: 26650294.0000\n",
            "Epoch 123/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 861.5341 - mae: 861.5341 - mse: 6060185.5000\n",
            "Epoch 123: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1491.0272 - mae: 1491.0273 - mse: 19032162.0000 - val_loss: 1772.5931 - val_mae: 1772.5931 - val_mse: 23910656.0000\n",
            "Epoch 124/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 588.0259 - mae: 588.0259 - mse: 5198276.0000\n",
            "Epoch 124: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1467.3521 - mae: 1467.3521 - mse: 19001390.0000 - val_loss: 1711.7402 - val_mae: 1711.7402 - val_mse: 22364022.0000\n",
            "Epoch 125/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 597.1870 - mae: 597.1870 - mse: 5331697.0000\n",
            "Epoch 125: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1410.8513 - mae: 1410.8513 - mse: 18913344.0000 - val_loss: 1749.5300 - val_mae: 1749.5300 - val_mse: 23270838.0000\n",
            "Epoch 126/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 552.7097 - mae: 552.7097 - mse: 5262898.5000\n",
            "Epoch 126: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1376.2211 - mae: 1376.2211 - mse: 18974068.0000 - val_loss: 1781.2196 - val_mae: 1781.2196 - val_mse: 22922876.0000\n",
            "Epoch 127/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1321.5006 - mae: 1321.5006 - mse: 17538654.0000\n",
            "Epoch 127: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1377.6055 - mae: 1377.6055 - mse: 18652442.0000 - val_loss: 1823.4902 - val_mae: 1823.4902 - val_mse: 23743630.0000\n",
            "Epoch 128/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 567.8160 - mae: 567.8160 - mse: 5362380.5000\n",
            "Epoch 128: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1437.6387 - mae: 1437.6387 - mse: 18955436.0000 - val_loss: 1803.4695 - val_mae: 1803.4695 - val_mse: 23725340.0000\n",
            "Epoch 129/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 582.7731 - mae: 582.7731 - mse: 5170625.5000\n",
            "Epoch 129: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1505.1680 - mae: 1505.1678 - mse: 19086432.0000 - val_loss: 1816.7045 - val_mae: 1816.7045 - val_mse: 23826432.0000\n",
            "Epoch 130/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 626.1648 - mae: 626.1648 - mse: 5416078.0000\n",
            "Epoch 130: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1504.9756 - mae: 1504.9756 - mse: 19239286.0000 - val_loss: 1895.4434 - val_mae: 1895.4434 - val_mse: 23838728.0000\n",
            "Epoch 131/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1417.5582 - mae: 1417.5582 - mse: 17785990.0000\n",
            "Epoch 131: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1461.3872 - mae: 1461.3872 - mse: 18884364.0000 - val_loss: 1745.9960 - val_mae: 1745.9960 - val_mse: 22997402.0000\n",
            "Epoch 132/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 587.4246 - mae: 587.4246 - mse: 5046586.0000\n",
            "Epoch 132: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1390.5469 - mae: 1390.5469 - mse: 18908862.0000 - val_loss: 1746.3967 - val_mae: 1746.3967 - val_mse: 23205400.0000\n",
            "Epoch 133/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 566.5613 - mae: 566.5613 - mse: 5413106.0000\n",
            "Epoch 133: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1466.3363 - mae: 1466.3363 - mse: 18895782.0000 - val_loss: 1905.8966 - val_mae: 1905.8966 - val_mse: 24466936.0000\n",
            "Epoch 134/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 618.6355 - mae: 618.6355 - mse: 5399861.5000\n",
            "Epoch 134: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1408.0243 - mae: 1408.0243 - mse: 18735002.0000 - val_loss: 1606.8785 - val_mae: 1606.8785 - val_mse: 21872808.0000\n",
            "Epoch 135/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 525.6918 - mae: 525.6918 - mse: 5097350.0000\n",
            "Epoch 135: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1431.2761 - mae: 1431.2761 - mse: 18817046.0000 - val_loss: 1875.0110 - val_mae: 1875.0110 - val_mse: 23359562.0000\n",
            "Epoch 136/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 742.7935 - mae: 742.7935 - mse: 5794922.0000\n",
            "Epoch 136: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1411.7979 - mae: 1411.7979 - mse: 18793284.0000 - val_loss: 1764.0798 - val_mae: 1764.0798 - val_mse: 23192772.0000\n",
            "Epoch 137/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 586.1844 - mae: 586.1844 - mse: 5407208.0000\n",
            "Epoch 137: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1437.1152 - mae: 1437.1152 - mse: 18744254.0000 - val_loss: 1739.6465 - val_mae: 1739.6465 - val_mse: 23123984.0000\n",
            "Epoch 138/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 554.7507 - mae: 554.7507 - mse: 5067612.5000\n",
            "Epoch 138: val_loss did not improve from 1601.42456\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1419.9203 - mae: 1419.9203 - mse: 18635350.0000 - val_loss: 1667.5759 - val_mae: 1667.5759 - val_mse: 22436646.0000\n",
            "Epoch 139/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 513.0941 - mae: 513.0941 - mse: 5190992.0000\n",
            "Epoch 139: val_loss improved from 1601.42456 to 1567.46057, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1359.3586 - mae: 1359.3586 - mse: 18909376.0000 - val_loss: 1567.4606 - val_mae: 1567.4606 - val_mse: 21609774.0000\n",
            "Epoch 140/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 460.1329 - mae: 460.1329 - mse: 5141040.5000\n",
            "Epoch 140: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1399.2477 - mae: 1399.2477 - mse: 18692918.0000 - val_loss: 1687.2434 - val_mae: 1687.2434 - val_mse: 22693196.0000\n",
            "Epoch 141/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 541.1664 - mae: 541.1664 - mse: 5114201.0000\n",
            "Epoch 141: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1504.0996 - mae: 1504.0996 - mse: 19057952.0000 - val_loss: 1667.2566 - val_mae: 1667.2566 - val_mse: 22156458.0000\n",
            "Epoch 142/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1380.2365 - mae: 1380.2365 - mse: 17906118.0000\n",
            "Epoch 142: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1442.4880 - mae: 1442.4880 - mse: 18978438.0000 - val_loss: 1851.5208 - val_mae: 1851.5208 - val_mse: 21541596.0000\n",
            "Epoch 143/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 819.6169 - mae: 819.6169 - mse: 5391017.0000\n",
            "Epoch 143: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1493.7478 - mae: 1493.7478 - mse: 18986696.0000 - val_loss: 1692.5314 - val_mae: 1692.5314 - val_mse: 22845706.0000\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1486.7386 - mae: 1486.7386 - mse: 19473580.0000\n",
            "Epoch 144: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1486.7386 - mae: 1486.7386 - mse: 19473580.0000 - val_loss: 1712.1774 - val_mae: 1712.1774 - val_mse: 22429118.0000\n",
            "Epoch 145/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 643.8904 - mae: 643.8904 - mse: 5336668.0000\n",
            "Epoch 145: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1449.2917 - mae: 1449.2917 - mse: 19086648.0000 - val_loss: 1830.7365 - val_mae: 1830.7365 - val_mse: 24175910.0000\n",
            "Epoch 146/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 571.6898 - mae: 571.6898 - mse: 5332766.5000\n",
            "Epoch 146: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1463.2307 - mae: 1463.2307 - mse: 18758804.0000 - val_loss: 1807.0955 - val_mae: 1807.0955 - val_mse: 23920482.0000\n",
            "Epoch 147/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 569.0984 - mae: 569.0984 - mse: 5301658.0000\n",
            "Epoch 147: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1450.5802 - mae: 1450.5802 - mse: 19121196.0000 - val_loss: 1744.6060 - val_mae: 1744.6060 - val_mse: 22227556.0000\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1437.3472 - mae: 1437.3472 - mse: 18874534.0000\n",
            "Epoch 148: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1437.3472 - mae: 1437.3472 - mse: 18874534.0000 - val_loss: 1790.4486 - val_mae: 1790.4486 - val_mse: 22942342.0000\n",
            "Epoch 149/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 649.2578 - mae: 649.2578 - mse: 5384189.0000\n",
            "Epoch 149: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1405.5731 - mae: 1405.5731 - mse: 18890486.0000 - val_loss: 1714.1625 - val_mae: 1714.1625 - val_mse: 22651584.0000\n",
            "Epoch 150/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 589.8744 - mae: 589.8744 - mse: 5367038.5000\n",
            "Epoch 150: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1375.7930 - mae: 1375.7930 - mse: 18897594.0000 - val_loss: 1646.0046 - val_mae: 1646.0046 - val_mse: 22250460.0000\n",
            "Epoch 151/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 542.3436 - mae: 542.3436 - mse: 5287566.0000\n",
            "Epoch 151: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1376.0460 - mae: 1376.0460 - mse: 18914156.0000 - val_loss: 1604.7181 - val_mae: 1604.7181 - val_mse: 22022288.0000\n",
            "Epoch 152/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 502.5577 - mae: 502.5577 - mse: 5151193.5000\n",
            "Epoch 152: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1375.3668 - mae: 1375.3668 - mse: 18796732.0000 - val_loss: 1690.9971 - val_mae: 1690.9971 - val_mse: 22414420.0000\n",
            "Epoch 153/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1464.5160 - mae: 1464.5160 - mse: 18282904.0000\n",
            "Epoch 153: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1525.9027 - mae: 1525.9027 - mse: 19369032.0000 - val_loss: 1795.7491 - val_mae: 1795.7491 - val_mse: 22062156.0000\n",
            "Epoch 154/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 714.4910 - mae: 714.4910 - mse: 5387441.5000\n",
            "Epoch 154: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1445.4313 - mae: 1445.4313 - mse: 18771300.0000 - val_loss: 1785.2498 - val_mae: 1785.2498 - val_mse: 22091532.0000\n",
            "Epoch 155/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 663.3214 - mae: 663.3214 - mse: 5213307.0000\n",
            "Epoch 155: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1390.9574 - mae: 1390.9574 - mse: 18818818.0000 - val_loss: 1820.0753 - val_mae: 1820.0753 - val_mse: 21917152.0000\n",
            "Epoch 156/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 674.6136 - mae: 674.6136 - mse: 5077669.0000\n",
            "Epoch 156: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1434.1426 - mae: 1434.1426 - mse: 19286256.0000 - val_loss: 1681.4463 - val_mae: 1681.4463 - val_mse: 22236720.0000\n",
            "Epoch 157/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 607.3848 - mae: 607.3848 - mse: 5396839.0000\n",
            "Epoch 157: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1505.0793 - mae: 1505.0793 - mse: 19412582.0000 - val_loss: 1667.6570 - val_mae: 1667.6570 - val_mse: 22262182.0000\n",
            "Epoch 158/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 569.6646 - mae: 569.6646 - mse: 5341037.5000\n",
            "Epoch 158: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1467.2026 - mae: 1467.2026 - mse: 19447470.0000 - val_loss: 1625.8983 - val_mae: 1625.8983 - val_mse: 21659416.0000\n",
            "Epoch 159/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 564.4611 - mae: 564.4611 - mse: 5266628.0000\n",
            "Epoch 159: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1429.0570 - mae: 1429.0570 - mse: 19018646.0000 - val_loss: 1592.9487 - val_mae: 1592.9487 - val_mse: 21886148.0000\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1420.3539 - mae: 1420.3539 - mse: 19142670.0000\n",
            "Epoch 160: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1420.3539 - mae: 1420.3539 - mse: 19142670.0000 - val_loss: 1657.9537 - val_mae: 1657.9537 - val_mse: 21760156.0000\n",
            "Epoch 161/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 566.2217 - mae: 566.2217 - mse: 5011003.5000\n",
            "Epoch 161: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1406.1500 - mae: 1406.1500 - mse: 18953652.0000 - val_loss: 1764.4265 - val_mae: 1764.4265 - val_mse: 22723564.0000\n",
            "Epoch 162/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 627.8361 - mae: 627.8361 - mse: 5451087.5000\n",
            "Epoch 162: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1450.8491 - mae: 1450.8491 - mse: 19325962.0000 - val_loss: 1865.5659 - val_mae: 1865.5659 - val_mse: 21878146.0000\n",
            "Epoch 163/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 757.3618 - mae: 757.3618 - mse: 5168329.5000\n",
            "Epoch 163: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1484.4259 - mae: 1484.4259 - mse: 19208224.0000 - val_loss: 1679.5656 - val_mae: 1679.5656 - val_mse: 21810308.0000\n",
            "Epoch 164/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 588.2212 - mae: 588.2212 - mse: 5097382.5000\n",
            "Epoch 164: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1399.5043 - mae: 1399.5043 - mse: 18882850.0000 - val_loss: 1588.6014 - val_mae: 1588.6014 - val_mse: 21569816.0000\n",
            "Epoch 165/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 491.7281 - mae: 491.7281 - mse: 5114630.0000\n",
            "Epoch 165: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1372.6948 - mae: 1372.6948 - mse: 19032622.0000 - val_loss: 1810.7289 - val_mae: 1810.7289 - val_mse: 22169478.0000\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1478.3064 - mae: 1478.3064 - mse: 19121620.0000\n",
            "Epoch 166: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1478.3064 - mae: 1478.3064 - mse: 19121620.0000 - val_loss: 1693.2512 - val_mae: 1693.2512 - val_mse: 21861716.0000\n",
            "Epoch 167/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 615.9459 - mae: 615.9459 - mse: 5233602.5000\n",
            "Epoch 167: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1386.0244 - mae: 1386.0244 - mse: 18929502.0000 - val_loss: 1606.5216 - val_mae: 1606.5216 - val_mse: 21772240.0000\n",
            "Epoch 168/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 540.9520 - mae: 540.9520 - mse: 5249143.0000\n",
            "Epoch 168: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1481.9241 - mae: 1481.9241 - mse: 19114342.0000 - val_loss: 1763.0306 - val_mae: 1763.0306 - val_mse: 21529090.0000\n",
            "Epoch 169/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1365.7289 - mae: 1365.7289 - mse: 17779696.0000\n",
            "Epoch 169: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1458.4142 - mae: 1458.4142 - mse: 19433214.0000 - val_loss: 1687.4558 - val_mae: 1687.4558 - val_mse: 22084158.0000\n",
            "Epoch 170/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1369.2236 - mae: 1369.2236 - mse: 18205252.0000\n",
            "Epoch 170: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1423.0815 - mae: 1423.0815 - mse: 19276742.0000 - val_loss: 1570.4565 - val_mae: 1570.4565 - val_mse: 21730082.0000\n",
            "Epoch 171/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1402.5637 - mae: 1402.5637 - mse: 18782788.0000\n",
            "Epoch 171: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1425.7990 - mae: 1425.7990 - mse: 19271336.0000 - val_loss: 1719.6309 - val_mae: 1719.6309 - val_mse: 21919718.0000\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1401.2018 - mae: 1401.2018 - mse: 19246408.0000\n",
            "Epoch 172: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1401.2018 - mae: 1401.2018 - mse: 19246408.0000 - val_loss: 1681.7344 - val_mae: 1681.7344 - val_mse: 22064636.0000\n",
            "Epoch 173/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 601.9940 - mae: 601.9940 - mse: 5305170.5000\n",
            "Epoch 173: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1452.2855 - mae: 1452.2855 - mse: 19361582.0000 - val_loss: 1741.8320 - val_mae: 1741.8320 - val_mse: 22826106.0000\n",
            "Epoch 174/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 652.7350 - mae: 652.7350 - mse: 5500091.5000\n",
            "Epoch 174: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1444.6577 - mae: 1444.6577 - mse: 19385616.0000 - val_loss: 1637.4092 - val_mae: 1637.4092 - val_mse: 22073490.0000\n",
            "Epoch 175/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1323.3716 - mae: 1323.3716 - mse: 15752439.0000\n",
            "Epoch 175: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1442.7186 - mae: 1442.7186 - mse: 18853488.0000 - val_loss: 1680.8284 - val_mae: 1680.8284 - val_mse: 22729020.0000\n",
            "Epoch 176/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 487.8693 - mae: 487.8693 - mse: 5148907.5000\n",
            "Epoch 176: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1379.7401 - mae: 1379.7401 - mse: 18882064.0000 - val_loss: 1680.3909 - val_mae: 1680.3909 - val_mse: 22290404.0000\n",
            "Epoch 177/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 540.1530 - mae: 540.1530 - mse: 5314445.5000\n",
            "Epoch 177: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1409.7736 - mae: 1409.7736 - mse: 19096146.0000 - val_loss: 1694.6171 - val_mae: 1694.6171 - val_mse: 22686394.0000\n",
            "Epoch 178/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 588.9081 - mae: 588.9081 - mse: 5378404.5000\n",
            "Epoch 178: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1461.3274 - mae: 1461.3274 - mse: 19320270.0000 - val_loss: 1714.6049 - val_mae: 1714.6049 - val_mse: 22318552.0000\n",
            "Epoch 179/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1409.8228 - mae: 1409.8228 - mse: 18589268.0000\n",
            "Epoch 179: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1430.6583 - mae: 1430.6583 - mse: 19097320.0000 - val_loss: 1811.1906 - val_mae: 1811.1906 - val_mse: 22924548.0000\n",
            "Epoch 180/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 714.1782 - mae: 714.1782 - mse: 5590574.5000\n",
            "Epoch 180: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1400.6813 - mae: 1400.6813 - mse: 18978240.0000 - val_loss: 1731.0895 - val_mae: 1731.0895 - val_mse: 22695568.0000\n",
            "Epoch 181/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 567.4251 - mae: 567.4251 - mse: 5270370.5000\n",
            "Epoch 181: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1448.5992 - mae: 1448.5992 - mse: 19117920.0000 - val_loss: 1762.2196 - val_mae: 1762.2196 - val_mse: 22425294.0000\n",
            "Epoch 182/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 688.7906 - mae: 688.7906 - mse: 5646026.5000\n",
            "Epoch 182: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1425.8807 - mae: 1425.8807 - mse: 18920910.0000 - val_loss: 1646.1298 - val_mae: 1646.1298 - val_mse: 22055288.0000\n",
            "Epoch 183/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 599.3000 - mae: 599.3000 - mse: 5187349.0000\n",
            "Epoch 183: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1460.7245 - mae: 1460.7245 - mse: 19175512.0000 - val_loss: 1704.9849 - val_mae: 1704.9849 - val_mse: 22230260.0000\n",
            "Epoch 184/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 597.6128 - mae: 597.6128 - mse: 5438386.5000\n",
            "Epoch 184: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1452.6411 - mae: 1452.6411 - mse: 19311882.0000 - val_loss: 1688.1228 - val_mae: 1688.1228 - val_mse: 21953458.0000\n",
            "Epoch 185/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1491.8967 - mae: 1491.8967 - mse: 16615170.0000\n",
            "Epoch 185: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1614.0773 - mae: 1614.0773 - mse: 19563024.0000 - val_loss: 2056.6270 - val_mae: 2056.6270 - val_mse: 23825086.0000\n",
            "Epoch 186/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1397.3013 - mae: 1397.3013 - mse: 16371541.0000\n",
            "Epoch 186: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1493.0251 - mae: 1493.0251 - mse: 19275794.0000 - val_loss: 1797.8459 - val_mae: 1797.8459 - val_mse: 23923606.0000\n",
            "Epoch 187/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1440.0934 - mae: 1440.0934 - mse: 18065194.0000\n",
            "Epoch 187: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1486.2892 - mae: 1486.2892 - mse: 19269246.0000 - val_loss: 1834.0236 - val_mae: 1834.0236 - val_mse: 21167352.0000\n",
            "Epoch 188/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1358.3448 - mae: 1358.3448 - mse: 17842140.0000\n",
            "Epoch 188: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1408.1727 - mae: 1408.1727 - mse: 18948598.0000 - val_loss: 1910.9517 - val_mae: 1910.9517 - val_mse: 24237932.0000\n",
            "Epoch 189/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1470.8364 - mae: 1470.8364 - mse: 18113928.0000\n",
            "Epoch 189: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1523.4659 - mae: 1523.4659 - mse: 19255978.0000 - val_loss: 1665.4508 - val_mae: 1665.4508 - val_mse: 22070186.0000\n",
            "Epoch 190/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1503.1479 - mae: 1503.1479 - mse: 18089650.0000\n",
            "Epoch 190: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1538.0819 - mae: 1538.0819 - mse: 19111136.0000 - val_loss: 1851.2350 - val_mae: 1851.2350 - val_mse: 23838222.0000\n",
            "Epoch 191/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1391.0160 - mae: 1391.0160 - mse: 17358308.0000\n",
            "Epoch 191: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1452.1488 - mae: 1452.1488 - mse: 18757576.0000 - val_loss: 1647.4734 - val_mae: 1647.4734 - val_mse: 21830712.0000\n",
            "Epoch 192/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1440.5079 - mae: 1440.5079 - mse: 18573174.0000\n",
            "Epoch 192: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1459.0653 - mae: 1459.0653 - mse: 19065950.0000 - val_loss: 1661.6846 - val_mae: 1661.6846 - val_mse: 21788978.0000\n",
            "Epoch 193/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1346.3329 - mae: 1346.3329 - mse: 17741618.0000\n",
            "Epoch 193: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1418.1926 - mae: 1418.1926 - mse: 18630562.0000 - val_loss: 1742.0984 - val_mae: 1742.0984 - val_mse: 22789298.0000\n",
            "Epoch 194/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1331.9315 - mae: 1331.9315 - mse: 17174822.0000\n",
            "Epoch 194: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1414.6473 - mae: 1414.6473 - mse: 18845152.0000 - val_loss: 1613.8800 - val_mae: 1613.8800 - val_mse: 22467454.0000\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1481.8088 - mae: 1481.8088 - mse: 18835108.0000\n",
            "Epoch 195: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1481.8088 - mae: 1481.8088 - mse: 18835108.0000 - val_loss: 1816.0914 - val_mae: 1816.0914 - val_mse: 23203830.0000\n",
            "Epoch 196/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1363.6702 - mae: 1363.6702 - mse: 17971038.0000\n",
            "Epoch 196: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1401.7616 - mae: 1401.7616 - mse: 18854646.0000 - val_loss: 1629.1235 - val_mae: 1629.1235 - val_mse: 22351700.0000\n",
            "Epoch 197/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1392.7878 - mae: 1392.7878 - mse: 17883996.0000\n",
            "Epoch 197: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1456.0135 - mae: 1456.0135 - mse: 19023544.0000 - val_loss: 1994.7765 - val_mae: 1994.7765 - val_mse: 24522754.0000\n",
            "Epoch 198/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1369.1909 - mae: 1369.1909 - mse: 17628114.0000\n",
            "Epoch 198: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1460.6887 - mae: 1460.6887 - mse: 19314040.0000 - val_loss: 1685.3812 - val_mae: 1685.3812 - val_mse: 22009584.0000\n",
            "Epoch 199/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1355.6654 - mae: 1355.6654 - mse: 18046890.0000\n",
            "Epoch 199: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1390.2170 - mae: 1390.2170 - mse: 18893606.0000 - val_loss: 1786.9207 - val_mae: 1786.9207 - val_mse: 23453242.0000\n",
            "Epoch 200/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1364.9854 - mae: 1364.9854 - mse: 17995768.0000\n",
            "Epoch 200: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1429.1984 - mae: 1429.1984 - mse: 18996318.0000 - val_loss: 1744.1576 - val_mae: 1744.1576 - val_mse: 23449966.0000\n",
            "Epoch 201/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1396.5591 - mae: 1396.5591 - mse: 18237362.0000\n",
            "Epoch 201: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1414.9854 - mae: 1414.9854 - mse: 18751806.0000 - val_loss: 1635.2697 - val_mae: 1635.2697 - val_mse: 22229528.0000\n",
            "Epoch 202/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1327.3448 - mae: 1327.3448 - mse: 17719698.0000\n",
            "Epoch 202: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1407.3344 - mae: 1407.3344 - mse: 18869676.0000 - val_loss: 1679.3595 - val_mae: 1679.3595 - val_mse: 22731780.0000\n",
            "Epoch 203/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1319.0209 - mae: 1319.0209 - mse: 17658432.0000\n",
            "Epoch 203: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1371.7443 - mae: 1371.7443 - mse: 18801598.0000 - val_loss: 1795.2662 - val_mae: 1795.2662 - val_mse: 23375606.0000\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1449.2316 - mae: 1449.2316 - mse: 18745152.0000\n",
            "Epoch 204: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1449.2316 - mae: 1449.2316 - mse: 18745152.0000 - val_loss: 1704.3145 - val_mae: 1704.3145 - val_mse: 22364018.0000\n",
            "Epoch 205/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1331.2493 - mae: 1331.2493 - mse: 17436568.0000\n",
            "Epoch 205: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1384.0553 - mae: 1384.0553 - mse: 18535072.0000 - val_loss: 1800.4004 - val_mae: 1800.4004 - val_mse: 22951468.0000\n",
            "Epoch 206/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1333.8624 - mae: 1333.8624 - mse: 17854744.0000\n",
            "Epoch 206: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1382.6377 - mae: 1382.6377 - mse: 18943666.0000 - val_loss: 1748.5133 - val_mae: 1748.5133 - val_mse: 22851204.0000\n",
            "Epoch 207/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1280.1592 - mae: 1280.1592 - mse: 17117354.0000\n",
            "Epoch 207: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1375.9685 - mae: 1375.9685 - mse: 18816752.0000 - val_loss: 1776.6945 - val_mae: 1776.6945 - val_mse: 23459630.0000\n",
            "Epoch 208/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1343.2617 - mae: 1343.2617 - mse: 18421178.0000\n",
            "Epoch 208: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1362.3572 - mae: 1362.3572 - mse: 18933112.0000 - val_loss: 1686.3638 - val_mae: 1686.3638 - val_mse: 22906474.0000\n",
            "Epoch 209/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1256.4005 - mae: 1256.4005 - mse: 16044375.0000\n",
            "Epoch 209: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1370.5601 - mae: 1370.5601 - mse: 18727280.0000 - val_loss: 1702.5634 - val_mae: 1702.5634 - val_mse: 23095530.0000\n",
            "Epoch 210/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1276.4280 - mae: 1276.4280 - mse: 17407542.0000\n",
            "Epoch 210: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1335.7239 - mae: 1335.7239 - mse: 18492710.0000 - val_loss: 1759.6548 - val_mae: 1759.6548 - val_mse: 23231666.0000\n",
            "Epoch 211/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1366.5308 - mae: 1366.5308 - mse: 17837072.0000\n",
            "Epoch 211: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1423.2284 - mae: 1423.2284 - mse: 18943038.0000 - val_loss: 1745.4187 - val_mae: 1745.4187 - val_mse: 23244566.0000\n",
            "Epoch 212/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1393.4305 - mae: 1393.4305 - mse: 17046016.0000\n",
            "Epoch 212: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1452.4225 - mae: 1452.4225 - mse: 18923358.0000 - val_loss: 1709.0654 - val_mae: 1709.0654 - val_mse: 22512526.0000\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1508.3890 - mae: 1508.3890 - mse: 18875284.0000\n",
            "Epoch 213: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1508.3890 - mae: 1508.3890 - mse: 18875284.0000 - val_loss: 1911.6688 - val_mae: 1911.6688 - val_mse: 24345878.0000\n",
            "Epoch 214/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1366.8964 - mae: 1366.8964 - mse: 17149270.0000\n",
            "Epoch 214: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1466.1649 - mae: 1466.1649 - mse: 18860570.0000 - val_loss: 1834.7493 - val_mae: 1834.7493 - val_mse: 23799468.0000\n",
            "Epoch 215/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1380.0923 - mae: 1380.0923 - mse: 17246170.0000\n",
            "Epoch 215: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1461.6234 - mae: 1461.6234 - mse: 18927304.0000 - val_loss: 1721.7473 - val_mae: 1721.7473 - val_mse: 22956420.0000\n",
            "Epoch 216/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1314.2947 - mae: 1314.2947 - mse: 17774294.0000\n",
            "Epoch 216: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1354.8741 - mae: 1354.8741 - mse: 18692432.0000 - val_loss: 1713.0367 - val_mae: 1713.0367 - val_mse: 23011500.0000\n",
            "Epoch 217/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1246.1017 - mae: 1246.1017 - mse: 16215683.0000\n",
            "Epoch 217: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1344.7434 - mae: 1344.7434 - mse: 18590824.0000 - val_loss: 1786.0050 - val_mae: 1786.0050 - val_mse: 25270480.0000\n",
            "Epoch 218/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1377.5502 - mae: 1377.5502 - mse: 17710584.0000\n",
            "Epoch 218: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1454.3879 - mae: 1454.3879 - mse: 18939490.0000 - val_loss: 1844.0593 - val_mae: 1844.0593 - val_mse: 21896570.0000\n",
            "Epoch 219/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1370.1290 - mae: 1370.1290 - mse: 17754506.0000\n",
            "Epoch 219: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1419.9154 - mae: 1419.9154 - mse: 18692442.0000 - val_loss: 2002.4938 - val_mae: 2002.4938 - val_mse: 25112610.0000\n",
            "Epoch 220/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1423.4341 - mae: 1423.4341 - mse: 17913250.0000\n",
            "Epoch 220: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1461.2417 - mae: 1461.2417 - mse: 18986904.0000 - val_loss: 1764.9296 - val_mae: 1764.9296 - val_mse: 24269372.0000\n",
            "Epoch 221/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1240.4718 - mae: 1240.4718 - mse: 16392806.0000\n",
            "Epoch 221: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1373.1230 - mae: 1373.1230 - mse: 18922078.0000 - val_loss: 1872.9337 - val_mae: 1872.9337 - val_mse: 22848552.0000\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1427.0886 - mae: 1427.0886 - mse: 18837224.0000\n",
            "Epoch 222: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1427.0886 - mae: 1427.0886 - mse: 18837224.0000 - val_loss: 1661.6101 - val_mae: 1661.6101 - val_mse: 22055446.0000\n",
            "Epoch 223/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1357.5381 - mae: 1357.5381 - mse: 17779442.0000\n",
            "Epoch 223: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1408.2477 - mae: 1408.2477 - mse: 18661842.0000 - val_loss: 1731.0695 - val_mae: 1731.0695 - val_mse: 23354824.0000\n",
            "Epoch 224/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1407.2947 - mae: 1407.2947 - mse: 17142290.0000\n",
            "Epoch 224: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1458.3625 - mae: 1458.3625 - mse: 18917300.0000 - val_loss: 1641.5757 - val_mae: 1641.5757 - val_mse: 21947448.0000\n",
            "Epoch 225/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1446.4354 - mae: 1446.4354 - mse: 18703786.0000\n",
            "Epoch 225: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1464.1989 - mae: 1464.1989 - mse: 19211412.0000 - val_loss: 1807.1235 - val_mae: 1807.1235 - val_mse: 23138036.0000\n",
            "Epoch 226/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1422.8491 - mae: 1422.8491 - mse: 18510902.0000\n",
            "Epoch 226: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1454.5483 - mae: 1454.5483 - mse: 19355154.0000 - val_loss: 1683.4576 - val_mae: 1683.4576 - val_mse: 21947322.0000\n",
            "Epoch 227/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1371.8593 - mae: 1371.8593 - mse: 17600424.0000\n",
            "Epoch 227: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1420.9420 - mae: 1420.9420 - mse: 18815540.0000 - val_loss: 1879.2101 - val_mae: 1879.2101 - val_mse: 23377502.0000\n",
            "Epoch 228/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1393.6161 - mae: 1393.6161 - mse: 17579606.0000\n",
            "Epoch 228: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1488.1372 - mae: 1488.1372 - mse: 19263264.0000 - val_loss: 1661.8918 - val_mae: 1661.8918 - val_mse: 21841676.0000\n",
            "Epoch 229/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1330.2087 - mae: 1330.2087 - mse: 16496613.0000\n",
            "Epoch 229: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1478.3921 - mae: 1478.3921 - mse: 19317078.0000 - val_loss: 1730.3789 - val_mae: 1730.3789 - val_mse: 22736712.0000\n",
            "Epoch 230/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1391.2585 - mae: 1391.2585 - mse: 17728242.0000\n",
            "Epoch 230: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1427.8259 - mae: 1427.8259 - mse: 18988072.0000 - val_loss: 1616.6948 - val_mae: 1616.6948 - val_mse: 21913592.0000\n",
            "Epoch 231/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1347.1276 - mae: 1347.1276 - mse: 18115964.0000\n",
            "Epoch 231: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1397.2310 - mae: 1397.2310 - mse: 19185498.0000 - val_loss: 1686.4241 - val_mae: 1686.4241 - val_mse: 22330640.0000\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1347.1080 - mae: 1347.1080 - mse: 18694630.0000\n",
            "Epoch 232: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1347.1080 - mae: 1347.1080 - mse: 18694630.0000 - val_loss: 1607.5652 - val_mae: 1607.5652 - val_mse: 21688320.0000\n",
            "Epoch 233/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1457.9041 - mae: 1457.9041 - mse: 18767276.0000\n",
            "Epoch 233: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1484.2043 - mae: 1484.2043 - mse: 19300360.0000 - val_loss: 1790.6971 - val_mae: 1790.6971 - val_mse: 23016190.0000\n",
            "Epoch 234/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1562.4578 - mae: 1562.4578 - mse: 18108052.0000\n",
            "Epoch 234: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1583.6100 - mae: 1583.6100 - mse: 19211008.0000 - val_loss: 1883.9236 - val_mae: 1883.9236 - val_mse: 21280332.0000\n",
            "Epoch 235/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1339.5214 - mae: 1339.5214 - mse: 16513413.0000\n",
            "Epoch 235: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1407.1671 - mae: 1407.1671 - mse: 18799558.0000 - val_loss: 1723.6868 - val_mae: 1723.6868 - val_mse: 22582248.0000\n",
            "Epoch 236/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1325.8102 - mae: 1325.8102 - mse: 17876754.0000\n",
            "Epoch 236: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1378.8998 - mae: 1378.8998 - mse: 18874256.0000 - val_loss: 1707.6884 - val_mae: 1707.6884 - val_mse: 22669612.0000\n",
            "Epoch 237/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1414.0015 - mae: 1414.0015 - mse: 18582414.0000\n",
            "Epoch 237: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1432.3499 - mae: 1432.3499 - mse: 19079512.0000 - val_loss: 1773.9921 - val_mae: 1773.9921 - val_mse: 23789568.0000\n",
            "Epoch 238/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1495.7709 - mae: 1495.7709 - mse: 18396140.0000\n",
            "Epoch 238: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1535.7421 - mae: 1535.7421 - mse: 19537300.0000 - val_loss: 1747.8827 - val_mae: 1747.8827 - val_mse: 21822776.0000\n",
            "Epoch 239/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1373.7424 - mae: 1373.7424 - mse: 16778026.0000\n",
            "Epoch 239: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1469.3998 - mae: 1469.3998 - mse: 19118114.0000 - val_loss: 1594.3737 - val_mae: 1594.3737 - val_mse: 22350332.0000\n",
            "Epoch 240/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1357.9313 - mae: 1357.9313 - mse: 17785132.0000\n",
            "Epoch 240: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1423.5604 - mae: 1423.5605 - mse: 18706972.0000 - val_loss: 1695.8733 - val_mae: 1695.8733 - val_mse: 21569698.0000\n",
            "Epoch 241/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1362.6145 - mae: 1362.6145 - mse: 16770567.0000\n",
            "Epoch 241: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1423.8473 - mae: 1423.8473 - mse: 18973914.0000 - val_loss: 1602.7769 - val_mae: 1602.7769 - val_mse: 22025718.0000\n",
            "Epoch 242/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 511.9213 - mae: 511.9213 - mse: 5235666.0000\n",
            "Epoch 242: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1366.9585 - mae: 1366.9585 - mse: 18770526.0000 - val_loss: 1606.8130 - val_mae: 1606.8130 - val_mse: 21581394.0000\n",
            "Epoch 243/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 613.0103 - mae: 613.0103 - mse: 5466455.5000\n",
            "Epoch 243: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1420.3661 - mae: 1420.3661 - mse: 18916318.0000 - val_loss: 1654.2559 - val_mae: 1654.2559 - val_mse: 21302856.0000\n",
            "Epoch 244/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1300.4437 - mae: 1300.4437 - mse: 17862872.0000\n",
            "Epoch 244: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1354.1848 - mae: 1354.1848 - mse: 18939854.0000 - val_loss: 1602.9214 - val_mae: 1602.9214 - val_mse: 22207124.0000\n",
            "Epoch 245/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 478.1036 - mae: 478.1036 - mse: 5223701.5000\n",
            "Epoch 245: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1394.3604 - mae: 1394.3604 - mse: 18591080.0000 - val_loss: 1662.8401 - val_mae: 1662.8401 - val_mse: 21902996.0000\n",
            "Epoch 246/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1426.0730 - mae: 1426.0730 - mse: 18571844.0000\n",
            "Epoch 246: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1447.2612 - mae: 1447.2612 - mse: 19089358.0000 - val_loss: 1873.8829 - val_mae: 1873.8829 - val_mse: 25039418.0000\n",
            "Epoch 247/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 574.1481 - mae: 574.1481 - mse: 5437413.5000\n",
            "Epoch 247: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1561.2599 - mae: 1561.2599 - mse: 19978862.0000 - val_loss: 1774.4122 - val_mae: 1774.4122 - val_mse: 22608856.0000\n",
            "Epoch 248/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 625.6118 - mae: 625.6118 - mse: 5229163.5000\n",
            "Epoch 248: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1495.5930 - mae: 1495.5930 - mse: 19223586.0000 - val_loss: 1765.4261 - val_mae: 1765.4261 - val_mse: 22399780.0000\n",
            "Epoch 249/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1418.1180 - mae: 1418.1180 - mse: 18017596.0000\n",
            "Epoch 249: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1478.3091 - mae: 1478.3091 - mse: 19160972.0000 - val_loss: 1634.2678 - val_mae: 1634.2678 - val_mse: 21448510.0000\n",
            "Epoch 250/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 613.1325 - mae: 613.1325 - mse: 5264668.0000\n",
            "Epoch 250: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1444.3531 - mae: 1444.3531 - mse: 18971034.0000 - val_loss: 1720.7611 - val_mae: 1720.7611 - val_mse: 23480420.0000\n",
            "Epoch 251/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1471.4567 - mae: 1471.4567 - mse: 18294582.0000\n",
            "Epoch 251: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1517.6603 - mae: 1517.6603 - mse: 19349786.0000 - val_loss: 1791.3805 - val_mae: 1791.3805 - val_mse: 23816782.0000\n",
            "Epoch 252/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 683.5714 - mae: 683.5714 - mse: 5658573.0000\n",
            "Epoch 252: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1562.0645 - mae: 1562.0645 - mse: 20290416.0000 - val_loss: 1710.7896 - val_mae: 1710.7896 - val_mse: 22168674.0000\n",
            "Epoch 253/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 661.2954 - mae: 661.2954 - mse: 5482514.5000\n",
            "Epoch 253: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1469.5442 - mae: 1469.5442 - mse: 19384794.0000 - val_loss: 1701.7494 - val_mae: 1701.7494 - val_mse: 22537102.0000\n",
            "Epoch 254/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1361.0764 - mae: 1361.0764 - mse: 17895236.0000\n",
            "Epoch 254: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1425.8164 - mae: 1425.8164 - mse: 19018466.0000 - val_loss: 1639.8154 - val_mae: 1639.8154 - val_mse: 22444914.0000\n",
            "Epoch 255/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1386.9207 - mae: 1386.9207 - mse: 18350766.0000\n",
            "Epoch 255: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1406.6230 - mae: 1406.6230 - mse: 18865114.0000 - val_loss: 1812.4210 - val_mae: 1812.4210 - val_mse: 23022262.0000\n",
            "Epoch 256/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1338.0763 - mae: 1338.0763 - mse: 17750466.0000\n",
            "Epoch 256: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1395.7812 - mae: 1395.7812 - mse: 18846992.0000 - val_loss: 1768.2990 - val_mae: 1768.2990 - val_mse: 23719884.0000\n",
            "Epoch 257/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1297.8496 - mae: 1297.8496 - mse: 15858418.0000\n",
            "Epoch 257: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1431.4176 - mae: 1431.4176 - mse: 18870332.0000 - val_loss: 1814.6718 - val_mae: 1814.6718 - val_mse: 23942034.0000\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1467.2291 - mae: 1467.2291 - mse: 19338072.0000\n",
            "Epoch 258: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1467.2291 - mae: 1467.2291 - mse: 19338072.0000 - val_loss: 1673.1095 - val_mae: 1673.1095 - val_mse: 21567492.0000\n",
            "Epoch 259/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1545.2587 - mae: 1545.2587 - mse: 18187494.0000\n",
            "Epoch 259: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1503.2100 - mae: 1503.2100 - mse: 18970360.0000 - val_loss: 1678.4800 - val_mae: 1678.4800 - val_mse: 22061494.0000\n",
            "Epoch 260/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1287.9131 - mae: 1287.9131 - mse: 17694154.0000\n",
            "Epoch 260: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1335.8734 - mae: 1335.8734 - mse: 18667854.0000 - val_loss: 1693.5121 - val_mae: 1693.5121 - val_mse: 22045606.0000\n",
            "Epoch 261/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1393.0258 - mae: 1393.0258 - mse: 18339878.0000\n",
            "Epoch 261: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1464.3398 - mae: 1464.3398 - mse: 19404846.0000 - val_loss: 1571.3969 - val_mae: 1571.3969 - val_mse: 21332136.0000\n",
            "Epoch 262/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1349.3394 - mae: 1349.3394 - mse: 17497454.0000\n",
            "Epoch 262: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1385.9578 - mae: 1385.9578 - mse: 18707112.0000 - val_loss: 1713.8215 - val_mae: 1713.8215 - val_mse: 22913452.0000\n",
            "Epoch 263/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1206.9016 - mae: 1206.9016 - mse: 15855748.0000\n",
            "Epoch 263: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1360.9121 - mae: 1360.9121 - mse: 18807848.0000 - val_loss: 1765.4054 - val_mae: 1765.4054 - val_mse: 21949464.0000\n",
            "Epoch 264/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1385.9523 - mae: 1385.9523 - mse: 18161352.0000\n",
            "Epoch 264: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1404.6885 - mae: 1404.6885 - mse: 18677570.0000 - val_loss: 1762.4856 - val_mae: 1762.4856 - val_mse: 23879746.0000\n",
            "Epoch 265/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 567.7638 - mae: 567.7638 - mse: 5334439.0000\n",
            "Epoch 265: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1463.8004 - mae: 1463.8004 - mse: 19175090.0000 - val_loss: 1654.9904 - val_mae: 1654.9904 - val_mse: 21753868.0000\n",
            "Epoch 266/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1319.8268 - mae: 1319.8268 - mse: 17671010.0000\n",
            "Epoch 266: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1372.8549 - mae: 1372.8549 - mse: 18799566.0000 - val_loss: 1614.1385 - val_mae: 1614.1385 - val_mse: 21501844.0000\n",
            "Epoch 267/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1381.0826 - mae: 1381.0826 - mse: 18029606.0000\n",
            "Epoch 267: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1464.7030 - mae: 1464.7030 - mse: 19003488.0000 - val_loss: 1829.1624 - val_mae: 1829.1624 - val_mse: 22459298.0000\n",
            "Epoch 268/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1313.2102 - mae: 1313.2102 - mse: 16569344.0000\n",
            "Epoch 268: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1401.2683 - mae: 1401.2683 - mse: 18861518.0000 - val_loss: 1680.3998 - val_mae: 1680.3998 - val_mse: 22284362.0000\n",
            "Epoch 269/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1483.4015 - mae: 1483.4015 - mse: 18547480.0000\n",
            "Epoch 269: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1507.6593 - mae: 1507.6593 - mse: 19058246.0000 - val_loss: 1986.6271 - val_mae: 1986.6271 - val_mse: 25090776.0000\n",
            "Epoch 270/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1638.4578 - mae: 1638.4578 - mse: 19882438.0000\n",
            "Epoch 270: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1636.1923 - mae: 1636.1923 - mse: 20248434.0000 - val_loss: 1936.2925 - val_mae: 1936.2925 - val_mse: 23809362.0000\n",
            "Epoch 271/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1498.6415 - mae: 1498.6415 - mse: 18129674.0000\n",
            "Epoch 271: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1548.9966 - mae: 1548.9966 - mse: 19199912.0000 - val_loss: 1940.2947 - val_mae: 1940.2947 - val_mse: 22457552.0000\n",
            "Epoch 272/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1361.4042 - mae: 1361.4042 - mse: 16390633.0000\n",
            "Epoch 272: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1463.6464 - mae: 1463.6464 - mse: 19155826.0000 - val_loss: 1658.7017 - val_mae: 1658.7017 - val_mse: 21184456.0000\n",
            "Epoch 273/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1447.9712 - mae: 1447.9712 - mse: 17980484.0000\n",
            "Epoch 273: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1487.1591 - mae: 1487.1591 - mse: 18960082.0000 - val_loss: 1707.5295 - val_mae: 1707.5295 - val_mse: 22806294.0000\n",
            "Epoch 274/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1316.8995 - mae: 1316.8995 - mse: 15784680.0000\n",
            "Epoch 274: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1455.4484 - mae: 1455.4484 - mse: 18752160.0000 - val_loss: 1600.3251 - val_mae: 1600.3251 - val_mse: 21380116.0000\n",
            "Epoch 275/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1337.4757 - mae: 1337.4757 - mse: 17436838.0000\n",
            "Epoch 275: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1384.8351 - mae: 1384.8351 - mse: 18699752.0000 - val_loss: 1662.7195 - val_mae: 1662.7195 - val_mse: 21432218.0000\n",
            "Epoch 276/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1338.4777 - mae: 1338.4777 - mse: 17651124.0000\n",
            "Epoch 276: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1372.6805 - mae: 1372.6805 - mse: 18857426.0000 - val_loss: 1789.5500 - val_mae: 1789.5500 - val_mse: 23141300.0000\n",
            "Epoch 277/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1335.4652 - mae: 1335.4652 - mse: 17040580.0000\n",
            "Epoch 277: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1430.2708 - mae: 1430.2708 - mse: 18721574.0000 - val_loss: 1615.6433 - val_mae: 1615.6433 - val_mse: 21856842.0000\n",
            "Epoch 278/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1260.1801 - mae: 1260.1801 - mse: 16535830.0000\n",
            "Epoch 278: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1353.5059 - mae: 1353.5059 - mse: 18830918.0000 - val_loss: 1623.4185 - val_mae: 1623.4185 - val_mse: 22015746.0000\n",
            "Epoch 279/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1241.6345 - mae: 1241.6345 - mse: 16911318.0000\n",
            "Epoch 279: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1341.5233 - mae: 1341.5233 - mse: 18573150.0000 - val_loss: 1827.7708 - val_mae: 1827.7708 - val_mse: 24099416.0000\n",
            "Epoch 280/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1363.0988 - mae: 1363.0988 - mse: 18065442.0000\n",
            "Epoch 280: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1430.1776 - mae: 1430.1776 - mse: 19015292.0000 - val_loss: 1679.0767 - val_mae: 1679.0767 - val_mse: 21459112.0000\n",
            "Epoch 281/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1327.1858 - mae: 1327.1858 - mse: 17029882.0000\n",
            "Epoch 281: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1416.8926 - mae: 1416.8926 - mse: 18645832.0000 - val_loss: 1769.4418 - val_mae: 1769.4418 - val_mse: 23412860.0000\n",
            "Epoch 282/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1243.8540 - mae: 1243.8540 - mse: 15568388.0000\n",
            "Epoch 282: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1442.2440 - mae: 1442.2440 - mse: 19016256.0000 - val_loss: 1651.1567 - val_mae: 1651.1567 - val_mse: 22301698.0000\n",
            "Epoch 283/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1321.2930 - mae: 1321.2930 - mse: 17244780.0000\n",
            "Epoch 283: val_loss did not improve from 1567.46057\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1357.1454 - mae: 1357.1454 - mse: 18558188.0000 - val_loss: 1651.0697 - val_mae: 1651.0697 - val_mse: 22045366.0000\n",
            "Epoch 284/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1282.8872 - mae: 1282.8872 - mse: 17724972.0000\n",
            "Epoch 284: val_loss improved from 1567.46057 to 1555.26282, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1335.7408 - mae: 1335.7408 - mse: 18707784.0000 - val_loss: 1555.2628 - val_mae: 1555.2628 - val_mse: 21295340.0000\n",
            "Epoch 285/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1292.8220 - mae: 1292.8220 - mse: 16312989.0000\n",
            "Epoch 285: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1395.6940 - mae: 1395.6940 - mse: 18726656.0000 - val_loss: 1681.6284 - val_mae: 1681.6284 - val_mse: 20807030.0000\n",
            "Epoch 286/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1477.2524 - mae: 1477.2524 - mse: 17741398.0000\n",
            "Epoch 286: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1449.2606 - mae: 1449.2606 - mse: 18801292.0000 - val_loss: 1659.8688 - val_mae: 1659.8688 - val_mse: 22454652.0000\n",
            "Epoch 287/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1338.1019 - mae: 1338.1019 - mse: 17558160.0000\n",
            "Epoch 287: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1405.3695 - mae: 1405.3695 - mse: 18689788.0000 - val_loss: 1768.7194 - val_mae: 1768.7194 - val_mse: 21091138.0000\n",
            "Epoch 288/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1327.1207 - mae: 1327.1207 - mse: 15915727.0000\n",
            "Epoch 288: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1451.3785 - mae: 1451.3785 - mse: 18744456.0000 - val_loss: 1703.1223 - val_mae: 1703.1223 - val_mse: 22253126.0000\n",
            "Epoch 289/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1359.8345 - mae: 1359.8345 - mse: 17492458.0000\n",
            "Epoch 289: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1379.9861 - mae: 1379.9861 - mse: 18666192.0000 - val_loss: 1608.2642 - val_mae: 1608.2642 - val_mse: 21708008.0000\n",
            "Epoch 290/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1291.2367 - mae: 1291.2367 - mse: 17510688.0000\n",
            "Epoch 290: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1347.4891 - mae: 1347.4891 - mse: 18583432.0000 - val_loss: 1738.4990 - val_mae: 1738.4990 - val_mse: 24043630.0000\n",
            "Epoch 291/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1446.4977 - mae: 1446.4977 - mse: 18543276.0000\n",
            "Epoch 291: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1508.1934 - mae: 1508.1934 - mse: 20019150.0000 - val_loss: 1710.9432 - val_mae: 1710.9432 - val_mse: 22913390.0000\n",
            "Epoch 292/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1408.9604 - mae: 1408.9604 - mse: 18156946.0000\n",
            "Epoch 292: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1457.7728 - mae: 1457.7728 - mse: 19206618.0000 - val_loss: 1877.8085 - val_mae: 1877.8085 - val_mse: 23924676.0000\n",
            "Epoch 293/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1315.1637 - mae: 1315.1637 - mse: 16070327.0000\n",
            "Epoch 293: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1429.8926 - mae: 1429.8926 - mse: 18954276.0000 - val_loss: 1623.5282 - val_mae: 1623.5282 - val_mse: 21398026.0000\n",
            "Epoch 294/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1294.8231 - mae: 1294.8231 - mse: 15928134.0000\n",
            "Epoch 294: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1390.8000 - mae: 1390.8000 - mse: 18706618.0000 - val_loss: 1631.2629 - val_mae: 1631.2629 - val_mse: 22372496.0000\n",
            "Epoch 295/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1357.1921 - mae: 1357.1921 - mse: 18217962.0000\n",
            "Epoch 295: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1380.6260 - mae: 1380.6260 - mse: 18721492.0000 - val_loss: 1891.6969 - val_mae: 1891.6969 - val_mse: 24594114.0000\n",
            "Epoch 296/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1436.8356 - mae: 1436.8356 - mse: 18026170.0000\n",
            "Epoch 296: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1493.9686 - mae: 1493.9686 - mse: 19204954.0000 - val_loss: 1783.3718 - val_mae: 1783.3718 - val_mse: 22482396.0000\n",
            "Epoch 297/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1305.3866 - mae: 1305.3866 - mse: 17627642.0000\n",
            "Epoch 297: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1349.1161 - mae: 1349.1161 - mse: 18563194.0000 - val_loss: 1760.3402 - val_mae: 1760.3402 - val_mse: 24170614.0000\n",
            "Epoch 298/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1243.9658 - mae: 1243.9658 - mse: 16835374.0000\n",
            "Epoch 298: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1340.1018 - mae: 1340.1018 - mse: 18538648.0000 - val_loss: 1701.1608 - val_mae: 1701.1608 - val_mse: 22818840.0000\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1405.8303 - mae: 1405.8303 - mse: 19097740.0000\n",
            "Epoch 299: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1405.8303 - mae: 1405.8303 - mse: 19097740.0000 - val_loss: 1579.0631 - val_mae: 1579.0631 - val_mse: 21370540.0000\n",
            "Epoch 300/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 541.2838 - mae: 541.2838 - mse: 5284028.0000\n",
            "Epoch 300: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1431.1050 - mae: 1431.1050 - mse: 18758752.0000 - val_loss: 1741.7732 - val_mae: 1741.7732 - val_mse: 23001736.0000\n",
            "Epoch 301/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 536.6804 - mae: 536.6804 - mse: 5159405.5000\n",
            "Epoch 301: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1394.0081 - mae: 1394.0081 - mse: 18704864.0000 - val_loss: 1814.9738 - val_mae: 1814.9738 - val_mse: 22807842.0000\n",
            "Epoch 302/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 681.6088 - mae: 681.6088 - mse: 5566433.0000\n",
            "Epoch 302: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1422.4640 - mae: 1422.4640 - mse: 18544344.0000 - val_loss: 1737.3368 - val_mae: 1737.3368 - val_mse: 23626110.0000\n",
            "Epoch 303/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1340.0239 - mae: 1340.0239 - mse: 17682440.0000\n",
            "Epoch 303: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1402.1125 - mae: 1402.1125 - mse: 18805758.0000 - val_loss: 1638.6221 - val_mae: 1638.6221 - val_mse: 21809124.0000\n",
            "Epoch 304/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 567.4313 - mae: 567.4313 - mse: 5273506.5000\n",
            "Epoch 304: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1446.9529 - mae: 1446.9529 - mse: 18750514.0000 - val_loss: 1690.9823 - val_mae: 1690.9823 - val_mse: 22778530.0000\n",
            "Epoch 305/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1351.8737 - mae: 1351.8737 - mse: 18191758.0000\n",
            "Epoch 305: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1378.3630 - mae: 1378.3630 - mse: 18714010.0000 - val_loss: 1858.1721 - val_mae: 1858.1721 - val_mse: 22859078.0000\n",
            "Epoch 306/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1311.7783 - mae: 1311.7783 - mse: 17316520.0000\n",
            "Epoch 306: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1372.8693 - mae: 1372.8693 - mse: 18409080.0000 - val_loss: 1681.3547 - val_mae: 1681.3547 - val_mse: 23663798.0000\n",
            "Epoch 307/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 542.2687 - mae: 542.2687 - mse: 5297490.0000\n",
            "Epoch 307: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1426.9291 - mae: 1426.9291 - mse: 18822394.0000 - val_loss: 1812.1438 - val_mae: 1812.1438 - val_mse: 22382392.0000\n",
            "Epoch 308/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1329.8979 - mae: 1329.8979 - mse: 17466744.0000\n",
            "Epoch 308: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1380.3444 - mae: 1380.3444 - mse: 18594656.0000 - val_loss: 1648.0641 - val_mae: 1648.0641 - val_mse: 21725420.0000\n",
            "Epoch 309/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 583.2685 - mae: 583.2685 - mse: 5083788.5000\n",
            "Epoch 309: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1340.0861 - mae: 1340.0861 - mse: 18395308.0000 - val_loss: 1639.4150 - val_mae: 1639.4150 - val_mse: 22097798.0000\n",
            "Epoch 310/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 551.3898 - mae: 551.3898 - mse: 5293689.0000\n",
            "Epoch 310: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1356.3149 - mae: 1356.3149 - mse: 18471374.0000 - val_loss: 1720.9845 - val_mae: 1720.9845 - val_mse: 23505202.0000\n",
            "Epoch 311/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 547.8005 - mae: 547.8005 - mse: 5119246.5000\n",
            "Epoch 311: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1422.5580 - mae: 1422.5580 - mse: 18766482.0000 - val_loss: 1699.3113 - val_mae: 1699.3113 - val_mse: 22101964.0000\n",
            "Epoch 312/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1296.6616 - mae: 1296.6616 - mse: 17310744.0000\n",
            "Epoch 312: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1352.2473 - mae: 1352.2473 - mse: 18414662.0000 - val_loss: 1770.1956 - val_mae: 1770.1956 - val_mse: 24353804.0000\n",
            "Epoch 313/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 522.8389 - mae: 522.8389 - mse: 5269676.5000\n",
            "Epoch 313: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1472.2281 - mae: 1472.2281 - mse: 19113754.0000 - val_loss: 1698.2830 - val_mae: 1698.2830 - val_mse: 22718286.0000\n",
            "Epoch 314/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1337.6670 - mae: 1337.6670 - mse: 17294520.0000\n",
            "Epoch 314: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1398.7867 - mae: 1398.7867 - mse: 18401962.0000 - val_loss: 1751.0677 - val_mae: 1751.0677 - val_mse: 22802428.0000\n",
            "Epoch 315/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 615.0707 - mae: 615.0707 - mse: 5117236.0000\n",
            "Epoch 315: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1397.2612 - mae: 1397.2612 - mse: 18617480.0000 - val_loss: 1717.2018 - val_mae: 1717.2018 - val_mse: 21769180.0000\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1405.4459 - mae: 1405.4459 - mse: 18472184.0000\n",
            "Epoch 316: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1405.4459 - mae: 1405.4459 - mse: 18472184.0000 - val_loss: 1711.0149 - val_mae: 1711.0149 - val_mse: 23098500.0000\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1379.9742 - mae: 1379.9742 - mse: 18904074.0000\n",
            "Epoch 317: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1379.9742 - mae: 1379.9742 - mse: 18904074.0000 - val_loss: 1716.6962 - val_mae: 1716.6962 - val_mse: 21041116.0000\n",
            "Epoch 318/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1366.5103 - mae: 1366.5103 - mse: 17539524.0000\n",
            "Epoch 318: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1402.3988 - mae: 1402.3988 - mse: 18501520.0000 - val_loss: 1741.1813 - val_mae: 1741.1813 - val_mse: 22920460.0000\n",
            "Epoch 319/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 598.1274 - mae: 598.1274 - mse: 5371040.5000\n",
            "Epoch 319: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1390.7083 - mae: 1390.7083 - mse: 18598830.0000 - val_loss: 1797.5977 - val_mae: 1797.5977 - val_mse: 25043232.0000\n",
            "Epoch 320/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1564.4562 - mae: 1564.4562 - mse: 20070874.0000\n",
            "Epoch 320: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1579.9962 - mae: 1579.9962 - mse: 20551836.0000 - val_loss: 1718.8262 - val_mae: 1718.8262 - val_mse: 23284806.0000\n",
            "Epoch 321/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1384.7375 - mae: 1384.7375 - mse: 18293116.0000\n",
            "Epoch 321: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1404.5630 - mae: 1404.5630 - mse: 18810176.0000 - val_loss: 1626.6138 - val_mae: 1626.6138 - val_mse: 22350948.0000\n",
            "Epoch 322/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1322.2452 - mae: 1322.2452 - mse: 17550306.0000\n",
            "Epoch 322: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1387.9113 - mae: 1387.9113 - mse: 18752740.0000 - val_loss: 1647.4144 - val_mae: 1647.4144 - val_mse: 21894378.0000\n",
            "Epoch 323/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 565.0809 - mae: 565.0809 - mse: 5099825.0000\n",
            "Epoch 323: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1386.1542 - mae: 1386.1542 - mse: 18829158.0000 - val_loss: 1707.6852 - val_mae: 1707.6852 - val_mse: 21182852.0000\n",
            "Epoch 324/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 679.2626 - mae: 679.2626 - mse: 5250181.5000\n",
            "Epoch 324: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1484.0254 - mae: 1484.0254 - mse: 19038266.0000 - val_loss: 1695.0312 - val_mae: 1695.0312 - val_mse: 22885220.0000\n",
            "Epoch 325/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1373.3207 - mae: 1373.3207 - mse: 17777512.0000\n",
            "Epoch 325: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1418.1237 - mae: 1418.1237 - mse: 18694780.0000 - val_loss: 1643.4661 - val_mae: 1643.4661 - val_mse: 21502978.0000\n",
            "Epoch 326/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1329.4996 - mae: 1329.4996 - mse: 17593924.0000\n",
            "Epoch 326: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1386.7908 - mae: 1386.7908 - mse: 18675000.0000 - val_loss: 1723.4858 - val_mae: 1723.4858 - val_mse: 23160000.0000\n",
            "Epoch 327/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 524.0862 - mae: 524.0862 - mse: 5292045.0000\n",
            "Epoch 327: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1393.4574 - mae: 1393.4574 - mse: 18630216.0000 - val_loss: 1776.2678 - val_mae: 1776.2678 - val_mse: 23637392.0000\n",
            "Epoch 328/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 560.2787 - mae: 560.2787 - mse: 5104784.5000\n",
            "Epoch 328: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1420.3928 - mae: 1420.3928 - mse: 18630758.0000 - val_loss: 1669.1891 - val_mae: 1669.1891 - val_mse: 21770204.0000\n",
            "Epoch 329/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 598.7822 - mae: 598.7822 - mse: 5059285.5000\n",
            "Epoch 329: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1369.4016 - mae: 1369.4016 - mse: 18378096.0000 - val_loss: 1625.9114 - val_mae: 1625.9114 - val_mse: 22139358.0000\n",
            "Epoch 330/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 505.3497 - mae: 505.3497 - mse: 5262687.0000\n",
            "Epoch 330: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1384.3589 - mae: 1384.3589 - mse: 18643556.0000 - val_loss: 1614.5079 - val_mae: 1614.5079 - val_mse: 21723110.0000\n",
            "Epoch 331/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 507.7123 - mae: 507.7123 - mse: 5193466.0000\n",
            "Epoch 331: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1353.4514 - mae: 1353.4514 - mse: 18457964.0000 - val_loss: 1669.5286 - val_mae: 1669.5286 - val_mse: 22100362.0000\n",
            "Epoch 332/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1335.4200 - mae: 1335.4200 - mse: 17485098.0000\n",
            "Epoch 332: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1390.6169 - mae: 1390.6169 - mse: 18589044.0000 - val_loss: 1858.1427 - val_mae: 1858.1427 - val_mse: 21111138.0000\n",
            "Epoch 333/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1350.2764 - mae: 1350.2764 - mse: 17479056.0000\n",
            "Epoch 333: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1400.7611 - mae: 1400.7611 - mse: 18590462.0000 - val_loss: 1642.1077 - val_mae: 1642.1077 - val_mse: 21901492.0000\n",
            "Epoch 334/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1476.9028 - mae: 1476.9028 - mse: 18311554.0000\n",
            "Epoch 334: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1497.0468 - mae: 1497.0468 - mse: 18817212.0000 - val_loss: 1638.4167 - val_mae: 1638.4167 - val_mse: 21269910.0000\n",
            "Epoch 335/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1254.3311 - mae: 1254.3311 - mse: 16208354.0000\n",
            "Epoch 335: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1372.3551 - mae: 1372.3551 - mse: 18706162.0000 - val_loss: 1604.3098 - val_mae: 1604.3098 - val_mse: 21748686.0000\n",
            "Epoch 336/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1372.1674 - mae: 1372.1674 - mse: 17651840.0000\n",
            "Epoch 336: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1432.5601 - mae: 1432.5601 - mse: 18787542.0000 - val_loss: 1863.3964 - val_mae: 1863.3964 - val_mse: 23819426.0000\n",
            "Epoch 337/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 685.9174 - mae: 685.9174 - mse: 5516015.0000\n",
            "Epoch 337: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1568.5341 - mae: 1568.5341 - mse: 18930948.0000 - val_loss: 1955.6012 - val_mae: 1955.6012 - val_mse: 24033434.0000\n",
            "Epoch 338/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 835.5568 - mae: 835.5568 - mse: 5735815.0000\n",
            "Epoch 338: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1491.9918 - mae: 1491.9918 - mse: 19539856.0000 - val_loss: 1643.5342 - val_mae: 1643.5342 - val_mse: 21493650.0000\n",
            "Epoch 339/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 585.2885 - mae: 585.2885 - mse: 5024718.0000\n",
            "Epoch 339: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1614.7903 - mae: 1614.7903 - mse: 19587736.0000 - val_loss: 1610.3131 - val_mae: 1610.3131 - val_mse: 21297176.0000\n",
            "Epoch 340/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 549.9006 - mae: 549.9006 - mse: 5076137.5000\n",
            "Epoch 340: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1409.9113 - mae: 1409.9113 - mse: 18553650.0000 - val_loss: 1635.5430 - val_mae: 1635.5430 - val_mse: 21911178.0000\n",
            "Epoch 341/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1404.8411 - mae: 1404.8411 - mse: 18248758.0000\n",
            "Epoch 341: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1421.7388 - mae: 1421.7388 - mse: 18765004.0000 - val_loss: 1672.8831 - val_mae: 1672.8831 - val_mse: 21057070.0000\n",
            "Epoch 342/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1290.7474 - mae: 1290.7474 - mse: 16949050.0000\n",
            "Epoch 342: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1379.2559 - mae: 1379.2559 - mse: 18636260.0000 - val_loss: 1702.0380 - val_mae: 1702.0380 - val_mse: 22565128.0000\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1382.9160 - mae: 1382.9160 - mse: 18535670.0000\n",
            "Epoch 343: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1382.9160 - mae: 1382.9160 - mse: 18535670.0000 - val_loss: 1757.4352 - val_mae: 1757.4352 - val_mse: 21840380.0000\n",
            "Epoch 344/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1367.0643 - mae: 1367.0643 - mse: 18083570.0000\n",
            "Epoch 344: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1385.3604 - mae: 1385.3604 - mse: 18602840.0000 - val_loss: 1683.9410 - val_mae: 1683.9410 - val_mse: 22997420.0000\n",
            "Epoch 345/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 524.5028 - mae: 524.5028 - mse: 5262439.0000\n",
            "Epoch 345: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1398.6936 - mae: 1398.6936 - mse: 18407640.0000 - val_loss: 1612.3231 - val_mae: 1612.3231 - val_mse: 22374374.0000\n",
            "Epoch 346/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 483.9465 - mae: 483.9465 - mse: 5088121.5000\n",
            "Epoch 346: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1411.0408 - mae: 1411.0408 - mse: 18771864.0000 - val_loss: 1735.5485 - val_mae: 1735.5485 - val_mse: 21857386.0000\n",
            "Epoch 347/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1401.5259 - mae: 1401.5259 - mse: 18046646.0000\n",
            "Epoch 347: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1427.7037 - mae: 1427.7037 - mse: 18579266.0000 - val_loss: 1761.1488 - val_mae: 1761.1488 - val_mse: 21956348.0000\n",
            "Epoch 348/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1431.8047 - mae: 1431.8047 - mse: 17580216.0000\n",
            "Epoch 348: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1476.3956 - mae: 1476.3956 - mse: 18733210.0000 - val_loss: 1595.7421 - val_mae: 1595.7421 - val_mse: 22035348.0000\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1375.8541 - mae: 1375.8541 - mse: 18328212.0000\n",
            "Epoch 349: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1375.8541 - mae: 1375.8541 - mse: 18328212.0000 - val_loss: 1631.0096 - val_mae: 1631.0096 - val_mse: 22223374.0000\n",
            "Epoch 350/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1368.5343 - mae: 1368.5343 - mse: 18082276.0000\n",
            "Epoch 350: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1386.2108 - mae: 1386.2108 - mse: 18597014.0000 - val_loss: 1635.2257 - val_mae: 1635.2257 - val_mse: 22121248.0000\n",
            "Epoch 351/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1303.1611 - mae: 1303.1611 - mse: 17251704.0000\n",
            "Epoch 351: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1359.7253 - mae: 1359.7253 - mse: 18373284.0000 - val_loss: 1612.9521 - val_mae: 1612.9521 - val_mse: 21756912.0000\n",
            "Epoch 352/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1265.7976 - mae: 1265.7976 - mse: 17330260.0000\n",
            "Epoch 352: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1324.9934 - mae: 1324.9934 - mse: 18426480.0000 - val_loss: 1619.9440 - val_mae: 1619.9440 - val_mse: 22234628.0000\n",
            "Epoch 353/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1364.1001 - mae: 1364.1001 - mse: 18139486.0000\n",
            "Epoch 353: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1384.4626 - mae: 1384.4626 - mse: 18664098.0000 - val_loss: 1643.0911 - val_mae: 1643.0911 - val_mse: 21771474.0000\n",
            "Epoch 354/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 553.3365 - mae: 553.3365 - mse: 5245501.0000\n",
            "Epoch 354: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1357.5273 - mae: 1357.5273 - mse: 18487480.0000 - val_loss: 1700.8247 - val_mae: 1700.8247 - val_mse: 21257642.0000\n",
            "Epoch 355/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 690.8301 - mae: 690.8301 - mse: 5200400.5000\n",
            "Epoch 355: val_loss did not improve from 1555.26282\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1387.8563 - mae: 1387.8563 - mse: 18630414.0000 - val_loss: 1628.9142 - val_mae: 1628.9142 - val_mse: 21925664.0000\n",
            "Epoch 356/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1319.2517 - mae: 1319.2517 - mse: 18037456.0000\n",
            "Epoch 356: val_loss improved from 1555.26282 to 1553.27161, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1339.4034 - mae: 1339.4034 - mse: 18549602.0000 - val_loss: 1553.2716 - val_mae: 1553.2716 - val_mse: 21329380.0000\n",
            "Epoch 357/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1300.8293 - mae: 1300.8293 - mse: 17061064.0000\n",
            "Epoch 357: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1426.5027 - mae: 1426.5027 - mse: 18819388.0000 - val_loss: 2428.1018 - val_mae: 2428.1018 - val_mse: 30839792.0000\n",
            "Epoch 358/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1546.0753 - mae: 1546.0753 - mse: 18550886.0000\n",
            "Epoch 358: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1584.6624 - mae: 1584.6624 - mse: 19611238.0000 - val_loss: 1823.8621 - val_mae: 1823.8621 - val_mse: 22002960.0000\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1416.7806 - mae: 1416.7806 - mse: 18665138.0000\n",
            "Epoch 359: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1416.7806 - mae: 1416.7806 - mse: 18665138.0000 - val_loss: 1749.1376 - val_mae: 1749.1376 - val_mse: 21998722.0000\n",
            "Epoch 360/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1465.6608 - mae: 1465.6608 - mse: 18318944.0000\n",
            "Epoch 360: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1491.0531 - mae: 1491.0531 - mse: 18870368.0000 - val_loss: 1774.6029 - val_mae: 1774.6029 - val_mse: 23057640.0000\n",
            "Epoch 361/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1284.4657 - mae: 1284.4657 - mse: 16749183.0000\n",
            "Epoch 361: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1382.4187 - mae: 1382.4187 - mse: 18437538.0000 - val_loss: 1652.2239 - val_mae: 1652.2239 - val_mse: 22773326.0000\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1378.6870 - mae: 1378.6870 - mse: 18563746.0000\n",
            "Epoch 362: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1378.6870 - mae: 1378.6870 - mse: 18563746.0000 - val_loss: 1824.4197 - val_mae: 1824.4197 - val_mse: 22843024.0000\n",
            "Epoch 363/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1348.7356 - mae: 1348.7356 - mse: 17712094.0000\n",
            "Epoch 363: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1398.7032 - mae: 1398.7032 - mse: 18809298.0000 - val_loss: 1590.2728 - val_mae: 1590.2728 - val_mse: 21851176.0000\n",
            "Epoch 364/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1326.0165 - mae: 1326.0165 - mse: 18044982.0000\n",
            "Epoch 364: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1346.4197 - mae: 1346.4197 - mse: 18566994.0000 - val_loss: 1624.1161 - val_mae: 1624.1161 - val_mse: 22290198.0000\n",
            "Epoch 365/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1316.0991 - mae: 1316.0991 - mse: 17507280.0000\n",
            "Epoch 365: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1367.0260 - mae: 1367.0260 - mse: 18509240.0000 - val_loss: 1755.7590 - val_mae: 1755.7590 - val_mse: 22315894.0000\n",
            "Epoch 366/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1378.6798 - mae: 1378.6798 - mse: 17970872.0000\n",
            "Epoch 366: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1397.7391 - mae: 1397.7391 - mse: 18500100.0000 - val_loss: 1684.2264 - val_mae: 1684.2264 - val_mse: 22712062.0000\n",
            "Epoch 367/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1299.3904 - mae: 1299.3904 - mse: 17141506.0000\n",
            "Epoch 367: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1341.5574 - mae: 1341.5574 - mse: 18420786.0000 - val_loss: 1693.8624 - val_mae: 1693.8624 - val_mse: 23363462.0000\n",
            "Epoch 368/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1261.3164 - mae: 1261.3164 - mse: 16679233.0000\n",
            "Epoch 368: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1366.2396 - mae: 1366.2396 - mse: 18497590.0000 - val_loss: 1696.8267 - val_mae: 1696.8267 - val_mse: 22973176.0000\n",
            "Epoch 369/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1307.1095 - mae: 1307.1095 - mse: 16184094.0000\n",
            "Epoch 369: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1440.3966 - mae: 1440.3966 - mse: 18802632.0000 - val_loss: 1899.2860 - val_mae: 1899.2860 - val_mse: 21315812.0000\n",
            "Epoch 370/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1330.7013 - mae: 1330.7013 - mse: 16037780.0000\n",
            "Epoch 370: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1405.3921 - mae: 1405.3921 - mse: 18368008.0000 - val_loss: 1796.4977 - val_mae: 1796.4977 - val_mse: 23659584.0000\n",
            "Epoch 371/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1404.5436 - mae: 1404.5436 - mse: 17868088.0000\n",
            "Epoch 371: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1437.5027 - mae: 1437.5027 - mse: 18986088.0000 - val_loss: 1625.0148 - val_mae: 1625.0148 - val_mse: 21799854.0000\n",
            "Epoch 372/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1351.5995 - mae: 1351.5995 - mse: 17365654.0000\n",
            "Epoch 372: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1404.4769 - mae: 1404.4769 - mse: 18477758.0000 - val_loss: 1665.3826 - val_mae: 1665.3826 - val_mse: 22196616.0000\n",
            "Epoch 373/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1402.8849 - mae: 1402.8849 - mse: 18058612.0000\n",
            "Epoch 373: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1422.1733 - mae: 1422.1733 - mse: 18579044.0000 - val_loss: 1676.0457 - val_mae: 1676.0457 - val_mse: 23290620.0000\n",
            "Epoch 374/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1374.8219 - mae: 1374.8219 - mse: 17473342.0000\n",
            "Epoch 374: val_loss did not improve from 1553.27161\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1429.5990 - mae: 1429.5990 - mse: 18581000.0000 - val_loss: 1750.1753 - val_mae: 1750.1753 - val_mse: 23383796.0000\n",
            "Epoch 375/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1360.0228 - mae: 1360.0228 - mse: 17533368.0000\n",
            "Epoch 375: val_loss improved from 1553.27161 to 1552.87793, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1404.3224 - mae: 1404.3224 - mse: 18561528.0000 - val_loss: 1552.8779 - val_mae: 1552.8779 - val_mse: 21355276.0000\n",
            "Epoch 376/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1331.8939 - mae: 1331.8939 - mse: 17955320.0000\n",
            "Epoch 376: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1352.6625 - mae: 1352.6625 - mse: 18470844.0000 - val_loss: 1738.4069 - val_mae: 1738.4069 - val_mse: 23479532.0000\n",
            "Epoch 377/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 563.5483 - mae: 563.5483 - mse: 5085457.0000\n",
            "Epoch 377: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1405.1125 - mae: 1405.1125 - mse: 19277296.0000 - val_loss: 1662.3098 - val_mae: 1662.3098 - val_mse: 22667912.0000\n",
            "Epoch 378/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1301.1812 - mae: 1301.1812 - mse: 17321446.0000\n",
            "Epoch 378: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1358.5582 - mae: 1358.5582 - mse: 18403366.0000 - val_loss: 1692.2145 - val_mae: 1692.2145 - val_mse: 22739994.0000\n",
            "Epoch 379/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1377.9510 - mae: 1377.9510 - mse: 17771504.0000\n",
            "Epoch 379: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1395.3673 - mae: 1395.3673 - mse: 18300934.0000 - val_loss: 1689.8315 - val_mae: 1689.8315 - val_mse: 22332170.0000\n",
            "Epoch 380/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1274.0990 - mae: 1274.0990 - mse: 17160486.0000\n",
            "Epoch 380: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1336.3616 - mae: 1336.3616 - mse: 18342226.0000 - val_loss: 1661.1406 - val_mae: 1661.1406 - val_mse: 22735544.0000\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1341.1647 - mae: 1341.1647 - mse: 18337204.0000\n",
            "Epoch 381: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1341.1647 - mae: 1341.1647 - mse: 18337204.0000 - val_loss: 1633.4214 - val_mae: 1633.4214 - val_mse: 22000802.0000\n",
            "Epoch 382/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1385.2911 - mae: 1385.2911 - mse: 17904170.0000\n",
            "Epoch 382: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1444.0593 - mae: 1444.0593 - mse: 18981354.0000 - val_loss: 1682.3907 - val_mae: 1682.3907 - val_mse: 21000030.0000\n",
            "Epoch 383/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1381.1711 - mae: 1381.1711 - mse: 17991644.0000\n",
            "Epoch 383: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1400.7450 - mae: 1400.7450 - mse: 18511356.0000 - val_loss: 1807.6046 - val_mae: 1807.6046 - val_mse: 21849562.0000\n",
            "Epoch 384/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 740.0716 - mae: 740.0716 - mse: 5070791.0000\n",
            "Epoch 384: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1458.8550 - mae: 1458.8550 - mse: 18640876.0000 - val_loss: 1570.1837 - val_mae: 1570.1837 - val_mse: 20672320.0000\n",
            "Epoch 385/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1338.8190 - mae: 1338.8190 - mse: 18109128.0000\n",
            "Epoch 385: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1358.2609 - mae: 1358.2609 - mse: 18625398.0000 - val_loss: 1691.4390 - val_mae: 1691.4390 - val_mse: 23710840.0000\n",
            "Epoch 386/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1323.7667 - mae: 1323.7667 - mse: 17254284.0000\n",
            "Epoch 386: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1383.6915 - mae: 1383.6915 - mse: 18383070.0000 - val_loss: 1835.9980 - val_mae: 1835.9980 - val_mse: 21154138.0000\n",
            "Epoch 387/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1350.0157 - mae: 1350.0157 - mse: 17256166.0000\n",
            "Epoch 387: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1402.1635 - mae: 1402.1635 - mse: 18380114.0000 - val_loss: 1649.7534 - val_mae: 1649.7534 - val_mse: 22620790.0000\n",
            "Epoch 388/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1324.2836 - mae: 1324.2836 - mse: 16781314.0000\n",
            "Epoch 388: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1416.1130 - mae: 1416.1130 - mse: 18552316.0000 - val_loss: 1675.4329 - val_mae: 1675.4329 - val_mse: 22730376.0000\n",
            "Epoch 389/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1313.2250 - mae: 1313.2250 - mse: 16455069.0000\n",
            "Epoch 389: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1414.9618 - mae: 1414.9618 - mse: 18714616.0000 - val_loss: 1718.3453 - val_mae: 1718.3453 - val_mse: 23755832.0000\n",
            "Epoch 390/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1504.0806 - mae: 1504.0806 - mse: 18482856.0000\n",
            "Epoch 390: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1557.0493 - mae: 1557.0493 - mse: 19549500.0000 - val_loss: 1756.1212 - val_mae: 1756.1212 - val_mse: 21406194.0000\n",
            "Epoch 391/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 818.1974 - mae: 818.1974 - mse: 5613926.0000\n",
            "Epoch 391: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1361.4984 - mae: 1361.4984 - mse: 18565228.0000 - val_loss: 1698.5930 - val_mae: 1698.5930 - val_mse: 23138068.0000\n",
            "Epoch 392/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1291.9803 - mae: 1291.9803 - mse: 17461494.0000\n",
            "Epoch 392: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1342.2219 - mae: 1342.2219 - mse: 18597564.0000 - val_loss: 1648.3350 - val_mae: 1648.3350 - val_mse: 22440884.0000\n",
            "Epoch 393/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1284.3846 - mae: 1284.3846 - mse: 17300664.0000\n",
            "Epoch 393: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1340.6144 - mae: 1340.6144 - mse: 18441694.0000 - val_loss: 1828.6996 - val_mae: 1828.6996 - val_mse: 25315308.0000\n",
            "Epoch 394/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1556.4028 - mae: 1556.4028 - mse: 18810790.0000\n",
            "Epoch 394: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1654.3702 - mae: 1654.3702 - mse: 21169498.0000 - val_loss: 2096.2888 - val_mae: 2096.2888 - val_mse: 26155784.0000\n",
            "Epoch 395/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1530.0792 - mae: 1530.0792 - mse: 18606544.0000\n",
            "Epoch 395: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1537.6130 - mae: 1537.6130 - mse: 19255360.0000 - val_loss: 1609.4072 - val_mae: 1609.4072 - val_mse: 21651598.0000\n",
            "Epoch 396/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1395.9855 - mae: 1395.9855 - mse: 17647854.0000\n",
            "Epoch 396: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1449.7278 - mae: 1449.7278 - mse: 18675984.0000 - val_loss: 1658.4004 - val_mae: 1658.4004 - val_mse: 22523442.0000\n",
            "Epoch 397/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1321.1411 - mae: 1321.1411 - mse: 17512008.0000\n",
            "Epoch 397: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1372.3730 - mae: 1372.3730 - mse: 18602492.0000 - val_loss: 1679.4868 - val_mae: 1679.4868 - val_mse: 22458344.0000\n",
            "Epoch 398/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1294.3015 - mae: 1294.3015 - mse: 17497198.0000\n",
            "Epoch 398: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1345.5573 - mae: 1345.5573 - mse: 18526662.0000 - val_loss: 1587.2948 - val_mae: 1587.2948 - val_mse: 21594206.0000\n",
            "Epoch 399/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1433.7462 - mae: 1433.7462 - mse: 17913702.0000\n",
            "Epoch 399: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1444.8604 - mae: 1444.8604 - mse: 18644936.0000 - val_loss: 1656.9075 - val_mae: 1656.9075 - val_mse: 23159026.0000\n",
            "Epoch 400/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 479.2088 - mae: 479.2088 - mse: 5116690.0000\n",
            "Epoch 400: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1341.8961 - mae: 1341.8961 - mse: 18540718.0000 - val_loss: 1726.3636 - val_mae: 1726.3636 - val_mse: 23616066.0000\n",
            "Epoch 401/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1384.3153 - mae: 1384.3153 - mse: 18127212.0000\n",
            "Epoch 401: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1402.6743 - mae: 1402.6743 - mse: 18658498.0000 - val_loss: 1678.3622 - val_mae: 1678.3622 - val_mse: 22899898.0000\n",
            "Epoch 402/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1401.8806 - mae: 1401.8806 - mse: 17608376.0000\n",
            "Epoch 402: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1452.8495 - mae: 1452.8495 - mse: 18705554.0000 - val_loss: 1610.5809 - val_mae: 1610.5809 - val_mse: 22108658.0000\n",
            "Epoch 403/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1332.4210 - mae: 1332.4210 - mse: 17815444.0000\n",
            "Epoch 403: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1358.3406 - mae: 1358.3406 - mse: 18338314.0000 - val_loss: 1715.6827 - val_mae: 1715.6827 - val_mse: 21827216.0000\n",
            "Epoch 404/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 644.1360 - mae: 644.1360 - mse: 5014908.0000\n",
            "Epoch 404: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1369.4469 - mae: 1369.4469 - mse: 18406060.0000 - val_loss: 1607.3480 - val_mae: 1607.3480 - val_mse: 22030168.0000\n",
            "Epoch 405/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1307.3345 - mae: 1307.3345 - mse: 17790078.0000\n",
            "Epoch 405: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1330.6522 - mae: 1330.6522 - mse: 18316456.0000 - val_loss: 1758.3418 - val_mae: 1758.3418 - val_mse: 21305982.0000\n",
            "Epoch 406/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1306.3684 - mae: 1306.3684 - mse: 16083963.0000\n",
            "Epoch 406: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1412.6320 - mae: 1412.6320 - mse: 18425080.0000 - val_loss: 1791.6290 - val_mae: 1791.6290 - val_mse: 21241120.0000\n",
            "Epoch 407/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1301.4624 - mae: 1301.4624 - mse: 17348890.0000\n",
            "Epoch 407: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1349.5009 - mae: 1349.5009 - mse: 18363278.0000 - val_loss: 1692.6152 - val_mae: 1692.6152 - val_mse: 22204018.0000\n",
            "Epoch 408/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1312.4961 - mae: 1312.4961 - mse: 17357148.0000\n",
            "Epoch 408: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1340.7540 - mae: 1340.7540 - mse: 18448224.0000 - val_loss: 1575.7103 - val_mae: 1575.7103 - val_mse: 21772828.0000\n",
            "Epoch 409/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1368.5764 - mae: 1368.5764 - mse: 18070796.0000\n",
            "Epoch 409: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1387.1154 - mae: 1387.1154 - mse: 18590408.0000 - val_loss: 1669.9402 - val_mae: 1669.9402 - val_mse: 22154630.0000\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1407.7145 - mae: 1407.7145 - mse: 18518792.0000\n",
            "Epoch 410: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1407.7145 - mae: 1407.7145 - mse: 18518792.0000 - val_loss: 1653.2699 - val_mae: 1653.2699 - val_mse: 21873322.0000\n",
            "Epoch 411/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1283.7721 - mae: 1283.7721 - mse: 17109328.0000\n",
            "Epoch 411: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1338.3624 - mae: 1338.3624 - mse: 18291290.0000 - val_loss: 1754.8424 - val_mae: 1754.8424 - val_mse: 24189428.0000\n",
            "Epoch 412/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1392.2753 - mae: 1392.2753 - mse: 16456618.0000\n",
            "Epoch 412: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1436.1055 - mae: 1436.1055 - mse: 18547060.0000 - val_loss: 1604.8698 - val_mae: 1604.8698 - val_mse: 21399106.0000\n",
            "Epoch 413/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1299.0480 - mae: 1299.0480 - mse: 15492261.0000\n",
            "Epoch 413: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1431.8289 - mae: 1431.8289 - mse: 18545924.0000 - val_loss: 1762.7896 - val_mae: 1762.7896 - val_mse: 23710524.0000\n",
            "Epoch 414/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1359.0039 - mae: 1359.0039 - mse: 17304596.0000\n",
            "Epoch 414: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1401.6329 - mae: 1401.6329 - mse: 18217764.0000 - val_loss: 1708.4626 - val_mae: 1708.4626 - val_mse: 24190858.0000\n",
            "Epoch 415/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1401.9714 - mae: 1401.9714 - mse: 18307804.0000\n",
            "Epoch 415: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1422.1891 - mae: 1422.1891 - mse: 18822196.0000 - val_loss: 1640.9644 - val_mae: 1640.9644 - val_mse: 22031082.0000\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1389.7740 - mae: 1389.7740 - mse: 18375732.0000\n",
            "Epoch 416: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1389.7740 - mae: 1389.7740 - mse: 18375732.0000 - val_loss: 1688.8055 - val_mae: 1688.8055 - val_mse: 23618390.0000\n",
            "Epoch 417/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1291.5885 - mae: 1291.5885 - mse: 17284642.0000\n",
            "Epoch 417: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1342.4723 - mae: 1342.4723 - mse: 18439770.0000 - val_loss: 1647.7163 - val_mae: 1647.7163 - val_mse: 22728106.0000\n",
            "Epoch 418/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1330.4532 - mae: 1330.4532 - mse: 17754464.0000\n",
            "Epoch 418: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1364.8555 - mae: 1364.8555 - mse: 18907542.0000 - val_loss: 1646.3462 - val_mae: 1646.3462 - val_mse: 22290264.0000\n",
            "Epoch 419/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1229.8210 - mae: 1229.8210 - mse: 16487534.0000\n",
            "Epoch 419: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1324.1854 - mae: 1324.1854 - mse: 18253030.0000 - val_loss: 1648.5426 - val_mae: 1648.5426 - val_mse: 22606164.0000\n",
            "Epoch 420/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1424.7928 - mae: 1424.7928 - mse: 18980980.0000\n",
            "Epoch 420: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1443.1698 - mae: 1443.1698 - mse: 19485468.0000 - val_loss: 1656.2986 - val_mae: 1656.2986 - val_mse: 23209170.0000\n",
            "Epoch 421/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1370.0221 - mae: 1370.0221 - mse: 17487134.0000\n",
            "Epoch 421: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1426.6882 - mae: 1426.6882 - mse: 18622956.0000 - val_loss: 1630.8380 - val_mae: 1630.8380 - val_mse: 22115978.0000\n",
            "Epoch 422/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1341.9319 - mae: 1341.9319 - mse: 17459218.0000\n",
            "Epoch 422: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1388.7119 - mae: 1388.7119 - mse: 18509462.0000 - val_loss: 1668.9935 - val_mae: 1668.9935 - val_mse: 23016376.0000\n",
            "Epoch 423/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1312.8679 - mae: 1312.8679 - mse: 17529892.0000\n",
            "Epoch 423: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1370.3770 - mae: 1370.3770 - mse: 18617438.0000 - val_loss: 1931.4558 - val_mae: 1931.4558 - val_mse: 22967536.0000\n",
            "Epoch 424/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1422.2672 - mae: 1422.2672 - mse: 16658816.0000\n",
            "Epoch 424: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1528.6952 - mae: 1528.6952 - mse: 19025954.0000 - val_loss: 1899.7025 - val_mae: 1899.7025 - val_mse: 23674426.0000\n",
            "Epoch 425/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1540.5856 - mae: 1540.5856 - mse: 17906686.0000\n",
            "Epoch 425: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1539.0288 - mae: 1539.0288 - mse: 18858458.0000 - val_loss: 1714.3676 - val_mae: 1714.3676 - val_mse: 21727306.0000\n",
            "Epoch 426/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1384.2942 - mae: 1384.2942 - mse: 17412244.0000\n",
            "Epoch 426: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1442.9742 - mae: 1442.9742 - mse: 18459742.0000 - val_loss: 1708.5342 - val_mae: 1708.5342 - val_mse: 22626756.0000\n",
            "Epoch 427/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1362.7480 - mae: 1362.7480 - mse: 17473126.0000\n",
            "Epoch 427: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1408.4020 - mae: 1408.4020 - mse: 18641016.0000 - val_loss: 1590.2065 - val_mae: 1590.2065 - val_mse: 21772572.0000\n",
            "Epoch 428/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1334.4983 - mae: 1334.4983 - mse: 17878276.0000\n",
            "Epoch 428: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1357.6511 - mae: 1357.6511 - mse: 18403428.0000 - val_loss: 1600.3879 - val_mae: 1600.3879 - val_mse: 22067240.0000\n",
            "Epoch 429/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1385.6226 - mae: 1385.6226 - mse: 17884846.0000\n",
            "Epoch 429: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1405.6387 - mae: 1405.6387 - mse: 18413582.0000 - val_loss: 1628.9226 - val_mae: 1628.9226 - val_mse: 22346682.0000\n",
            "Epoch 430/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 548.9435 - mae: 548.9435 - mse: 5295142.0000\n",
            "Epoch 430: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1392.6838 - mae: 1392.6838 - mse: 18437608.0000 - val_loss: 1631.4714 - val_mae: 1631.4714 - val_mse: 22462222.0000\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1341.3640 - mae: 1341.3640 - mse: 18336194.0000\n",
            "Epoch 431: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1341.3640 - mae: 1341.3640 - mse: 18336194.0000 - val_loss: 1666.1296 - val_mae: 1666.1296 - val_mse: 22893010.0000\n",
            "Epoch 432/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1287.4653 - mae: 1287.4653 - mse: 17551818.0000\n",
            "Epoch 432: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1323.9569 - mae: 1323.9569 - mse: 18418188.0000 - val_loss: 1575.6945 - val_mae: 1575.6945 - val_mse: 21926408.0000\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1321.6169 - mae: 1321.6169 - mse: 18288972.0000\n",
            "Epoch 433: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1321.6169 - mae: 1321.6169 - mse: 18288972.0000 - val_loss: 1619.2502 - val_mae: 1619.2502 - val_mse: 22217090.0000\n",
            "Epoch 434/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1252.3231 - mae: 1252.3231 - mse: 17226964.0000\n",
            "Epoch 434: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1317.1779 - mae: 1317.1779 - mse: 18365572.0000 - val_loss: 1651.9340 - val_mae: 1651.9340 - val_mse: 22583554.0000\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1394.3661 - mae: 1394.3661 - mse: 18510030.0000\n",
            "Epoch 435: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1394.3661 - mae: 1394.3661 - mse: 18510030.0000 - val_loss: 1559.8046 - val_mae: 1559.8046 - val_mse: 22001330.0000\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1330.6481 - mae: 1330.6481 - mse: 18435646.0000\n",
            "Epoch 436: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1330.6481 - mae: 1330.6481 - mse: 18435646.0000 - val_loss: 1677.0873 - val_mae: 1677.0873 - val_mse: 21315194.0000\n",
            "Epoch 437/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1312.1522 - mae: 1312.1522 - mse: 17891064.0000\n",
            "Epoch 437: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1335.1821 - mae: 1335.1821 - mse: 18416882.0000 - val_loss: 1667.6141 - val_mae: 1667.6141 - val_mse: 21333476.0000\n",
            "Epoch 438/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 639.7910 - mae: 639.7910 - mse: 5092726.5000\n",
            "Epoch 438: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1369.5262 - mae: 1369.5262 - mse: 18365260.0000 - val_loss: 1651.9772 - val_mae: 1651.9772 - val_mse: 22622806.0000\n",
            "Epoch 439/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1373.0670 - mae: 1373.0670 - mse: 17341258.0000\n",
            "Epoch 439: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1431.3771 - mae: 1431.3771 - mse: 18458614.0000 - val_loss: 1873.7878 - val_mae: 1873.7878 - val_mse: 22943840.0000\n",
            "Epoch 440/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1383.9537 - mae: 1383.9537 - mse: 17836682.0000\n",
            "Epoch 440: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1403.0325 - mae: 1403.0325 - mse: 18372328.0000 - val_loss: 1618.5616 - val_mae: 1618.5616 - val_mse: 21472634.0000\n",
            "Epoch 441/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1343.4835 - mae: 1343.4835 - mse: 17279970.0000\n",
            "Epoch 441: val_loss did not improve from 1552.87793\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1404.8767 - mae: 1404.8767 - mse: 18486232.0000 - val_loss: 1725.2773 - val_mae: 1725.2773 - val_mse: 22202004.0000\n",
            "Epoch 442/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1347.7897 - mae: 1347.7897 - mse: 17826992.0000\n",
            "Epoch 442: val_loss improved from 1552.87793 to 1542.49731, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 1367.3911 - mae: 1367.3911 - mse: 18581928.0000 - val_loss: 1542.4973 - val_mae: 1542.4973 - val_mse: 21528530.0000\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1308.3262 - mae: 1308.3262 - mse: 18264486.0000\n",
            "Epoch 443: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1308.3262 - mae: 1308.3262 - mse: 18264486.0000 - val_loss: 1632.5568 - val_mae: 1632.5568 - val_mse: 22292600.0000\n",
            "Epoch 444/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1309.3099 - mae: 1309.3099 - mse: 17894972.0000\n",
            "Epoch 444: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1330.3867 - mae: 1330.3867 - mse: 18420140.0000 - val_loss: 1665.3351 - val_mae: 1665.3351 - val_mse: 22901368.0000\n",
            "Epoch 445/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1284.1235 - mae: 1284.1235 - mse: 17775130.0000\n",
            "Epoch 445: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1306.8945 - mae: 1306.8945 - mse: 18300986.0000 - val_loss: 1618.0809 - val_mae: 1618.0809 - val_mse: 22475016.0000\n",
            "Epoch 446/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1257.6680 - mae: 1257.6680 - mse: 17050580.0000\n",
            "Epoch 446: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1317.3217 - mae: 1317.3217 - mse: 18207446.0000 - val_loss: 1673.6215 - val_mae: 1673.6215 - val_mse: 23116046.0000\n",
            "Epoch 447/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1292.9596 - mae: 1292.9596 - mse: 16227224.0000\n",
            "Epoch 447: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1367.4264 - mae: 1367.4264 - mse: 18322250.0000 - val_loss: 1730.9058 - val_mae: 1730.9058 - val_mse: 24290646.0000\n",
            "Epoch 448/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1313.8954 - mae: 1313.8954 - mse: 16702077.0000\n",
            "Epoch 448: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1406.0447 - mae: 1406.0447 - mse: 18506932.0000 - val_loss: 1755.0292 - val_mae: 1755.0292 - val_mse: 21971374.0000\n",
            "Epoch 449/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1228.0359 - mae: 1228.0359 - mse: 15716294.0000\n",
            "Epoch 449: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1347.0508 - mae: 1347.0508 - mse: 18414606.0000 - val_loss: 1685.3090 - val_mae: 1685.3090 - val_mse: 22730402.0000\n",
            "Epoch 450/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1314.5267 - mae: 1314.5267 - mse: 17602918.0000\n",
            "Epoch 450: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1360.2915 - mae: 1360.2915 - mse: 18603756.0000 - val_loss: 1620.8931 - val_mae: 1620.8931 - val_mse: 22960746.0000\n",
            "Epoch 451/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1362.6993 - mae: 1362.6993 - mse: 18075160.0000\n",
            "Epoch 451: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1389.0719 - mae: 1389.0719 - mse: 18615430.0000 - val_loss: 2122.5251 - val_mae: 2122.5251 - val_mse: 29769726.0000\n",
            "Epoch 452/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1440.0667 - mae: 1440.0667 - mse: 17311014.0000\n",
            "Epoch 452: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1483.1907 - mae: 1483.1907 - mse: 19265814.0000 - val_loss: 1671.0333 - val_mae: 1671.0333 - val_mse: 22511078.0000\n",
            "Epoch 453/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1291.2167 - mae: 1291.2167 - mse: 17560070.0000\n",
            "Epoch 453: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1326.5520 - mae: 1326.5520 - mse: 18432124.0000 - val_loss: 1623.1390 - val_mae: 1623.1390 - val_mse: 23205912.0000\n",
            "Epoch 454/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1278.2794 - mae: 1278.2794 - mse: 17303966.0000\n",
            "Epoch 454: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1327.5950 - mae: 1327.5950 - mse: 18353842.0000 - val_loss: 1582.3772 - val_mae: 1582.3772 - val_mse: 22158652.0000\n",
            "Epoch 455/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1290.9648 - mae: 1290.9648 - mse: 17238124.0000\n",
            "Epoch 455: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1334.1400 - mae: 1334.1400 - mse: 18339928.0000 - val_loss: 1684.6238 - val_mae: 1684.6238 - val_mse: 23399884.0000\n",
            "Epoch 456/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1298.6246 - mae: 1298.6246 - mse: 17436514.0000\n",
            "Epoch 456: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1355.9664 - mae: 1355.9664 - mse: 18510362.0000 - val_loss: 1581.8215 - val_mae: 1581.8215 - val_mse: 22019070.0000\n",
            "Epoch 457/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1303.5640 - mae: 1303.5640 - mse: 17332484.0000\n",
            "Epoch 457: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1341.7056 - mae: 1341.7056 - mse: 18460770.0000 - val_loss: 1626.6880 - val_mae: 1626.6880 - val_mse: 22193054.0000\n",
            "Epoch 458/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1307.1072 - mae: 1307.1072 - mse: 17880456.0000\n",
            "Epoch 458: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1326.3765 - mae: 1326.3765 - mse: 18404302.0000 - val_loss: 1577.8529 - val_mae: 1577.8529 - val_mse: 22333364.0000\n",
            "Epoch 459/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1261.1819 - mae: 1261.1819 - mse: 16969142.0000\n",
            "Epoch 459: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1308.0128 - mae: 1308.0128 - mse: 18189698.0000 - val_loss: 1667.5155 - val_mae: 1667.5155 - val_mse: 23265486.0000\n",
            "Epoch 460/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1257.3824 - mae: 1257.3824 - mse: 16502614.0000\n",
            "Epoch 460: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1360.9529 - mae: 1360.9529 - mse: 18327074.0000 - val_loss: 1813.3365 - val_mae: 1813.3365 - val_mse: 22478008.0000\n",
            "Epoch 461/500\n",
            "10/27 [==========>...................] - ETA: 0s - loss: 1221.3962 - mae: 1221.3962 - mse: 14563603.0000\n",
            "Epoch 461: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1406.7902 - mae: 1406.7902 - mse: 18740634.0000 - val_loss: 1714.1613 - val_mae: 1714.1613 - val_mse: 21910902.0000\n",
            "Epoch 462/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1377.1748 - mae: 1377.1748 - mse: 16350192.0000\n",
            "Epoch 462: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1483.5908 - mae: 1483.5908 - mse: 19166576.0000 - val_loss: 1747.9093 - val_mae: 1747.9093 - val_mse: 21574958.0000\n",
            "Epoch 463/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1323.1974 - mae: 1323.1974 - mse: 17382680.0000\n",
            "Epoch 463: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1375.6337 - mae: 1375.6337 - mse: 18527970.0000 - val_loss: 1619.8425 - val_mae: 1619.8425 - val_mse: 21791426.0000\n",
            "Epoch 464/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1323.3654 - mae: 1323.3654 - mse: 17543316.0000\n",
            "Epoch 464: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1409.1511 - mae: 1409.1511 - mse: 19159474.0000 - val_loss: 1686.3176 - val_mae: 1686.3176 - val_mse: 23004304.0000\n",
            "Epoch 465/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1344.4792 - mae: 1344.4792 - mse: 17268866.0000\n",
            "Epoch 465: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1379.5038 - mae: 1379.5038 - mse: 18358908.0000 - val_loss: 1718.2866 - val_mae: 1718.2866 - val_mse: 22840744.0000\n",
            "Epoch 466/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1310.6094 - mae: 1310.6094 - mse: 15838043.0000\n",
            "Epoch 466: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1470.9668 - mae: 1470.9668 - mse: 18928580.0000 - val_loss: 1658.3431 - val_mae: 1658.3431 - val_mse: 21981522.0000\n",
            "Epoch 467/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1253.5704 - mae: 1253.5704 - mse: 15466212.0000\n",
            "Epoch 467: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1387.6599 - mae: 1387.6599 - mse: 18550736.0000 - val_loss: 1706.1011 - val_mae: 1706.1011 - val_mse: 22813010.0000\n",
            "Epoch 468/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1275.0994 - mae: 1275.0994 - mse: 16117860.0000\n",
            "Epoch 468: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1440.0947 - mae: 1440.0947 - mse: 18753124.0000 - val_loss: 1800.5157 - val_mae: 1800.5157 - val_mse: 22899952.0000\n",
            "Epoch 469/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1362.2523 - mae: 1362.2523 - mse: 17666930.0000\n",
            "Epoch 469: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1416.3452 - mae: 1416.3452 - mse: 18751918.0000 - val_loss: 1717.3118 - val_mae: 1717.3118 - val_mse: 23827110.0000\n",
            "Epoch 470/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1313.7366 - mae: 1313.7366 - mse: 17470548.0000\n",
            "Epoch 470: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1346.3328 - mae: 1346.3328 - mse: 18604466.0000 - val_loss: 1618.5746 - val_mae: 1618.5746 - val_mse: 22050214.0000\n",
            "Epoch 471/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1237.0186 - mae: 1237.0186 - mse: 16081469.0000\n",
            "Epoch 471: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1321.0853 - mae: 1321.0853 - mse: 18258754.0000 - val_loss: 1702.1259 - val_mae: 1702.1259 - val_mse: 22910926.0000\n",
            "Epoch 472/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1312.0569 - mae: 1312.0569 - mse: 18125420.0000\n",
            "Epoch 472: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1332.4122 - mae: 1332.4122 - mse: 18643766.0000 - val_loss: 1583.8110 - val_mae: 1583.8110 - val_mse: 22223712.0000\n",
            "Epoch 473/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1361.1373 - mae: 1361.1373 - mse: 18035380.0000\n",
            "Epoch 473: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1382.9025 - mae: 1382.9025 - mse: 18569282.0000 - val_loss: 1585.1578 - val_mae: 1585.1578 - val_mse: 21998760.0000\n",
            "Epoch 474/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1362.8564 - mae: 1362.8564 - mse: 17324666.0000\n",
            "Epoch 474: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1413.0149 - mae: 1413.0149 - mse: 18442756.0000 - val_loss: 1647.5835 - val_mae: 1647.5835 - val_mse: 22550702.0000\n",
            "Epoch 475/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1304.3931 - mae: 1304.3931 - mse: 17371618.0000\n",
            "Epoch 475: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1353.4983 - mae: 1353.4983 - mse: 18412874.0000 - val_loss: 1696.5647 - val_mae: 1696.5647 - val_mse: 22565758.0000\n",
            "Epoch 476/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1320.9082 - mae: 1320.9082 - mse: 17247444.0000\n",
            "Epoch 476: val_loss did not improve from 1542.49731\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1374.9362 - mae: 1374.9362 - mse: 18327446.0000 - val_loss: 1627.9124 - val_mae: 1627.9124 - val_mse: 22202534.0000\n",
            "Epoch 477/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 523.6407 - mae: 523.6407 - mse: 5129384.0000\n",
            "Epoch 477: val_loss improved from 1542.49731 to 1524.88074, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1376.0275 - mae: 1376.0275 - mse: 18399084.0000 - val_loss: 1524.8807 - val_mae: 1524.8805 - val_mse: 21918612.0000\n",
            "Epoch 478/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 478.1836 - mae: 478.1836 - mse: 5179229.5000\n",
            "Epoch 478: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1332.1976 - mae: 1332.1976 - mse: 18367326.0000 - val_loss: 1719.8094 - val_mae: 1719.8094 - val_mse: 21174610.0000\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1504.5070 - mae: 1504.5070 - mse: 18782602.0000\n",
            "Epoch 479: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1504.5070 - mae: 1504.5070 - mse: 18782602.0000 - val_loss: 1939.5598 - val_mae: 1939.5598 - val_mse: 23738062.0000\n",
            "Epoch 480/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1379.5110 - mae: 1379.5110 - mse: 17984076.0000\n",
            "Epoch 480: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1398.1337 - mae: 1398.1337 - mse: 18511804.0000 - val_loss: 1643.4407 - val_mae: 1643.4407 - val_mse: 23420872.0000\n",
            "Epoch 481/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 495.9971 - mae: 495.9971 - mse: 5156708.0000\n",
            "Epoch 481: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1342.9664 - mae: 1342.9664 - mse: 18403776.0000 - val_loss: 1658.3271 - val_mae: 1658.3271 - val_mse: 22768876.0000\n",
            "Epoch 482/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 532.6914 - mae: 532.6914 - mse: 5304975.0000\n",
            "Epoch 482: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1471.9000 - mae: 1471.9000 - mse: 19302110.0000 - val_loss: 1823.9926 - val_mae: 1823.9926 - val_mse: 21961836.0000\n",
            "Epoch 483/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1374.9620 - mae: 1374.9620 - mse: 17989962.0000\n",
            "Epoch 483: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1400.3346 - mae: 1400.3346 - mse: 18523926.0000 - val_loss: 1722.7235 - val_mae: 1722.7235 - val_mse: 22230580.0000\n",
            "Epoch 484/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1321.8777 - mae: 1321.8777 - mse: 17358008.0000\n",
            "Epoch 484: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1375.1587 - mae: 1375.1587 - mse: 18453346.0000 - val_loss: 1647.8959 - val_mae: 1647.8959 - val_mse: 21579778.0000\n",
            "Epoch 485/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1324.8782 - mae: 1324.8782 - mse: 17895616.0000\n",
            "Epoch 485: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1346.1379 - mae: 1346.1379 - mse: 18424988.0000 - val_loss: 1841.3572 - val_mae: 1841.3572 - val_mse: 24223014.0000\n",
            "Epoch 486/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1430.9377 - mae: 1430.9377 - mse: 18094988.0000\n",
            "Epoch 486: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1450.6396 - mae: 1450.6396 - mse: 18628198.0000 - val_loss: 1828.3562 - val_mae: 1828.3562 - val_mse: 24099536.0000\n",
            "Epoch 487/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 636.1572 - mae: 636.1572 - mse: 5424274.0000\n",
            "Epoch 487: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1353.7961 - mae: 1353.7961 - mse: 18541108.0000 - val_loss: 1691.9159 - val_mae: 1691.9159 - val_mse: 23277250.0000\n",
            "Epoch 488/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 500.1738 - mae: 500.1738 - mse: 5177226.0000\n",
            "Epoch 488: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1313.9332 - mae: 1313.9332 - mse: 18318120.0000 - val_loss: 1644.5221 - val_mae: 1644.5221 - val_mse: 22480632.0000\n",
            "Epoch 489/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1399.3184 - mae: 1399.3184 - mse: 17987302.0000\n",
            "Epoch 489: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1418.2281 - mae: 1418.2281 - mse: 18506360.0000 - val_loss: 1683.5277 - val_mae: 1683.5277 - val_mse: 23168296.0000\n",
            "Epoch 490/500\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 546.2145 - mae: 546.2145 - mse: 5318581.0000\n",
            "Epoch 490: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1372.5789 - mae: 1372.5789 - mse: 18348466.0000 - val_loss: 1662.5856 - val_mae: 1662.5856 - val_mse: 21981212.0000\n",
            "Epoch 491/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1396.7318 - mae: 1396.7318 - mse: 18256882.0000\n",
            "Epoch 491: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1416.1958 - mae: 1416.1958 - mse: 18769222.0000 - val_loss: 1752.3480 - val_mae: 1752.3480 - val_mse: 23950578.0000\n",
            "Epoch 492/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1269.6505 - mae: 1269.6505 - mse: 17199600.0000\n",
            "Epoch 492: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1324.8492 - mae: 1324.8492 - mse: 18267690.0000 - val_loss: 1648.7700 - val_mae: 1648.7700 - val_mse: 22682494.0000\n",
            "Epoch 493/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1305.4491 - mae: 1305.4491 - mse: 17141038.0000\n",
            "Epoch 493: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1363.3662 - mae: 1363.3662 - mse: 18361570.0000 - val_loss: 1588.1094 - val_mae: 1588.1094 - val_mse: 21828726.0000\n",
            "Epoch 494/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1321.6622 - mae: 1321.6622 - mse: 17383994.0000\n",
            "Epoch 494: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1375.6614 - mae: 1375.6614 - mse: 18473800.0000 - val_loss: 1721.6580 - val_mae: 1721.6580 - val_mse: 23161030.0000\n",
            "Epoch 495/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1455.7166 - mae: 1455.7166 - mse: 18878478.0000\n",
            "Epoch 495: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1478.4130 - mae: 1478.4130 - mse: 19531168.0000 - val_loss: 1726.9221 - val_mae: 1726.9221 - val_mse: 21913562.0000\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1379.2642 - mae: 1379.2642 - mse: 18592662.0000\n",
            "Epoch 496: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1379.2642 - mae: 1379.2642 - mse: 18592662.0000 - val_loss: 1784.8949 - val_mae: 1784.8949 - val_mse: 21162140.0000\n",
            "Epoch 497/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1483.7526 - mae: 1483.7526 - mse: 18376048.0000\n",
            "Epoch 497: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1523.9242 - mae: 1523.9242 - mse: 19042094.0000 - val_loss: 1620.0466 - val_mae: 1620.0466 - val_mse: 21567834.0000\n",
            "Epoch 498/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1416.4370 - mae: 1416.4370 - mse: 17493570.0000\n",
            "Epoch 498: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1422.7998 - mae: 1422.7998 - mse: 18622676.0000 - val_loss: 1664.5647 - val_mae: 1664.5647 - val_mse: 22559782.0000\n",
            "Epoch 499/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1277.0145 - mae: 1277.0145 - mse: 17081286.0000\n",
            "Epoch 499: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1333.2271 - mae: 1333.2271 - mse: 18220394.0000 - val_loss: 1608.8165 - val_mae: 1608.8165 - val_mse: 22183274.0000\n",
            "Epoch 500/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1286.2926 - mae: 1286.2926 - mse: 17148490.0000\n",
            "Epoch 500: val_loss did not improve from 1524.88074\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1348.5397 - mae: 1348.5397 - mse: 18252114.0000 - val_loss: 1579.3906 - val_mae: 1579.3906 - val_mse: 21911516.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "ffebc61d-ea88-4b4d-feb7-696cb382d5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2081.7781 - mae: 2081.7781 - mse: 33523188.0000 - 24ms/epoch - 3ms/step\n",
            "Testing set Mean Abs Error: 2081.78 expenses\n",
            "You passed the challenge. Great job!\n",
            "9/9 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute some descriptive statistics of the test dataset\n",
        "test_descript_stats = test_dataset.describe()\\\n",
        "                           .transpose()\\\n",
        "                           .round(3)\n",
        "test_descript_stats"
      ],
      "metadata": {
        "id": "DuPjD-P0pn5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6ecae55d-b995-4377-9cfd-c753bddae7ec"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  count    mean     std   min   25%   50%     75%   max\n",
              "age               268.0  39.888  13.680  18.0  28.0  40.0  52.000  64.0\n",
              "bmi               268.0  30.379   6.232  17.4  26.0  30.1  34.125  48.1\n",
              "children          268.0   1.101   1.184   0.0   0.0   1.0   2.000   5.0\n",
              "sex_male          268.0   0.534   0.500   0.0   0.0   1.0   1.000   1.0\n",
              "smoker_yes        268.0   0.228   0.420   0.0   0.0   0.0   0.000   1.0\n",
              "region_northwest  268.0   0.272   0.446   0.0   0.0   0.0   1.000   1.0\n",
              "region_southeast  268.0   0.235   0.425   0.0   0.0   0.0   0.000   1.0\n",
              "region_southwest  268.0   0.276   0.448   0.0   0.0   0.0   1.000   1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f37f2674-d614-4767-af2d-f7fdf3d2c22d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>268.0</td>\n",
              "      <td>39.888</td>\n",
              "      <td>13.680</td>\n",
              "      <td>18.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>52.000</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>268.0</td>\n",
              "      <td>30.379</td>\n",
              "      <td>6.232</td>\n",
              "      <td>17.4</td>\n",
              "      <td>26.0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>34.125</td>\n",
              "      <td>48.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>268.0</td>\n",
              "      <td>1.101</td>\n",
              "      <td>1.184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_male</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker_yes</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.228</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_northwest</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southeast</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southwest</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f37f2674-d614-4767-af2d-f7fdf3d2c22d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f37f2674-d614-4767-af2d-f7fdf3d2c22d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f37f2674-d614-4767-af2d-f7fdf3d2c22d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-515ce4b8-1bfe-4754-a054-3ac3e696c57c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-515ce4b8-1bfe-4754-a054-3ac3e696c57c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-515ce4b8-1bfe-4754-a054-3ac3e696c57c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e8b853b2-f67f-4680-a362-01a92e64d760\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_descript_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e8b853b2-f67f-4680-a362-01a92e64d760 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_descript_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}