{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dd8810-34cf-4172-d95e-5dfbd858695b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "# from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "55b546de-a04c-424d-cf14-05deeb9b644c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-28 16:53:28--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 104.26.3.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv.2’\n",
            "\n",
            "insurance.csv.2     100%[===================>]  49.09K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-12-28 16:53:28 (64.0 MB/s) - ‘insurance.csv.2’ saved [50264/50264]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa0a6fa6-1743-495a-a4c8-b74b5800264e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa0a6fa6-1743-495a-a4c8-b74b5800264e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa0a6fa6-1743-495a-a4c8-b74b5800264e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa0a6fa6-1743-495a-a4c8-b74b5800264e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d9662bc-fdf7-4e2a-9c4a-0599c08b2afc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d9662bc-fdf7-4e2a-9c4a-0599c08b2afc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d9662bc-fdf7-4e2a-9c4a-0599c08b2afc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4316d558-53c9-4b2b-9dd8-a471a81636e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex   bmi  children smoker     region  expenses\n",
              "0   19  female  27.9         0    yes  southwest  16884.92\n",
              "1   18    male  33.8         1     no  southeast   1725.55\n",
              "2   28    male  33.0         3     no  southeast   4449.46\n",
              "3   33    male  22.7         0     no  northwest  21984.47\n",
              "4   32    male  28.9         0     no  northwest   3866.86"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28b49a59-1adf-4369-a01d-138c15be4a5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28b49a59-1adf-4369-a01d-138c15be4a5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28b49a59-1adf-4369-a01d-138c15be4a5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28b49a59-1adf-4369-a01d-138c15be4a5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-196cad4f-307c-47c6-9c2a-f2824a6d11d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-196cad4f-307c-47c6-9c2a-f2824a6d11d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-196cad4f-307c-47c6-9c2a-f2824a6d11d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Avoid repeated and unnecessary importations of the dataset\n",
        "# from fCC's Static Assets.\n",
        "df = dataset.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Any necessity to impute any value?\n",
        "df.isna()\\\n",
        "  .sum()"
      ],
      "metadata": {
        "id": "ANxsGAlEQ-xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5588ad-93ba-4cae-86c0-47416a4fde4f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "bmi         0\n",
              "children    0\n",
              "smoker      0\n",
              "region      0\n",
              "expenses    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical values to be parsed as numerical ones\n",
        "categoricals = ['sex',\n",
        "                'smoker',\n",
        "                'region']\n",
        "df = pd.get_dummies(df,\n",
        "                    columns = categoricals,\n",
        "                    drop_first = False)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IB2o-ili7HMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d6eb9c62-49e3-4206-d7dc-7ec35f1260e1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age   bmi  children  expenses  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0   19  27.9         0  16884.92           1         0          0           1   \n",
              "1   18  33.8         1   1725.55           0         1          1           0   \n",
              "2   28  33.0         3   4449.46           0         1          1           0   \n",
              "3   33  22.7         0  21984.47           0         1          1           0   \n",
              "4   32  28.9         0   3866.86           0         1          1           0   \n",
              "\n",
              "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                 0                 0                 0                 1  \n",
              "1                 0                 0                 1                 0  \n",
              "2                 0                 0                 1                 0  \n",
              "3                 0                 1                 0                 0  \n",
              "4                 0                 1                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3b16bd-49df-4f40-8994-3ccf166dedd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.86</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3b16bd-49df-4f40-8994-3ccf166dedd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b3b16bd-49df-4f40-8994-3ccf166dedd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b3b16bd-49df-4f40-8994-3ccf166dedd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d616d908-1981-405c-8639-17eec31f6c59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d616d908-1981-405c-8639-17eec31f6c59')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d616d908-1981-405c-8639-17eec31f6c59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the train dataset, create a random sample\n",
        "# which contains 80% of the observations\n",
        "train_dataset = df.sample(frac = .8,\n",
        "                          random_state = 0)\n",
        "\n",
        "# Assign the test dataset\n",
        "test_dataset = df.drop(train_dataset.index)\n",
        "\n",
        "# Pop off the 'expenses' colmuns\n",
        "train_labels = train_dataset.pop('expenses')\n",
        "test_labels = test_dataset.pop('expenses')\n"
      ],
      "metadata": {
        "id": "Yi4E5nn37X60"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add output layers\n",
        "input_shape = len(train_dataset.keys())\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "    layers.Dense(128,\n",
        "                 activation = 'relu',\n",
        "                 input_shape = [input_shape]),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.Dense(16, activation = 'relu'),\n",
        "    layers.Dense(1, activation = 'relu')\n",
        "  ]\n",
        "    )\n",
        "\n",
        "# Compile the model:\n",
        "# Implement an 'Adaptive Moment Estimation' algorithm\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate = .008\n",
        ")\n",
        "\n",
        "model.compile(loss = 'mae',\n",
        "              optimizer = optimizer,\n",
        "              metrics = ['mae',\n",
        "                         'mse'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "vw7IQ9E02at4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fb3a82-4b8b-4157-b4e3-918b7a2ca3e4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17633 (68.88 KB)\n",
            "Trainable params: 17633 (68.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Trian the model\n",
        "# https://keras.io/api/callbacks/model_checkpoint/:\n",
        "\n",
        "EPOCHS = 500\n",
        "checkpoint_filepath = './tmp/ckpt/fcchealthcosts.model.keras'\n",
        "\n",
        "checkpoint_callback  = [tf.keras.callbacks\\\n",
        "                        .ModelCheckpoint(filepath = checkpoint_filepath,\n",
        "                                         monitor = 'val_loss',\n",
        "                                         verbose = 1,\n",
        "                                         save_best_only = True,\n",
        "                                         mode = 'min'\n",
        "                                         )\n",
        "]\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit:\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    train_labels,\n",
        "                    epochs = EPOCHS,\n",
        "                    verbose = 1,\n",
        "                    validation_split = .2,\n",
        "                    shuffle = False,\n",
        "                    callbacks = checkpoint_callback\n",
        ")\n"
      ],
      "metadata": {
        "id": "mxjqcCZ537I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007457ff-f389-4c77-bca9-25c1f56751c6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1307.4921 - mae: 1307.4921 - mse: 17824300.0000\n",
            "Epoch 1: val_loss improved from inf to 1649.56726, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1353.5736 - mae: 1353.5736 - mse: 18744604.0000 - val_loss: 1649.5673 - val_mae: 1649.5673 - val_mse: 23189170.0000\n",
            "Epoch 2/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1187.2695 - mae: 1187.2695 - mse: 16749847.0000\n",
            "Epoch 2: val_loss improved from 1649.56726 to 1561.83020, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1243.9939 - mae: 1243.9939 - mse: 17872172.0000 - val_loss: 1561.8302 - val_mae: 1561.8302 - val_mse: 22054622.0000\n",
            "Epoch 3/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1203.7334 - mae: 1203.7334 - mse: 16773228.0000\n",
            "Epoch 3: val_loss improved from 1561.83020 to 1542.43311, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1259.6731 - mae: 1259.6731 - mse: 17979422.0000 - val_loss: 1542.4331 - val_mae: 1542.4331 - val_mse: 21748836.0000\n",
            "Epoch 4/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1181.5425 - mae: 1181.5425 - mse: 16607277.0000\n",
            "Epoch 4: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1243.5469 - mae: 1243.5469 - mse: 17818360.0000 - val_loss: 1742.2772 - val_mae: 1742.2772 - val_mse: 23672590.0000\n",
            "Epoch 5/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1186.5780 - mae: 1186.5780 - mse: 15863089.0000\n",
            "Epoch 5: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1330.6890 - mae: 1330.6890 - mse: 17999034.0000 - val_loss: 1782.2606 - val_mae: 1782.2606 - val_mse: 21978762.0000\n",
            "Epoch 6/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1320.5450 - mae: 1320.5450 - mse: 16389560.0000\n",
            "Epoch 6: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1399.5471 - mae: 1399.5471 - mse: 18140444.0000 - val_loss: 1600.7646 - val_mae: 1600.7646 - val_mse: 22617330.0000\n",
            "Epoch 7/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1281.4695 - mae: 1281.4695 - mse: 16878158.0000\n",
            "Epoch 7: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1331.0653 - mae: 1331.0653 - mse: 17976384.0000 - val_loss: 1641.7491 - val_mae: 1641.7491 - val_mse: 23108008.0000\n",
            "Epoch 8/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1224.6593 - mae: 1224.6593 - mse: 16857164.0000\n",
            "Epoch 8: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1258.9965 - mae: 1258.9965 - mse: 17986900.0000 - val_loss: 1711.7539 - val_mae: 1711.7539 - val_mse: 24017708.0000\n",
            "Epoch 9/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1182.2599 - mae: 1182.2599 - mse: 16943298.0000\n",
            "Epoch 9: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1241.9243 - mae: 1241.9242 - mse: 18023196.0000 - val_loss: 1605.3215 - val_mae: 1605.3215 - val_mse: 23275984.0000\n",
            "Epoch 10/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1141.6174 - mae: 1141.6174 - mse: 16253032.0000\n",
            "Epoch 10: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1246.6093 - mae: 1246.6091 - mse: 18066756.0000 - val_loss: 1593.1565 - val_mae: 1593.1565 - val_mse: 23422162.0000\n",
            "Epoch 11/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1187.7589 - mae: 1187.7589 - mse: 16747836.0000\n",
            "Epoch 11: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1245.2880 - mae: 1245.2880 - mse: 17823238.0000 - val_loss: 1674.2981 - val_mae: 1674.2981 - val_mse: 24503822.0000\n",
            "Epoch 12/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1145.1246 - mae: 1145.1246 - mse: 15969368.0000\n",
            "Epoch 12: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1245.8660 - mae: 1245.8660 - mse: 17818408.0000 - val_loss: 1561.8251 - val_mae: 1561.8251 - val_mse: 22971226.0000\n",
            "Epoch 13/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1208.2048 - mae: 1208.2048 - mse: 16623732.0000\n",
            "Epoch 13: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1265.5790 - mae: 1265.5790 - mse: 17840430.0000 - val_loss: 1582.0582 - val_mae: 1582.0582 - val_mse: 22811208.0000\n",
            "Epoch 14/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1210.8545 - mae: 1210.8545 - mse: 16668019.0000\n",
            "Epoch 14: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1276.8231 - mae: 1276.8231 - mse: 17926756.0000 - val_loss: 1608.7583 - val_mae: 1608.7583 - val_mse: 22983708.0000\n",
            "Epoch 15/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1197.4587 - mae: 1197.4587 - mse: 16618160.0000\n",
            "Epoch 15: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1259.0520 - mae: 1259.0520 - mse: 17756792.0000 - val_loss: 1659.3490 - val_mae: 1659.3490 - val_mse: 24939236.0000\n",
            "Epoch 16/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1249.1019 - mae: 1249.1019 - mse: 15701738.0000\n",
            "Epoch 16: val_loss did not improve from 1542.43311\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1321.6454 - mae: 1321.6454 - mse: 17910064.0000 - val_loss: 1664.2063 - val_mae: 1664.2063 - val_mse: 23777130.0000\n",
            "Epoch 17/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1298.0574 - mae: 1298.0574 - mse: 17010312.0000\n",
            "Epoch 17: val_loss improved from 1542.43311 to 1533.70361, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1313.2190 - mae: 1313.2190 - mse: 18065388.0000 - val_loss: 1533.7036 - val_mae: 1533.7036 - val_mse: 22144168.0000\n",
            "Epoch 18/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1212.4650 - mae: 1212.4650 - mse: 16561381.0000\n",
            "Epoch 18: val_loss did not improve from 1533.70361\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1274.1058 - mae: 1274.1058 - mse: 17755584.0000 - val_loss: 1626.6482 - val_mae: 1626.6482 - val_mse: 23380916.0000\n",
            "Epoch 19/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1199.9491 - mae: 1199.9491 - mse: 16682475.0000\n",
            "Epoch 19: val_loss improved from 1533.70361 to 1532.86316, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1267.2356 - mae: 1267.2356 - mse: 17874270.0000 - val_loss: 1532.8632 - val_mae: 1532.8632 - val_mse: 21924914.0000\n",
            "Epoch 20/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1187.8813 - mae: 1187.8813 - mse: 16723293.0000\n",
            "Epoch 20: val_loss did not improve from 1532.86316\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1249.9178 - mae: 1249.9178 - mse: 17831870.0000 - val_loss: 1642.6086 - val_mae: 1642.6086 - val_mse: 23344618.0000\n",
            "Epoch 21/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1192.9845 - mae: 1192.9845 - mse: 16954814.0000\n",
            "Epoch 21: val_loss improved from 1532.86316 to 1474.99341, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1253.5653 - mae: 1253.5653 - mse: 18046838.0000 - val_loss: 1474.9934 - val_mae: 1474.9934 - val_mse: 21581418.0000\n",
            "Epoch 22/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1213.7643 - mae: 1213.7643 - mse: 17011222.0000\n",
            "Epoch 22: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1271.3484 - mae: 1271.3484 - mse: 18033464.0000 - val_loss: 1652.3116 - val_mae: 1652.3116 - val_mse: 24058706.0000\n",
            "Epoch 23/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1201.2139 - mae: 1201.2139 - mse: 16610473.0000\n",
            "Epoch 23: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1277.6799 - mae: 1277.6799 - mse: 18157884.0000 - val_loss: 1574.9928 - val_mae: 1574.9928 - val_mse: 23130006.0000\n",
            "Epoch 24/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1196.5643 - mae: 1196.5643 - mse: 16771654.0000\n",
            "Epoch 24: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1247.3534 - mae: 1247.3534 - mse: 18029866.0000 - val_loss: 1518.8536 - val_mae: 1518.8536 - val_mse: 21351928.0000\n",
            "Epoch 25/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1188.0298 - mae: 1188.0298 - mse: 16771001.0000\n",
            "Epoch 25: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1242.6541 - mae: 1242.6541 - mse: 17890100.0000 - val_loss: 1620.8976 - val_mae: 1620.8976 - val_mse: 22426574.0000\n",
            "Epoch 26/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1221.7577 - mae: 1221.7577 - mse: 16087766.0000\n",
            "Epoch 26: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1315.4839 - mae: 1315.4839 - mse: 17909496.0000 - val_loss: 1510.1687 - val_mae: 1510.1687 - val_mse: 21285396.0000\n",
            "Epoch 27/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1193.5389 - mae: 1193.5389 - mse: 16668356.0000\n",
            "Epoch 27: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1259.4025 - mae: 1259.4025 - mse: 17803098.0000 - val_loss: 1661.8392 - val_mae: 1661.8392 - val_mse: 22985156.0000\n",
            "Epoch 28/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1169.5179 - mae: 1169.5179 - mse: 15973686.0000\n",
            "Epoch 28: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1270.9469 - mae: 1270.9469 - mse: 17823126.0000 - val_loss: 1587.3082 - val_mae: 1587.3082 - val_mse: 22966976.0000\n",
            "Epoch 29/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1182.6472 - mae: 1182.6472 - mse: 16724650.0000\n",
            "Epoch 29: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1244.5270 - mae: 1244.5270 - mse: 17864372.0000 - val_loss: 1598.6460 - val_mae: 1598.6460 - val_mse: 23636226.0000\n",
            "Epoch 30/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1189.3132 - mae: 1189.3132 - mse: 16739432.0000\n",
            "Epoch 30: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1249.3711 - mae: 1249.3711 - mse: 17962540.0000 - val_loss: 1618.9880 - val_mae: 1618.9880 - val_mse: 22425742.0000\n",
            "Epoch 31/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1176.6963 - mae: 1176.6963 - mse: 16662150.0000\n",
            "Epoch 31: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1221.6554 - mae: 1221.6554 - mse: 17833596.0000 - val_loss: 1566.5060 - val_mae: 1566.5060 - val_mse: 21949740.0000\n",
            "Epoch 32/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1184.7140 - mae: 1184.7140 - mse: 16846030.0000\n",
            "Epoch 32: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1240.7896 - mae: 1240.7896 - mse: 17943944.0000 - val_loss: 1626.8317 - val_mae: 1626.8317 - val_mse: 22977752.0000\n",
            "Epoch 33/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1188.1827 - mae: 1188.1827 - mse: 16886374.0000\n",
            "Epoch 33: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1250.1921 - mae: 1250.1921 - mse: 18031058.0000 - val_loss: 1553.7812 - val_mae: 1553.7812 - val_mse: 22372920.0000\n",
            "Epoch 34/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1215.4946 - mae: 1215.4946 - mse: 17151230.0000\n",
            "Epoch 34: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1246.6376 - mae: 1246.6376 - mse: 17877834.0000 - val_loss: 1598.1050 - val_mae: 1598.1050 - val_mse: 23748300.0000\n",
            "Epoch 35/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1190.9243 - mae: 1190.9243 - mse: 16740704.0000\n",
            "Epoch 35: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1248.7329 - mae: 1248.7329 - mse: 17814190.0000 - val_loss: 1633.0663 - val_mae: 1633.0663 - val_mse: 24354550.0000\n",
            "Epoch 36/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1150.9203 - mae: 1150.9203 - mse: 16016141.0000\n",
            "Epoch 36: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1256.5890 - mae: 1256.5890 - mse: 17829632.0000 - val_loss: 1588.4563 - val_mae: 1588.4563 - val_mse: 23662116.0000\n",
            "Epoch 37/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1184.8958 - mae: 1184.8958 - mse: 16849644.0000\n",
            "Epoch 37: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1249.9159 - mae: 1249.9159 - mse: 18012228.0000 - val_loss: 1630.5730 - val_mae: 1630.5730 - val_mse: 22885660.0000\n",
            "Epoch 38/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1131.6379 - mae: 1131.6379 - mse: 16027423.0000\n",
            "Epoch 38: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1235.5233 - mae: 1235.5233 - mse: 17818368.0000 - val_loss: 1549.7596 - val_mae: 1549.7596 - val_mse: 22049058.0000\n",
            "Epoch 39/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1145.7097 - mae: 1145.7097 - mse: 15255066.0000\n",
            "Epoch 39: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1290.1660 - mae: 1290.1660 - mse: 18057390.0000 - val_loss: 1688.9823 - val_mae: 1688.9823 - val_mse: 22686724.0000\n",
            "Epoch 40/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1228.4901 - mae: 1228.4901 - mse: 17055648.0000\n",
            "Epoch 40: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1283.5999 - mae: 1283.5999 - mse: 17930908.0000 - val_loss: 1552.8700 - val_mae: 1552.8700 - val_mse: 21074582.0000\n",
            "Epoch 41/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1227.2285 - mae: 1227.2285 - mse: 16920898.0000\n",
            "Epoch 41: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.3890 - mae: 1280.3890 - mse: 18002094.0000 - val_loss: 1589.4075 - val_mae: 1589.4075 - val_mse: 21412726.0000\n",
            "Epoch 42/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1203.2848 - mae: 1203.2848 - mse: 15466324.0000\n",
            "Epoch 42: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1291.3662 - mae: 1291.3662 - mse: 17742204.0000 - val_loss: 1551.7211 - val_mae: 1551.7211 - val_mse: 21940710.0000\n",
            "Epoch 43/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1206.7061 - mae: 1206.7061 - mse: 16770640.0000\n",
            "Epoch 43: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1268.1743 - mae: 1268.1743 - mse: 17869786.0000 - val_loss: 1535.4265 - val_mae: 1535.4265 - val_mse: 21976744.0000\n",
            "Epoch 44/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1150.6740 - mae: 1150.6740 - mse: 16103737.0000\n",
            "Epoch 44: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1256.2957 - mae: 1256.2957 - mse: 17934650.0000 - val_loss: 1636.4540 - val_mae: 1636.4540 - val_mse: 22395830.0000\n",
            "Epoch 45/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1166.4742 - mae: 1166.4742 - mse: 16007392.0000\n",
            "Epoch 45: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1264.8634 - mae: 1264.8634 - mse: 17832026.0000 - val_loss: 1603.4889 - val_mae: 1603.4889 - val_mse: 23240236.0000\n",
            "Epoch 46/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1197.1484 - mae: 1197.1484 - mse: 16771760.0000\n",
            "Epoch 46: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1252.7249 - mae: 1252.7249 - mse: 17888932.0000 - val_loss: 1638.8131 - val_mae: 1638.8131 - val_mse: 23698868.0000\n",
            "Epoch 47/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1150.7570 - mae: 1150.7570 - mse: 16657887.0000\n",
            "Epoch 47: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1216.6149 - mae: 1216.6149 - mse: 17820380.0000 - val_loss: 1595.8093 - val_mae: 1595.8093 - val_mse: 22693876.0000\n",
            "Epoch 48/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1082.5803 - mae: 1082.5803 - mse: 14846726.0000\n",
            "Epoch 48: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1246.9797 - mae: 1246.9797 - mse: 17893942.0000 - val_loss: 1485.9783 - val_mae: 1485.9783 - val_mse: 21406512.0000\n",
            "Epoch 49/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1190.0846 - mae: 1190.0846 - mse: 16738163.0000\n",
            "Epoch 49: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1248.9435 - mae: 1248.9435 - mse: 17952684.0000 - val_loss: 1591.3346 - val_mae: 1591.3346 - val_mse: 23448500.0000\n",
            "Epoch 50/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1187.3450 - mae: 1187.3450 - mse: 16651495.0000\n",
            "Epoch 50: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1247.2024 - mae: 1247.2024 - mse: 17878270.0000 - val_loss: 1635.7826 - val_mae: 1635.7826 - val_mse: 23701058.0000\n",
            "Epoch 51/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1222.7242 - mae: 1222.7242 - mse: 16889054.0000\n",
            "Epoch 51: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1280.5497 - mae: 1280.5497 - mse: 17983986.0000 - val_loss: 1577.6539 - val_mae: 1577.6539 - val_mse: 22482810.0000\n",
            "Epoch 52/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1225.4701 - mae: 1225.4701 - mse: 16667399.0000\n",
            "Epoch 52: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1294.8224 - mae: 1294.8224 - mse: 17921356.0000 - val_loss: 1787.5433 - val_mae: 1787.5433 - val_mse: 24587140.0000\n",
            "Epoch 53/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1198.7877 - mae: 1198.7877 - mse: 16125103.0000\n",
            "Epoch 53: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1310.1575 - mae: 1310.1575 - mse: 17955666.0000 - val_loss: 1673.9941 - val_mae: 1673.9941 - val_mse: 21645848.0000\n",
            "Epoch 54/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1310.6130 - mae: 1310.6130 - mse: 17106500.0000\n",
            "Epoch 54: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1361.6855 - mae: 1361.6855 - mse: 17976906.0000 - val_loss: 1595.0648 - val_mae: 1595.0648 - val_mse: 21842638.0000\n",
            "Epoch 55/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1217.5386 - mae: 1217.5386 - mse: 15537425.0000\n",
            "Epoch 55: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1313.0394 - mae: 1313.0394 - mse: 17761094.0000 - val_loss: 1687.5090 - val_mae: 1687.5090 - val_mse: 22378638.0000\n",
            "Epoch 56/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1192.4528 - mae: 1192.4528 - mse: 15771680.0000\n",
            "Epoch 56: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1286.8324 - mae: 1286.8324 - mse: 17992800.0000 - val_loss: 1670.8506 - val_mae: 1670.8506 - val_mse: 23931266.0000\n",
            "Epoch 57/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1255.9823 - mae: 1255.9823 - mse: 16724945.0000\n",
            "Epoch 57: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1335.2654 - mae: 1335.2654 - mse: 17953554.0000 - val_loss: 1796.4366 - val_mae: 1796.4366 - val_mse: 21790286.0000\n",
            "Epoch 58/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1251.1079 - mae: 1251.1079 - mse: 16810514.0000\n",
            "Epoch 58: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1307.2479 - mae: 1307.2479 - mse: 17896446.0000 - val_loss: 1525.5793 - val_mae: 1525.5793 - val_mse: 21792732.0000\n",
            "Epoch 59/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1201.4166 - mae: 1201.4166 - mse: 16668262.0000\n",
            "Epoch 59: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1250.3666 - mae: 1250.3666 - mse: 17864488.0000 - val_loss: 1503.1494 - val_mae: 1503.1494 - val_mse: 21382984.0000\n",
            "Epoch 60/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1170.9569 - mae: 1170.9569 - mse: 16719002.0000\n",
            "Epoch 60: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1239.2175 - mae: 1239.2175 - mse: 17844964.0000 - val_loss: 1576.5002 - val_mae: 1576.5002 - val_mse: 22409060.0000\n",
            "Epoch 61/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1194.6080 - mae: 1194.6080 - mse: 17059304.0000\n",
            "Epoch 61: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1236.8068 - mae: 1236.8068 - mse: 17872742.0000 - val_loss: 1576.7267 - val_mae: 1576.7267 - val_mse: 22590772.0000\n",
            "Epoch 62/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1183.9768 - mae: 1183.9768 - mse: 16530256.0000\n",
            "Epoch 62: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1250.1227 - mae: 1250.1227 - mse: 17765148.0000 - val_loss: 1720.5165 - val_mae: 1720.5165 - val_mse: 25420192.0000\n",
            "Epoch 63/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1230.9042 - mae: 1230.9042 - mse: 16120661.0000\n",
            "Epoch 63: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1324.0421 - mae: 1324.0421 - mse: 17935298.0000 - val_loss: 1687.0765 - val_mae: 1687.0765 - val_mse: 24451388.0000\n",
            "Epoch 64/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1184.3450 - mae: 1184.3450 - mse: 16196943.0000\n",
            "Epoch 64: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1301.8333 - mae: 1301.8333 - mse: 18039774.0000 - val_loss: 1673.6019 - val_mae: 1673.6019 - val_mse: 21053460.0000\n",
            "Epoch 65/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1179.3373 - mae: 1179.3373 - mse: 15486715.0000\n",
            "Epoch 65: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1279.4443 - mae: 1279.4443 - mse: 17923618.0000 - val_loss: 1559.2672 - val_mae: 1559.2672 - val_mse: 22557016.0000\n",
            "Epoch 66/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1189.9366 - mae: 1189.9366 - mse: 16592524.0000\n",
            "Epoch 66: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1253.4761 - mae: 1253.4761 - mse: 17732078.0000 - val_loss: 1620.1183 - val_mae: 1620.1183 - val_mse: 23491466.0000\n",
            "Epoch 67/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1186.8489 - mae: 1186.8489 - mse: 17021562.0000\n",
            "Epoch 67: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1249.4941 - mae: 1249.4941 - mse: 18149298.0000 - val_loss: 1504.8802 - val_mae: 1504.8802 - val_mse: 22272902.0000\n",
            "Epoch 68/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1196.5636 - mae: 1196.5636 - mse: 16794278.0000\n",
            "Epoch 68: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1265.8816 - mae: 1265.8816 - mse: 18044540.0000 - val_loss: 1558.0378 - val_mae: 1558.0378 - val_mse: 22008642.0000\n",
            "Epoch 69/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1245.9344 - mae: 1245.9344 - mse: 16583729.0000\n",
            "Epoch 69: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1318.4563 - mae: 1318.4563 - mse: 17808666.0000 - val_loss: 1765.3815 - val_mae: 1765.3815 - val_mse: 23741540.0000\n",
            "Epoch 70/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1317.1615 - mae: 1317.1615 - mse: 17652150.0000\n",
            "Epoch 70: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1332.3718 - mae: 1332.3718 - mse: 18327006.0000 - val_loss: 1654.9918 - val_mae: 1654.9918 - val_mse: 23356014.0000\n",
            "Epoch 71/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1108.5229 - mae: 1108.5229 - mse: 14962180.0000\n",
            "Epoch 71: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1264.4735 - mae: 1264.4735 - mse: 18136694.0000 - val_loss: 1516.0847 - val_mae: 1516.0847 - val_mse: 21980816.0000\n",
            "Epoch 72/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1187.1542 - mae: 1187.1542 - mse: 16039067.0000\n",
            "Epoch 72: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1269.4530 - mae: 1269.4530 - mse: 18179724.0000 - val_loss: 1626.4456 - val_mae: 1626.4456 - val_mse: 23021292.0000\n",
            "Epoch 73/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1244.3265 - mae: 1244.3265 - mse: 17095766.0000\n",
            "Epoch 73: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1276.7925 - mae: 1276.7925 - mse: 17865216.0000 - val_loss: 1617.0829 - val_mae: 1617.0829 - val_mse: 23870878.0000\n",
            "Epoch 74/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1195.5178 - mae: 1195.5178 - mse: 16684312.0000\n",
            "Epoch 74: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1235.9375 - mae: 1235.9375 - mse: 17815592.0000 - val_loss: 1663.7374 - val_mae: 1663.7374 - val_mse: 24754980.0000\n",
            "Epoch 75/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1224.7487 - mae: 1224.7487 - mse: 17304060.0000\n",
            "Epoch 75: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1255.8052 - mae: 1255.8052 - mse: 18031516.0000 - val_loss: 1704.1383 - val_mae: 1704.1383 - val_mse: 23321708.0000\n",
            "Epoch 76/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1235.0651 - mae: 1235.0651 - mse: 17160822.0000\n",
            "Epoch 76: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1273.5203 - mae: 1273.5203 - mse: 17936210.0000 - val_loss: 1570.8711 - val_mae: 1570.8711 - val_mse: 22484854.0000\n",
            "Epoch 77/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1223.9653 - mae: 1223.9653 - mse: 16661774.0000\n",
            "Epoch 77: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1284.5254 - mae: 1284.5254 - mse: 17887800.0000 - val_loss: 1858.5267 - val_mae: 1858.5267 - val_mse: 24947210.0000\n",
            "Epoch 78/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1246.7224 - mae: 1246.7224 - mse: 16981362.0000\n",
            "Epoch 78: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1269.9540 - mae: 1269.9540 - mse: 17756354.0000 - val_loss: 1690.4666 - val_mae: 1690.4666 - val_mse: 24799074.0000\n",
            "Epoch 79/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1077.8768 - mae: 1077.8768 - mse: 14653590.0000\n",
            "Epoch 79: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1219.9835 - mae: 1219.9835 - mse: 17732860.0000 - val_loss: 1613.7969 - val_mae: 1613.7969 - val_mse: 24266096.0000\n",
            "Epoch 80/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1165.8695 - mae: 1165.8695 - mse: 15547483.0000\n",
            "Epoch 80: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.8809 - mae: 1280.8809 - mse: 17821488.0000 - val_loss: 1694.2141 - val_mae: 1694.2141 - val_mse: 23000832.0000\n",
            "Epoch 81/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1234.8109 - mae: 1234.8109 - mse: 17028758.0000\n",
            "Epoch 81: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1286.5194 - mae: 1286.5194 - mse: 18094628.0000 - val_loss: 1488.8748 - val_mae: 1488.8748 - val_mse: 21796152.0000\n",
            "Epoch 82/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1102.8478 - mae: 1102.8478 - mse: 15554602.0000\n",
            "Epoch 82: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1216.5018 - mae: 1216.5018 - mse: 17805012.0000 - val_loss: 1482.3108 - val_mae: 1482.3108 - val_mse: 22249116.0000\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1226.4076 - mae: 1226.4076 - mse: 17826094.0000\n",
            "Epoch 83: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1226.4076 - mae: 1226.4076 - mse: 17826094.0000 - val_loss: 1598.4559 - val_mae: 1598.4559 - val_mse: 23352744.0000\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1222.4056 - mae: 1222.4056 - mse: 18090202.0000\n",
            "Epoch 84: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1222.4056 - mae: 1222.4056 - mse: 18090202.0000 - val_loss: 1577.8909 - val_mae: 1577.8909 - val_mse: 23849250.0000\n",
            "Epoch 85/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1138.2644 - mae: 1138.2644 - mse: 15994598.0000\n",
            "Epoch 85: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1240.7941 - mae: 1240.7941 - mse: 17823320.0000 - val_loss: 1633.3320 - val_mae: 1633.3320 - val_mse: 24198384.0000\n",
            "Epoch 86/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1176.3798 - mae: 1176.3798 - mse: 16683626.0000\n",
            "Epoch 86: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1241.8184 - mae: 1241.8184 - mse: 17808852.0000 - val_loss: 1551.5262 - val_mae: 1551.5262 - val_mse: 22718402.0000\n",
            "Epoch 87/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1217.0044 - mae: 1217.0044 - mse: 16810484.0000\n",
            "Epoch 87: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1281.4048 - mae: 1281.4048 - mse: 17929250.0000 - val_loss: 1617.7728 - val_mae: 1617.7728 - val_mse: 22302926.0000\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1321.4518 - mae: 1321.4518 - mse: 18322680.0000\n",
            "Epoch 88: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1321.4518 - mae: 1321.4518 - mse: 18322680.0000 - val_loss: 1604.1088 - val_mae: 1604.1088 - val_mse: 23915834.0000\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1294.0649 - mae: 1294.0649 - mse: 17810616.0000\n",
            "Epoch 89: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1294.0649 - mae: 1294.0649 - mse: 17810616.0000 - val_loss: 1651.2909 - val_mae: 1651.2909 - val_mse: 23321556.0000\n",
            "Epoch 90/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1256.3071 - mae: 1256.3071 - mse: 16706757.0000\n",
            "Epoch 90: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1321.7075 - mae: 1321.7075 - mse: 17834768.0000 - val_loss: 1807.3660 - val_mae: 1807.3660 - val_mse: 22685874.0000\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1261.2922 - mae: 1261.2922 - mse: 17756914.0000\n",
            "Epoch 91: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1261.2922 - mae: 1261.2922 - mse: 17756914.0000 - val_loss: 1552.2592 - val_mae: 1552.2592 - val_mse: 23031752.0000\n",
            "Epoch 92/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1153.7983 - mae: 1153.7983 - mse: 16353766.0000\n",
            "Epoch 92: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1218.7314 - mae: 1218.7314 - mse: 17757498.0000 - val_loss: 1562.2454 - val_mae: 1562.2454 - val_mse: 23198240.0000\n",
            "Epoch 93/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1129.1422 - mae: 1129.1422 - mse: 15568076.0000\n",
            "Epoch 93: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1233.8037 - mae: 1233.8037 - mse: 17737890.0000 - val_loss: 1666.2406 - val_mae: 1666.2406 - val_mse: 25605326.0000\n",
            "Epoch 94/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1235.8860 - mae: 1235.8860 - mse: 17118712.0000\n",
            "Epoch 94: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1293.5046 - mae: 1293.5046 - mse: 18232964.0000 - val_loss: 1721.4806 - val_mae: 1721.4806 - val_mse: 25565716.0000\n",
            "Epoch 95/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1299.7443 - mae: 1299.7443 - mse: 18204886.0000\n",
            "Epoch 95: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1341.7778 - mae: 1341.7778 - mse: 19405984.0000 - val_loss: 1729.1227 - val_mae: 1729.1227 - val_mse: 24837474.0000\n",
            "Epoch 96/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1256.0203 - mae: 1256.0203 - mse: 17467554.0000\n",
            "Epoch 96: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1313.5724 - mae: 1313.5724 - mse: 18579276.0000 - val_loss: 1643.7592 - val_mae: 1643.7592 - val_mse: 23921018.0000\n",
            "Epoch 97/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1263.3101 - mae: 1263.3101 - mse: 16570859.0000\n",
            "Epoch 97: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1299.3024 - mae: 1299.3024 - mse: 17879190.0000 - val_loss: 1597.3239 - val_mae: 1597.3239 - val_mse: 21922258.0000\n",
            "Epoch 98/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1202.3202 - mae: 1202.3202 - mse: 16784514.0000\n",
            "Epoch 98: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1259.9315 - mae: 1259.9315 - mse: 17928528.0000 - val_loss: 1541.8392 - val_mae: 1541.8392 - val_mse: 22368968.0000\n",
            "Epoch 99/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1135.1348 - mae: 1135.1348 - mse: 15666564.0000\n",
            "Epoch 99: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1237.8594 - mae: 1237.8594 - mse: 17842644.0000 - val_loss: 1555.0193 - val_mae: 1555.0193 - val_mse: 23355230.0000\n",
            "Epoch 100/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1197.7079 - mae: 1197.7079 - mse: 16494461.0000\n",
            "Epoch 100: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1297.1289 - mae: 1297.1289 - mse: 17851620.0000 - val_loss: 1745.9647 - val_mae: 1745.9647 - val_mse: 24299914.0000\n",
            "Epoch 101/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1232.6024 - mae: 1232.6024 - mse: 16706445.0000\n",
            "Epoch 101: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1294.4130 - mae: 1294.4130 - mse: 17891654.0000 - val_loss: 1600.2231 - val_mae: 1600.2231 - val_mse: 23272738.0000\n",
            "Epoch 102/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1203.7637 - mae: 1203.7637 - mse: 16796986.0000\n",
            "Epoch 102: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1247.2583 - mae: 1247.2583 - mse: 17965998.0000 - val_loss: 1611.9026 - val_mae: 1611.9026 - val_mse: 23255190.0000\n",
            "Epoch 103/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1202.0005 - mae: 1202.0005 - mse: 16655224.0000\n",
            "Epoch 103: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1260.1429 - mae: 1260.1429 - mse: 17877728.0000 - val_loss: 1511.3536 - val_mae: 1511.3536 - val_mse: 22700496.0000\n",
            "Epoch 104/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1171.1506 - mae: 1171.1506 - mse: 16577093.0000\n",
            "Epoch 104: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1214.8871 - mae: 1214.8871 - mse: 17748882.0000 - val_loss: 1538.5104 - val_mae: 1538.5104 - val_mse: 22086042.0000\n",
            "Epoch 105/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1164.9622 - mae: 1164.9622 - mse: 16060263.0000\n",
            "Epoch 105: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1271.6355 - mae: 1271.6355 - mse: 17818842.0000 - val_loss: 1578.6340 - val_mae: 1578.6340 - val_mse: 23317708.0000\n",
            "Epoch 106/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1247.3682 - mae: 1247.3682 - mse: 17087812.0000\n",
            "Epoch 106: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1279.9871 - mae: 1279.9871 - mse: 17857882.0000 - val_loss: 1542.6255 - val_mae: 1542.6255 - val_mse: 22370784.0000\n",
            "Epoch 107/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1119.0465 - mae: 1119.0465 - mse: 16032440.0000\n",
            "Epoch 107: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1221.4949 - mae: 1221.4949 - mse: 17846840.0000 - val_loss: 1713.1243 - val_mae: 1713.1243 - val_mse: 23527044.0000\n",
            "Epoch 108/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1208.7306 - mae: 1208.7306 - mse: 15692926.0000\n",
            "Epoch 108: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1302.4072 - mae: 1302.4072 - mse: 17956810.0000 - val_loss: 1598.8914 - val_mae: 1598.8914 - val_mse: 22178440.0000\n",
            "Epoch 109/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1251.3889 - mae: 1251.3889 - mse: 15687323.0000\n",
            "Epoch 109: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1365.1255 - mae: 1365.1255 - mse: 18142504.0000 - val_loss: 1637.1747 - val_mae: 1637.1747 - val_mse: 21149736.0000\n",
            "Epoch 110/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1187.5471 - mae: 1187.5471 - mse: 15594213.0000\n",
            "Epoch 110: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1266.3101 - mae: 1266.3101 - mse: 17892006.0000 - val_loss: 1566.9050 - val_mae: 1566.9050 - val_mse: 22338374.0000\n",
            "Epoch 111/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1212.0807 - mae: 1212.0807 - mse: 17065400.0000\n",
            "Epoch 111: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1254.2783 - mae: 1254.2783 - mse: 17857654.0000 - val_loss: 1679.5995 - val_mae: 1679.5995 - val_mse: 22144886.0000\n",
            "Epoch 112/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1218.1523 - mae: 1218.1523 - mse: 15098544.0000\n",
            "Epoch 112: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1335.9471 - mae: 1335.9471 - mse: 18051628.0000 - val_loss: 1727.7976 - val_mae: 1727.7976 - val_mse: 23674866.0000\n",
            "Epoch 113/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1217.8268 - mae: 1217.8268 - mse: 15833032.0000\n",
            "Epoch 113: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1306.0479 - mae: 1306.0479 - mse: 18017576.0000 - val_loss: 1868.2988 - val_mae: 1868.2988 - val_mse: 23760794.0000\n",
            "Epoch 114/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1339.5010 - mae: 1339.5010 - mse: 17366862.0000\n",
            "Epoch 114: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1391.2537 - mae: 1391.2537 - mse: 18312526.0000 - val_loss: 1683.9702 - val_mae: 1683.9702 - val_mse: 23313664.0000\n",
            "Epoch 115/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1292.3481 - mae: 1292.3481 - mse: 15197682.0000\n",
            "Epoch 115: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1373.3671 - mae: 1373.3671 - mse: 17907094.0000 - val_loss: 1635.3320 - val_mae: 1635.3320 - val_mse: 22953476.0000\n",
            "Epoch 116/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1227.6477 - mae: 1227.6477 - mse: 16771139.0000\n",
            "Epoch 116: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1265.2670 - mae: 1265.2670 - mse: 17981204.0000 - val_loss: 1527.1481 - val_mae: 1527.1481 - val_mse: 22079034.0000\n",
            "Epoch 117/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1132.1765 - mae: 1132.1765 - mse: 15815262.0000\n",
            "Epoch 117: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1229.0332 - mae: 1229.0332 - mse: 17787420.0000 - val_loss: 1565.5516 - val_mae: 1565.5516 - val_mse: 23400408.0000\n",
            "Epoch 118/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1220.5890 - mae: 1220.5890 - mse: 17191964.0000\n",
            "Epoch 118: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1251.0692 - mae: 1251.0692 - mse: 17905038.0000 - val_loss: 1682.3127 - val_mae: 1682.3127 - val_mse: 24214822.0000\n",
            "Epoch 119/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1270.1577 - mae: 1270.1577 - mse: 17171868.0000\n",
            "Epoch 119: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1326.2866 - mae: 1326.2866 - mse: 18207196.0000 - val_loss: 1758.6539 - val_mae: 1758.6539 - val_mse: 22949732.0000\n",
            "Epoch 120/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1226.1560 - mae: 1226.1560 - mse: 15812480.0000\n",
            "Epoch 120: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1295.4125 - mae: 1295.4125 - mse: 18026674.0000 - val_loss: 1546.8197 - val_mae: 1546.8197 - val_mse: 22183514.0000\n",
            "Epoch 121/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1178.8406 - mae: 1178.8406 - mse: 15696802.0000\n",
            "Epoch 121: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1282.9688 - mae: 1282.9688 - mse: 18151986.0000 - val_loss: 1629.0618 - val_mae: 1629.0618 - val_mse: 23999740.0000\n",
            "Epoch 122/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1231.8173 - mae: 1231.8173 - mse: 16902664.0000\n",
            "Epoch 122: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1299.0682 - mae: 1299.0682 - mse: 17947594.0000 - val_loss: 1673.8257 - val_mae: 1673.8257 - val_mse: 23399836.0000\n",
            "Epoch 123/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1305.0483 - mae: 1305.0483 - mse: 16773524.0000\n",
            "Epoch 123: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1341.8535 - mae: 1341.8535 - mse: 17868894.0000 - val_loss: 1587.4005 - val_mae: 1587.4005 - val_mse: 23802624.0000\n",
            "Epoch 124/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1194.1001 - mae: 1194.1001 - mse: 15791685.0000\n",
            "Epoch 124: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1279.6415 - mae: 1279.6415 - mse: 17948390.0000 - val_loss: 1535.1278 - val_mae: 1535.1278 - val_mse: 22356214.0000\n",
            "Epoch 125/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1226.0897 - mae: 1226.0897 - mse: 16713126.0000\n",
            "Epoch 125: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1276.5586 - mae: 1276.5586 - mse: 17874848.0000 - val_loss: 1790.5082 - val_mae: 1790.5082 - val_mse: 24003896.0000\n",
            "Epoch 126/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1329.7476 - mae: 1329.7476 - mse: 16912434.0000\n",
            "Epoch 126: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1376.2455 - mae: 1376.2455 - mse: 18013900.0000 - val_loss: 1775.0201 - val_mae: 1775.0201 - val_mse: 24698022.0000\n",
            "Epoch 127/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1370.1102 - mae: 1370.1102 - mse: 17748468.0000\n",
            "Epoch 127: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1403.8967 - mae: 1403.8967 - mse: 18558414.0000 - val_loss: 1709.5605 - val_mae: 1709.5605 - val_mse: 21547450.0000\n",
            "Epoch 128/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1305.6205 - mae: 1305.6205 - mse: 16817876.0000\n",
            "Epoch 128: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1352.8606 - mae: 1352.8606 - mse: 18201882.0000 - val_loss: 1719.3003 - val_mae: 1719.3003 - val_mse: 22944316.0000\n",
            "Epoch 129/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1185.6520 - mae: 1185.6520 - mse: 16515951.0000\n",
            "Epoch 129: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1278.6022 - mae: 1278.6022 - mse: 18248774.0000 - val_loss: 1544.5791 - val_mae: 1544.5791 - val_mse: 22443220.0000\n",
            "Epoch 130/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1085.1261 - mae: 1085.1261 - mse: 14900346.0000\n",
            "Epoch 130: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1240.5575 - mae: 1240.5575 - mse: 17960962.0000 - val_loss: 1609.2819 - val_mae: 1609.2819 - val_mse: 22522330.0000\n",
            "Epoch 131/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1171.9294 - mae: 1171.9294 - mse: 15951478.0000\n",
            "Epoch 131: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.2417 - mae: 1252.2417 - mse: 18119576.0000 - val_loss: 1588.3195 - val_mae: 1588.3195 - val_mse: 23598628.0000\n",
            "Epoch 132/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1177.4358 - mae: 1177.4358 - mse: 15620510.0000\n",
            "Epoch 132: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1255.8618 - mae: 1255.8618 - mse: 17843038.0000 - val_loss: 1612.0780 - val_mae: 1612.0780 - val_mse: 23348818.0000\n",
            "Epoch 133/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1087.7781 - mae: 1087.7781 - mse: 14746844.0000\n",
            "Epoch 133: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1262.6818 - mae: 1262.6818 - mse: 17847336.0000 - val_loss: 1640.8281 - val_mae: 1640.8281 - val_mse: 22610534.0000\n",
            "Epoch 134/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1157.5144 - mae: 1157.5144 - mse: 15594826.0000\n",
            "Epoch 134: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1262.3190 - mae: 1262.3190 - mse: 17826208.0000 - val_loss: 1629.8923 - val_mae: 1629.8923 - val_mse: 21751280.0000\n",
            "Epoch 135/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1125.2706 - mae: 1125.2706 - mse: 14698132.0000\n",
            "Epoch 135: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1259.2214 - mae: 1259.2214 - mse: 17803268.0000 - val_loss: 1528.9894 - val_mae: 1528.9894 - val_mse: 22737218.0000\n",
            "Epoch 136/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1196.8590 - mae: 1196.8590 - mse: 16548917.0000\n",
            "Epoch 136: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1232.0074 - mae: 1232.0074 - mse: 17723334.0000 - val_loss: 1543.1959 - val_mae: 1543.1959 - val_mse: 22681178.0000\n",
            "Epoch 137/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1062.3394 - mae: 1062.3394 - mse: 14672454.0000\n",
            "Epoch 137: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1220.1985 - mae: 1220.1985 - mse: 17743418.0000 - val_loss: 1545.7599 - val_mae: 1545.7599 - val_mse: 22887790.0000\n",
            "Epoch 138/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1142.0208 - mae: 1142.0208 - mse: 15242344.0000\n",
            "Epoch 138: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1285.1300 - mae: 1285.1300 - mse: 17933844.0000 - val_loss: 1644.4167 - val_mae: 1644.4167 - val_mse: 22122272.0000\n",
            "Epoch 139/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1082.2432 - mae: 1082.2432 - mse: 14624475.0000\n",
            "Epoch 139: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1241.0193 - mae: 1241.0193 - mse: 17709692.0000 - val_loss: 1587.3547 - val_mae: 1587.3547 - val_mse: 22939406.0000\n",
            "Epoch 140/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1280.9081 - mae: 1280.9081 - mse: 15802241.0000\n",
            "Epoch 140: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1328.7488 - mae: 1328.7488 - mse: 17939296.0000 - val_loss: 1647.7428 - val_mae: 1647.7428 - val_mse: 23362314.0000\n",
            "Epoch 141/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1171.3795 - mae: 1171.3795 - mse: 15595788.0000\n",
            "Epoch 141: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1276.2186 - mae: 1276.2186 - mse: 17811058.0000 - val_loss: 1701.2368 - val_mae: 1701.2368 - val_mse: 23707808.0000\n",
            "Epoch 142/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1202.0740 - mae: 1202.0740 - mse: 17003988.0000\n",
            "Epoch 142: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1239.6769 - mae: 1239.6769 - mse: 17835242.0000 - val_loss: 1510.0967 - val_mae: 1510.0967 - val_mse: 22215682.0000\n",
            "Epoch 143/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1202.0421 - mae: 1202.0421 - mse: 15605267.0000\n",
            "Epoch 143: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1299.3733 - mae: 1299.3733 - mse: 17910030.0000 - val_loss: 1655.8566 - val_mae: 1655.8566 - val_mse: 22222864.0000\n",
            "Epoch 144/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1244.3700 - mae: 1244.3700 - mse: 17088716.0000\n",
            "Epoch 144: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1292.9681 - mae: 1292.9681 - mse: 18105182.0000 - val_loss: 1585.9384 - val_mae: 1585.9384 - val_mse: 23399458.0000\n",
            "Epoch 145/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1198.3320 - mae: 1198.3320 - mse: 15710525.0000\n",
            "Epoch 145: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1309.8220 - mae: 1309.8220 - mse: 18030438.0000 - val_loss: 1664.4923 - val_mae: 1664.4923 - val_mse: 24268048.0000\n",
            "Epoch 146/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1176.7992 - mae: 1176.7992 - mse: 15584958.0000\n",
            "Epoch 146: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1265.5013 - mae: 1265.5013 - mse: 17848140.0000 - val_loss: 1600.9567 - val_mae: 1600.9567 - val_mse: 23304092.0000\n",
            "Epoch 147/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1140.9424 - mae: 1140.9424 - mse: 15755946.0000\n",
            "Epoch 147: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1231.7120 - mae: 1231.7120 - mse: 17953904.0000 - val_loss: 1612.3560 - val_mae: 1612.3560 - val_mse: 23913896.0000\n",
            "Epoch 148/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1120.3752 - mae: 1120.3752 - mse: 15854369.0000\n",
            "Epoch 148: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1248.5111 - mae: 1248.5111 - mse: 17998898.0000 - val_loss: 1640.3556 - val_mae: 1640.3556 - val_mse: 22429686.0000\n",
            "Epoch 149/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1084.6896 - mae: 1084.6896 - mse: 14994739.0000\n",
            "Epoch 149: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1228.1438 - mae: 1228.1438 - mse: 17765944.0000 - val_loss: 1540.6984 - val_mae: 1540.6984 - val_mse: 23746100.0000\n",
            "Epoch 150/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1225.9255 - mae: 1225.9255 - mse: 17139544.0000\n",
            "Epoch 150: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1266.0656 - mae: 1266.0656 - mse: 17894686.0000 - val_loss: 1673.3950 - val_mae: 1673.3950 - val_mse: 23390252.0000\n",
            "Epoch 151/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1234.9171 - mae: 1234.9171 - mse: 15802579.0000\n",
            "Epoch 151: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1320.6404 - mae: 1320.6404 - mse: 18043800.0000 - val_loss: 1581.2863 - val_mae: 1581.2863 - val_mse: 23495452.0000\n",
            "Epoch 152/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1232.5641 - mae: 1232.5641 - mse: 16674805.0000\n",
            "Epoch 152: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1286.3690 - mae: 1286.3690 - mse: 17855660.0000 - val_loss: 1624.4000 - val_mae: 1624.4000 - val_mse: 22644346.0000\n",
            "Epoch 153/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1227.5504 - mae: 1227.5504 - mse: 15612116.0000\n",
            "Epoch 153: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1326.7849 - mae: 1326.7849 - mse: 17810952.0000 - val_loss: 1737.4093 - val_mae: 1737.4093 - val_mse: 23561708.0000\n",
            "Epoch 154/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1157.9647 - mae: 1157.9647 - mse: 14788439.0000\n",
            "Epoch 154: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1309.7133 - mae: 1309.7133 - mse: 17922482.0000 - val_loss: 1628.6731 - val_mae: 1628.6731 - val_mse: 24086236.0000\n",
            "Epoch 155/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1185.2659 - mae: 1185.2659 - mse: 15222598.0000\n",
            "Epoch 155: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1287.5425 - mae: 1287.5425 - mse: 17768224.0000 - val_loss: 1620.2476 - val_mae: 1620.2476 - val_mse: 24095352.0000\n",
            "Epoch 156/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1189.7860 - mae: 1189.7860 - mse: 16492452.0000\n",
            "Epoch 156: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1255.9719 - mae: 1255.9719 - mse: 17762552.0000 - val_loss: 1797.1429 - val_mae: 1797.1429 - val_mse: 25179772.0000\n",
            "Epoch 157/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1184.4503 - mae: 1184.4503 - mse: 15705676.0000\n",
            "Epoch 157: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1270.9086 - mae: 1270.9086 - mse: 17812936.0000 - val_loss: 1587.9280 - val_mae: 1587.9280 - val_mse: 24500234.0000\n",
            "Epoch 158/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1117.3340 - mae: 1117.3340 - mse: 15505263.0000\n",
            "Epoch 158: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1213.7297 - mae: 1213.7297 - mse: 17789676.0000 - val_loss: 1559.8840 - val_mae: 1559.8840 - val_mse: 23353710.0000\n",
            "Epoch 159/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1070.8445 - mae: 1070.8445 - mse: 14685350.0000\n",
            "Epoch 159: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1224.7709 - mae: 1224.7709 - mse: 17754218.0000 - val_loss: 1528.0017 - val_mae: 1528.0017 - val_mse: 23586064.0000\n",
            "Epoch 160/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1209.1532 - mae: 1209.1532 - mse: 16788276.0000\n",
            "Epoch 160: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1245.3804 - mae: 1245.3804 - mse: 17893366.0000 - val_loss: 1641.7590 - val_mae: 1641.7590 - val_mse: 23959234.0000\n",
            "Epoch 161/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1112.5903 - mae: 1112.5903 - mse: 14861686.0000\n",
            "Epoch 161: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1272.0396 - mae: 1272.0396 - mse: 17892186.0000 - val_loss: 1522.6267 - val_mae: 1522.6267 - val_mse: 21621404.0000\n",
            "Epoch 162/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1096.6447 - mae: 1096.6447 - mse: 15300102.0000\n",
            "Epoch 162: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1237.9332 - mae: 1237.9332 - mse: 17913884.0000 - val_loss: 1509.2026 - val_mae: 1509.2026 - val_mse: 21774108.0000\n",
            "Epoch 163/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1138.5138 - mae: 1138.5138 - mse: 15168093.0000\n",
            "Epoch 163: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1265.3676 - mae: 1265.3676 - mse: 17968370.0000 - val_loss: 1569.9969 - val_mae: 1569.9969 - val_mse: 23250054.0000\n",
            "Epoch 164/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1116.0869 - mae: 1116.0869 - mse: 15516711.0000\n",
            "Epoch 164: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1225.3566 - mae: 1225.3566 - mse: 17781456.0000 - val_loss: 1514.4196 - val_mae: 1514.4196 - val_mse: 21929620.0000\n",
            "Epoch 165/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1151.6815 - mae: 1151.6815 - mse: 15594828.0000\n",
            "Epoch 165: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1256.3735 - mae: 1256.3735 - mse: 17832666.0000 - val_loss: 1638.3341 - val_mae: 1638.3341 - val_mse: 22717584.0000\n",
            "Epoch 166/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1296.2330 - mae: 1296.2330 - mse: 16085539.0000\n",
            "Epoch 166: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1398.4048 - mae: 1398.4048 - mse: 18262740.0000 - val_loss: 1836.2466 - val_mae: 1836.2466 - val_mse: 24532040.0000\n",
            "Epoch 167/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1251.4944 - mae: 1251.4944 - mse: 17017828.0000\n",
            "Epoch 167: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1299.3817 - mae: 1299.3817 - mse: 17854526.0000 - val_loss: 1713.0455 - val_mae: 1713.0455 - val_mse: 23447512.0000\n",
            "Epoch 168/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1270.3872 - mae: 1270.3872 - mse: 16890108.0000\n",
            "Epoch 168: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1316.4805 - mae: 1316.4805 - mse: 18257788.0000 - val_loss: 1583.3922 - val_mae: 1583.3922 - val_mse: 23022344.0000\n",
            "Epoch 169/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1106.4375 - mae: 1106.4375 - mse: 14926789.0000\n",
            "Epoch 169: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1239.8184 - mae: 1239.8184 - mse: 17824640.0000 - val_loss: 1526.7505 - val_mae: 1526.7505 - val_mse: 22788780.0000\n",
            "Epoch 170/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1179.1010 - mae: 1179.1010 - mse: 16566781.0000\n",
            "Epoch 170: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1219.5166 - mae: 1219.5166 - mse: 17750702.0000 - val_loss: 1563.3334 - val_mae: 1563.3334 - val_mse: 23295948.0000\n",
            "Epoch 171/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1233.0455 - mae: 1233.0455 - mse: 16548784.0000\n",
            "Epoch 171: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1281.2722 - mae: 1281.2722 - mse: 17768714.0000 - val_loss: 1641.6589 - val_mae: 1641.6589 - val_mse: 24187046.0000\n",
            "Epoch 172/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1246.2236 - mae: 1246.2236 - mse: 16976766.0000\n",
            "Epoch 172: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1292.2628 - mae: 1292.2628 - mse: 18099506.0000 - val_loss: 1679.3226 - val_mae: 1679.3226 - val_mse: 24259226.0000\n",
            "Epoch 173/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1170.8480 - mae: 1170.8480 - mse: 16740825.0000\n",
            "Epoch 173: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1228.7252 - mae: 1228.7252 - mse: 17864804.0000 - val_loss: 1582.4625 - val_mae: 1582.4625 - val_mse: 22800002.0000\n",
            "Epoch 174/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1122.9929 - mae: 1122.9929 - mse: 15536512.0000\n",
            "Epoch 174: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1246.5500 - mae: 1246.5500 - mse: 17870506.0000 - val_loss: 1682.5676 - val_mae: 1682.5676 - val_mse: 23495472.0000\n",
            "Epoch 175/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1148.6555 - mae: 1148.6555 - mse: 15384572.0000\n",
            "Epoch 175: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1253.2728 - mae: 1253.2728 - mse: 18035534.0000 - val_loss: 1512.3241 - val_mae: 1512.3241 - val_mse: 22517952.0000\n",
            "Epoch 176/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1142.4064 - mae: 1142.4064 - mse: 15271674.0000\n",
            "Epoch 176: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1281.2803 - mae: 1281.2803 - mse: 18097776.0000 - val_loss: 1510.0902 - val_mae: 1510.0902 - val_mse: 22260786.0000\n",
            "Epoch 177/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1297.9757 - mae: 1297.9757 - mse: 16913964.0000\n",
            "Epoch 177: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1313.0499 - mae: 1313.0499 - mse: 17956648.0000 - val_loss: 1579.1176 - val_mae: 1579.1176 - val_mse: 22567984.0000\n",
            "Epoch 178/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1199.1099 - mae: 1199.1099 - mse: 17058384.0000\n",
            "Epoch 178: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1279.6637 - mae: 1279.6637 - mse: 18387424.0000 - val_loss: 1621.9098 - val_mae: 1621.9098 - val_mse: 23941530.0000\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1307.1384 - mae: 1307.1384 - mse: 18269814.0000\n",
            "Epoch 179: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1307.1384 - mae: 1307.1384 - mse: 18269814.0000 - val_loss: 1621.0098 - val_mae: 1621.0098 - val_mse: 23702516.0000\n",
            "Epoch 180/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1217.6992 - mae: 1217.6992 - mse: 16557602.0000\n",
            "Epoch 180: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1278.5444 - mae: 1278.5444 - mse: 17942480.0000 - val_loss: 1607.8195 - val_mae: 1607.8195 - val_mse: 21837108.0000\n",
            "Epoch 181/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1229.9838 - mae: 1229.9838 - mse: 17415992.0000\n",
            "Epoch 181: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1251.8887 - mae: 1251.8887 - mse: 17957142.0000 - val_loss: 1622.1632 - val_mae: 1622.1632 - val_mse: 24146786.0000\n",
            "Epoch 182/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1123.5237 - mae: 1123.5237 - mse: 16066552.0000\n",
            "Epoch 182: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1225.2740 - mae: 1225.2740 - mse: 17895794.0000 - val_loss: 1543.1887 - val_mae: 1543.1887 - val_mse: 22458360.0000\n",
            "Epoch 183/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1191.0474 - mae: 1191.0474 - mse: 16593390.0000\n",
            "Epoch 183: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1252.2837 - mae: 1252.2837 - mse: 17735290.0000 - val_loss: 1510.0298 - val_mae: 1510.0298 - val_mse: 22866668.0000\n",
            "Epoch 184/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1220.8361 - mae: 1220.8361 - mse: 16560511.0000\n",
            "Epoch 184: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1261.3690 - mae: 1261.3690 - mse: 17890150.0000 - val_loss: 1548.0200 - val_mae: 1548.0200 - val_mse: 23550632.0000\n",
            "Epoch 185/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1166.2999 - mae: 1166.2999 - mse: 16665052.0000\n",
            "Epoch 185: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1232.8282 - mae: 1232.8282 - mse: 17871816.0000 - val_loss: 1638.5385 - val_mae: 1638.5385 - val_mse: 22664530.0000\n",
            "Epoch 186/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1167.7864 - mae: 1167.7864 - mse: 16370027.0000\n",
            "Epoch 186: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1274.1531 - mae: 1274.1531 - mse: 18193248.0000 - val_loss: 1612.4027 - val_mae: 1612.4027 - val_mse: 22575956.0000\n",
            "Epoch 187/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1237.2791 - mae: 1237.2791 - mse: 17280210.0000\n",
            "Epoch 187: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1258.3492 - mae: 1258.3492 - mse: 17824436.0000 - val_loss: 1537.5818 - val_mae: 1537.5818 - val_mse: 22284110.0000\n",
            "Epoch 188/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1215.9288 - mae: 1215.9288 - mse: 17358006.0000\n",
            "Epoch 188: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1238.5099 - mae: 1238.5099 - mse: 17900204.0000 - val_loss: 1512.8829 - val_mae: 1512.8829 - val_mse: 22222336.0000\n",
            "Epoch 189/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1120.5204 - mae: 1120.5204 - mse: 15372482.0000\n",
            "Epoch 189: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1242.3071 - mae: 1242.3071 - mse: 17800938.0000 - val_loss: 1536.2366 - val_mae: 1536.2366 - val_mse: 22985788.0000\n",
            "Epoch 190/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1130.3647 - mae: 1130.3647 - mse: 15745470.0000\n",
            "Epoch 190: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1227.3510 - mae: 1227.3510 - mse: 17887478.0000 - val_loss: 1645.9452 - val_mae: 1645.9452 - val_mse: 24186982.0000\n",
            "Epoch 191/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1163.6559 - mae: 1163.6559 - mse: 16608914.0000\n",
            "Epoch 191: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1222.1592 - mae: 1222.1592 - mse: 17900292.0000 - val_loss: 1533.5808 - val_mae: 1533.5808 - val_mse: 21818916.0000\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1221.3999 - mae: 1221.3999 - mse: 17949926.0000\n",
            "Epoch 192: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1221.3999 - mae: 1221.3999 - mse: 17949926.0000 - val_loss: 1542.3966 - val_mae: 1542.3966 - val_mse: 22598518.0000\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1231.7609 - mae: 1231.7609 - mse: 17672838.0000\n",
            "Epoch 193: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1231.7609 - mae: 1231.7609 - mse: 17672838.0000 - val_loss: 1536.0698 - val_mae: 1536.0698 - val_mse: 22983118.0000\n",
            "Epoch 194/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1169.1090 - mae: 1169.1090 - mse: 16528463.0000\n",
            "Epoch 194: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1252.3848 - mae: 1252.3848 - mse: 17858612.0000 - val_loss: 1607.9819 - val_mae: 1607.9819 - val_mse: 22635008.0000\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1221.2025 - mae: 1221.2025 - mse: 17784660.0000\n",
            "Epoch 195: val_loss did not improve from 1474.99341\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1221.2025 - mae: 1221.2025 - mse: 17784660.0000 - val_loss: 1526.1396 - val_mae: 1526.1396 - val_mse: 22507820.0000\n",
            "Epoch 196/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1157.4263 - mae: 1157.4263 - mse: 16644490.0000\n",
            "Epoch 196: val_loss improved from 1474.99341 to 1473.29407, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1218.5621 - mae: 1218.5621 - mse: 17797780.0000 - val_loss: 1473.2941 - val_mae: 1473.2941 - val_mse: 22134136.0000\n",
            "Epoch 197/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1135.1285 - mae: 1135.1285 - mse: 16568664.0000\n",
            "Epoch 197: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1199.1282 - mae: 1199.1282 - mse: 17738558.0000 - val_loss: 1605.2332 - val_mae: 1605.2332 - val_mse: 23072362.0000\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1237.3711 - mae: 1237.3711 - mse: 17815282.0000\n",
            "Epoch 198: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1237.3711 - mae: 1237.3711 - mse: 17815282.0000 - val_loss: 1622.1195 - val_mae: 1622.1195 - val_mse: 22473688.0000\n",
            "Epoch 199/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1185.4575 - mae: 1185.4575 - mse: 16643027.0000\n",
            "Epoch 199: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1227.0604 - mae: 1227.0604 - mse: 17815130.0000 - val_loss: 1543.7897 - val_mae: 1543.7897 - val_mse: 22307304.0000\n",
            "Epoch 200/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1223.4253 - mae: 1223.4253 - mse: 16944304.0000\n",
            "Epoch 200: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1271.1329 - mae: 1271.1329 - mse: 17797982.0000 - val_loss: 1606.1538 - val_mae: 1606.1538 - val_mse: 22118246.0000\n",
            "Epoch 201/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1279.9597 - mae: 1279.9597 - mse: 15716322.0000\n",
            "Epoch 201: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1368.3667 - mae: 1368.3667 - mse: 17932308.0000 - val_loss: 1741.6266 - val_mae: 1741.6266 - val_mse: 23750924.0000\n",
            "Epoch 202/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1343.6324 - mae: 1343.6324 - mse: 17072380.0000\n",
            "Epoch 202: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1354.7751 - mae: 1354.7751 - mse: 17826010.0000 - val_loss: 1621.6183 - val_mae: 1621.6183 - val_mse: 23641410.0000\n",
            "Epoch 203/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1161.1216 - mae: 1161.1216 - mse: 15564538.0000\n",
            "Epoch 203: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1244.4561 - mae: 1244.4561 - mse: 17771512.0000 - val_loss: 1612.4824 - val_mae: 1612.4824 - val_mse: 24757774.0000\n",
            "Epoch 204/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1136.1503 - mae: 1136.1503 - mse: 15737664.0000\n",
            "Epoch 204: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1218.3953 - mae: 1218.3953 - mse: 17882674.0000 - val_loss: 1649.7247 - val_mae: 1649.7247 - val_mse: 24050562.0000\n",
            "Epoch 205/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1185.0509 - mae: 1185.0509 - mse: 16022381.0000\n",
            "Epoch 205: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.3715 - mae: 1280.3715 - mse: 18122010.0000 - val_loss: 1580.8474 - val_mae: 1580.8474 - val_mse: 22197588.0000\n",
            "Epoch 206/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1109.9725 - mae: 1109.9725 - mse: 15032823.0000\n",
            "Epoch 206: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1255.2604 - mae: 1255.2604 - mse: 18047496.0000 - val_loss: 1624.6337 - val_mae: 1624.6337 - val_mse: 24271870.0000\n",
            "Epoch 207/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1150.3629 - mae: 1150.3629 - mse: 15731394.0000\n",
            "Epoch 207: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1287.0399 - mae: 1287.0399 - mse: 17983780.0000 - val_loss: 1719.0399 - val_mae: 1719.0399 - val_mse: 23926086.0000\n",
            "Epoch 208/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1165.2452 - mae: 1165.2452 - mse: 16636827.0000\n",
            "Epoch 208: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1223.0435 - mae: 1223.0435 - mse: 17882664.0000 - val_loss: 1668.0306 - val_mae: 1668.0306 - val_mse: 24274750.0000\n",
            "Epoch 209/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1251.3049 - mae: 1251.3049 - mse: 17151564.0000\n",
            "Epoch 209: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1331.4354 - mae: 1331.4354 - mse: 18551848.0000 - val_loss: 1757.6123 - val_mae: 1757.6123 - val_mse: 25524844.0000\n",
            "Epoch 210/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1215.1696 - mae: 1215.1696 - mse: 15801585.0000\n",
            "Epoch 210: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1287.6437 - mae: 1287.6437 - mse: 17991506.0000 - val_loss: 1626.1420 - val_mae: 1626.1420 - val_mse: 23346128.0000\n",
            "Epoch 211/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1105.3677 - mae: 1105.3677 - mse: 14967899.0000\n",
            "Epoch 211: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1274.6698 - mae: 1274.6698 - mse: 18231788.0000 - val_loss: 1555.5142 - val_mae: 1555.5142 - val_mse: 22641564.0000\n",
            "Epoch 212/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1205.8406 - mae: 1205.8406 - mse: 17355134.0000\n",
            "Epoch 212: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1251.5649 - mae: 1251.5649 - mse: 18311696.0000 - val_loss: 1621.1562 - val_mae: 1621.1562 - val_mse: 24070746.0000\n",
            "Epoch 213/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1182.0200 - mae: 1182.0200 - mse: 15854835.0000\n",
            "Epoch 213: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1285.2461 - mae: 1285.2461 - mse: 18100820.0000 - val_loss: 1611.5593 - val_mae: 1611.5593 - val_mse: 23351670.0000\n",
            "Epoch 214/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1204.6294 - mae: 1204.6294 - mse: 16952454.0000\n",
            "Epoch 214: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1252.2604 - mae: 1252.2604 - mse: 18009652.0000 - val_loss: 1593.7535 - val_mae: 1593.7535 - val_mse: 24434672.0000\n",
            "Epoch 215/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1180.0637 - mae: 1180.0637 - mse: 16623799.0000\n",
            "Epoch 215: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1251.8328 - mae: 1251.8328 - mse: 17812974.0000 - val_loss: 1780.5422 - val_mae: 1780.5422 - val_mse: 25337126.0000\n",
            "Epoch 216/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1238.1173 - mae: 1238.1173 - mse: 16162023.0000\n",
            "Epoch 216: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1332.5663 - mae: 1332.5663 - mse: 18429920.0000 - val_loss: 1551.1803 - val_mae: 1551.1803 - val_mse: 20881934.0000\n",
            "Epoch 217/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1154.5603 - mae: 1154.5603 - mse: 15060872.0000\n",
            "Epoch 217: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1306.6084 - mae: 1306.6084 - mse: 18010510.0000 - val_loss: 1536.4872 - val_mae: 1536.4872 - val_mse: 22881976.0000\n",
            "Epoch 218/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1140.1442 - mae: 1140.1442 - mse: 15738307.0000\n",
            "Epoch 218: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1256.7246 - mae: 1256.7246 - mse: 18110204.0000 - val_loss: 1620.8594 - val_mae: 1620.8594 - val_mse: 22625674.0000\n",
            "Epoch 219/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1274.9706 - mae: 1274.9706 - mse: 15692722.0000\n",
            "Epoch 219: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1342.0679 - mae: 1342.0679 - mse: 17775762.0000 - val_loss: 1641.8141 - val_mae: 1641.8141 - val_mse: 23087060.0000\n",
            "Epoch 220/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1123.5149 - mae: 1123.5149 - mse: 15442898.0000\n",
            "Epoch 220: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1241.6669 - mae: 1241.6669 - mse: 18019724.0000 - val_loss: 1629.9810 - val_mae: 1629.9810 - val_mse: 22827992.0000\n",
            "Epoch 221/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1208.5260 - mae: 1208.5260 - mse: 17017916.0000\n",
            "Epoch 221: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1252.5775 - mae: 1252.5775 - mse: 17838172.0000 - val_loss: 1536.5835 - val_mae: 1536.5835 - val_mse: 21445548.0000\n",
            "Epoch 222/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1101.1178 - mae: 1101.1178 - mse: 15081853.0000\n",
            "Epoch 222: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1257.1726 - mae: 1257.1726 - mse: 17848044.0000 - val_loss: 1519.4105 - val_mae: 1519.4105 - val_mse: 21638790.0000\n",
            "Epoch 223/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1157.6744 - mae: 1157.6744 - mse: 16397414.0000\n",
            "Epoch 223: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1233.1576 - mae: 1233.1576 - mse: 17703134.0000 - val_loss: 1592.0742 - val_mae: 1592.0742 - val_mse: 22583966.0000\n",
            "Epoch 224/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1156.1349 - mae: 1156.1349 - mse: 15107904.0000\n",
            "Epoch 224: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1305.0416 - mae: 1305.0416 - mse: 17832042.0000 - val_loss: 1702.6279 - val_mae: 1702.6279 - val_mse: 22599294.0000\n",
            "Epoch 225/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1176.1367 - mae: 1176.1367 - mse: 15595835.0000\n",
            "Epoch 225: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1277.2777 - mae: 1277.2777 - mse: 17824080.0000 - val_loss: 1668.4293 - val_mae: 1668.4293 - val_mse: 24187658.0000\n",
            "Epoch 226/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1101.8257 - mae: 1101.8257 - mse: 15032649.0000\n",
            "Epoch 226: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1259.9783 - mae: 1259.9783 - mse: 18085642.0000 - val_loss: 1750.9430 - val_mae: 1750.9430 - val_mse: 25261162.0000\n",
            "Epoch 227/500\n",
            "11/27 [===========>..................] - ETA: 0s - loss: 1319.9662 - mae: 1319.9662 - mse: 16272945.0000\n",
            "Epoch 227: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1390.5686 - mae: 1390.5686 - mse: 19076794.0000 - val_loss: 1589.8362 - val_mae: 1589.8362 - val_mse: 22795546.0000\n",
            "Epoch 228/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1210.8104 - mae: 1210.8104 - mse: 16561122.0000\n",
            "Epoch 228: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1259.2852 - mae: 1259.2852 - mse: 17841694.0000 - val_loss: 1637.9159 - val_mae: 1637.9159 - val_mse: 23050652.0000\n",
            "Epoch 229/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1110.0056 - mae: 1110.0056 - mse: 15094535.0000\n",
            "Epoch 229: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1257.6426 - mae: 1257.6426 - mse: 18085266.0000 - val_loss: 1643.6807 - val_mae: 1643.6807 - val_mse: 23442480.0000\n",
            "Epoch 230/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1201.3230 - mae: 1201.3230 - mse: 16650059.0000\n",
            "Epoch 230: val_loss did not improve from 1473.29407\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1258.2931 - mae: 1258.2931 - mse: 18065416.0000 - val_loss: 1479.9921 - val_mae: 1479.9921 - val_mse: 21391734.0000\n",
            "Epoch 231/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1163.2003 - mae: 1163.2003 - mse: 15760747.0000\n",
            "Epoch 231: val_loss improved from 1473.29407 to 1464.49683, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1277.4607 - mae: 1277.4607 - mse: 18491498.0000 - val_loss: 1464.4968 - val_mae: 1464.4968 - val_mse: 21394610.0000\n",
            "Epoch 232/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1174.0632 - mae: 1174.0632 - mse: 16465039.0000\n",
            "Epoch 232: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1245.6962 - mae: 1245.6962 - mse: 17984006.0000 - val_loss: 1546.3262 - val_mae: 1546.3262 - val_mse: 22017344.0000\n",
            "Epoch 233/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1136.9827 - mae: 1136.9827 - mse: 15532550.0000\n",
            "Epoch 233: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1247.3691 - mae: 1247.3691 - mse: 17904276.0000 - val_loss: 1571.1337 - val_mae: 1571.1337 - val_mse: 22510922.0000\n",
            "Epoch 234/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1136.8419 - mae: 1136.8419 - mse: 15563450.0000\n",
            "Epoch 234: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1256.8116 - mae: 1256.8116 - mse: 17791922.0000 - val_loss: 1692.9069 - val_mae: 1692.9069 - val_mse: 21429708.0000\n",
            "Epoch 235/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1339.5327 - mae: 1339.5327 - mse: 16556460.0000\n",
            "Epoch 235: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1351.5947 - mae: 1351.5947 - mse: 17858854.0000 - val_loss: 1634.8423 - val_mae: 1634.8423 - val_mse: 23557970.0000\n",
            "Epoch 236/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1097.5657 - mae: 1097.5657 - mse: 14976585.0000\n",
            "Epoch 236: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1262.1177 - mae: 1262.1177 - mse: 18041494.0000 - val_loss: 1476.4519 - val_mae: 1476.4519 - val_mse: 21385936.0000\n",
            "Epoch 237/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1156.6550 - mae: 1156.6550 - mse: 15572300.0000\n",
            "Epoch 237: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1253.5349 - mae: 1253.5349 - mse: 17856276.0000 - val_loss: 1513.2506 - val_mae: 1513.2506 - val_mse: 21446848.0000\n",
            "Epoch 238/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1179.2253 - mae: 1179.2253 - mse: 16677382.0000\n",
            "Epoch 238: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1237.9377 - mae: 1237.9377 - mse: 17880812.0000 - val_loss: 1664.8943 - val_mae: 1664.8943 - val_mse: 23955616.0000\n",
            "Epoch 239/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1186.6337 - mae: 1186.6337 - mse: 15658831.0000\n",
            "Epoch 239: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1274.7416 - mae: 1274.7416 - mse: 18013978.0000 - val_loss: 1539.4402 - val_mae: 1539.4402 - val_mse: 22225332.0000\n",
            "Epoch 240/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1145.5945 - mae: 1145.5945 - mse: 15469226.0000\n",
            "Epoch 240: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1242.1547 - mae: 1242.1547 - mse: 17793922.0000 - val_loss: 1500.7991 - val_mae: 1500.7991 - val_mse: 21475418.0000\n",
            "Epoch 241/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1155.2715 - mae: 1155.2715 - mse: 16322663.0000\n",
            "Epoch 241: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1267.6102 - mae: 1267.6102 - mse: 17770352.0000 - val_loss: 1745.5797 - val_mae: 1745.5797 - val_mse: 23640196.0000\n",
            "Epoch 242/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1138.3929 - mae: 1138.3929 - mse: 15804294.0000\n",
            "Epoch 242: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1223.9808 - mae: 1223.9808 - mse: 17748574.0000 - val_loss: 1725.8557 - val_mae: 1725.8557 - val_mse: 24454494.0000\n",
            "Epoch 243/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1200.6647 - mae: 1200.6647 - mse: 15807315.0000\n",
            "Epoch 243: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1312.6873 - mae: 1312.6873 - mse: 17891206.0000 - val_loss: 1781.0809 - val_mae: 1781.0809 - val_mse: 23330694.0000\n",
            "Epoch 244/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1233.3101 - mae: 1233.3101 - mse: 16443802.0000\n",
            "Epoch 244: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1266.9380 - mae: 1266.9380 - mse: 17755682.0000 - val_loss: 1570.1610 - val_mae: 1570.1610 - val_mse: 22298600.0000\n",
            "Epoch 245/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1216.0370 - mae: 1216.0370 - mse: 16455761.0000\n",
            "Epoch 245: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.4829 - mae: 1280.4829 - mse: 17881686.0000 - val_loss: 1636.3989 - val_mae: 1636.3989 - val_mse: 23640364.0000\n",
            "Epoch 246/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1120.0101 - mae: 1120.0101 - mse: 15105746.0000\n",
            "Epoch 246: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1256.3976 - mae: 1256.3976 - mse: 17861914.0000 - val_loss: 1544.6223 - val_mae: 1544.6223 - val_mse: 22711974.0000\n",
            "Epoch 247/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1098.2144 - mae: 1098.2144 - mse: 15113224.0000\n",
            "Epoch 247: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1231.3723 - mae: 1231.3723 - mse: 17863020.0000 - val_loss: 1506.9934 - val_mae: 1506.9934 - val_mse: 22581530.0000\n",
            "Epoch 248/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1089.1567 - mae: 1089.1567 - mse: 14643835.0000\n",
            "Epoch 248: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1257.8634 - mae: 1257.8634 - mse: 17701906.0000 - val_loss: 1659.9714 - val_mae: 1659.9714 - val_mse: 22834226.0000\n",
            "Epoch 249/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1115.0775 - mae: 1115.0775 - mse: 15527454.0000\n",
            "Epoch 249: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1230.0186 - mae: 1230.0186 - mse: 17726470.0000 - val_loss: 1576.9287 - val_mae: 1576.9287 - val_mse: 23400514.0000\n",
            "Epoch 250/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1146.2465 - mae: 1146.2465 - mse: 15614005.0000\n",
            "Epoch 250: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1240.7394 - mae: 1240.7394 - mse: 17806316.0000 - val_loss: 1528.5177 - val_mae: 1528.5177 - val_mse: 22527222.0000\n",
            "Epoch 251/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1195.7463 - mae: 1195.7463 - mse: 16619349.0000\n",
            "Epoch 251: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1229.2203 - mae: 1229.2203 - mse: 17792894.0000 - val_loss: 1525.6926 - val_mae: 1525.6926 - val_mse: 22635066.0000\n",
            "Epoch 252/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1141.4865 - mae: 1141.4865 - mse: 16367241.0000\n",
            "Epoch 252: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1201.0865 - mae: 1201.0865 - mse: 17709050.0000 - val_loss: 1540.4432 - val_mae: 1540.4432 - val_mse: 23268934.0000\n",
            "Epoch 253/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1127.9501 - mae: 1127.9501 - mse: 15730159.0000\n",
            "Epoch 253: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1232.0992 - mae: 1232.0992 - mse: 17764774.0000 - val_loss: 1554.2544 - val_mae: 1554.2544 - val_mse: 23415222.0000\n",
            "Epoch 254/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1135.9650 - mae: 1135.9650 - mse: 15649125.0000\n",
            "Epoch 254: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1239.6851 - mae: 1239.6851 - mse: 17818324.0000 - val_loss: 1547.0447 - val_mae: 1547.0447 - val_mse: 23035346.0000\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1229.3805 - mae: 1229.3805 - mse: 17713284.0000\n",
            "Epoch 255: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1229.3805 - mae: 1229.3805 - mse: 17713284.0000 - val_loss: 1594.5840 - val_mae: 1594.5840 - val_mse: 23385998.0000\n",
            "Epoch 256/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1115.6422 - mae: 1115.6422 - mse: 15058876.0000\n",
            "Epoch 256: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1235.4830 - mae: 1235.4830 - mse: 17836040.0000 - val_loss: 1515.0077 - val_mae: 1515.0077 - val_mse: 22221978.0000\n",
            "Epoch 257/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1136.3947 - mae: 1136.3947 - mse: 15562705.0000\n",
            "Epoch 257: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1231.0288 - mae: 1231.0288 - mse: 17761300.0000 - val_loss: 1572.8555 - val_mae: 1572.8555 - val_mse: 23855338.0000\n",
            "Epoch 258/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1154.0192 - mae: 1154.0192 - mse: 15535235.0000\n",
            "Epoch 258: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1262.9733 - mae: 1262.9733 - mse: 17796172.0000 - val_loss: 1679.8380 - val_mae: 1679.8380 - val_mse: 23552450.0000\n",
            "Epoch 259/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1131.3588 - mae: 1131.3588 - mse: 15092221.0000\n",
            "Epoch 259: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1264.7317 - mae: 1264.7317 - mse: 17857232.0000 - val_loss: 1587.2440 - val_mae: 1587.2440 - val_mse: 22511834.0000\n",
            "Epoch 260/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1104.3663 - mae: 1104.3663 - mse: 15306097.0000\n",
            "Epoch 260: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1239.8752 - mae: 1239.8752 - mse: 17820536.0000 - val_loss: 1555.0111 - val_mae: 1555.0111 - val_mse: 22795240.0000\n",
            "Epoch 261/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1129.1046 - mae: 1129.1046 - mse: 15799439.0000\n",
            "Epoch 261: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1253.3257 - mae: 1253.3257 - mse: 17792266.0000 - val_loss: 1854.3964 - val_mae: 1854.3964 - val_mse: 22826176.0000\n",
            "Epoch 262/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1219.2339 - mae: 1219.2339 - mse: 15342774.0000\n",
            "Epoch 262: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1332.5237 - mae: 1332.5237 - mse: 17846362.0000 - val_loss: 1749.0247 - val_mae: 1749.0247 - val_mse: 24207884.0000\n",
            "Epoch 263/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1238.7096 - mae: 1238.7096 - mse: 16477209.0000\n",
            "Epoch 263: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1316.9875 - mae: 1316.9875 - mse: 18358398.0000 - val_loss: 1683.5558 - val_mae: 1683.5558 - val_mse: 22787376.0000\n",
            "Epoch 264/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1170.6218 - mae: 1170.6218 - mse: 15720121.0000\n",
            "Epoch 264: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1284.0468 - mae: 1284.0468 - mse: 18081458.0000 - val_loss: 1653.6698 - val_mae: 1653.6698 - val_mse: 23520450.0000\n",
            "Epoch 265/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1196.9602 - mae: 1196.9602 - mse: 15016171.0000\n",
            "Epoch 265: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1330.5669 - mae: 1330.5669 - mse: 18227668.0000 - val_loss: 1596.9261 - val_mae: 1596.9261 - val_mse: 23539286.0000\n",
            "Epoch 266/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1180.4567 - mae: 1180.4567 - mse: 16306632.0000\n",
            "Epoch 266: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1292.5266 - mae: 1292.5266 - mse: 18497458.0000 - val_loss: 1734.0928 - val_mae: 1734.0928 - val_mse: 24041378.0000\n",
            "Epoch 267/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1153.9364 - mae: 1153.9364 - mse: 15289132.0000\n",
            "Epoch 267: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1265.8004 - mae: 1265.8004 - mse: 17982130.0000 - val_loss: 1595.3021 - val_mae: 1595.3021 - val_mse: 23395142.0000\n",
            "Epoch 268/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1166.9315 - mae: 1166.9315 - mse: 15718214.0000\n",
            "Epoch 268: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1277.6334 - mae: 1277.6334 - mse: 17918424.0000 - val_loss: 1589.2249 - val_mae: 1589.2249 - val_mse: 23033476.0000\n",
            "Epoch 269/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1249.4172 - mae: 1249.4172 - mse: 17081302.0000\n",
            "Epoch 269: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1283.2346 - mae: 1283.2346 - mse: 17896058.0000 - val_loss: 1550.3595 - val_mae: 1550.3595 - val_mse: 21960806.0000\n",
            "Epoch 270/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1240.0304 - mae: 1240.0304 - mse: 16799544.0000\n",
            "Epoch 270: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1301.2120 - mae: 1301.2120 - mse: 17940402.0000 - val_loss: 1736.4083 - val_mae: 1736.4083 - val_mse: 23252822.0000\n",
            "Epoch 271/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1179.3994 - mae: 1179.3994 - mse: 15066484.0000\n",
            "Epoch 271: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1302.9075 - mae: 1302.9075 - mse: 17992604.0000 - val_loss: 1553.0295 - val_mae: 1553.0295 - val_mse: 22934272.0000\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1249.6406 - mae: 1249.6406 - mse: 17951852.0000\n",
            "Epoch 272: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1249.6406 - mae: 1249.6406 - mse: 17951852.0000 - val_loss: 1673.2800 - val_mae: 1673.2800 - val_mse: 24668116.0000\n",
            "Epoch 273/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1173.4285 - mae: 1173.4285 - mse: 16763516.0000\n",
            "Epoch 273: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1238.5493 - mae: 1238.5493 - mse: 17885920.0000 - val_loss: 1560.5654 - val_mae: 1560.5654 - val_mse: 22921866.0000\n",
            "Epoch 274/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1154.8491 - mae: 1154.8491 - mse: 16626570.0000\n",
            "Epoch 274: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1198.5266 - mae: 1198.5266 - mse: 17800312.0000 - val_loss: 1508.2964 - val_mae: 1508.2964 - val_mse: 22493112.0000\n",
            "Epoch 275/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1199.8695 - mae: 1199.8695 - mse: 16588788.0000\n",
            "Epoch 275: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1266.6705 - mae: 1266.6705 - mse: 17805346.0000 - val_loss: 1660.0769 - val_mae: 1660.0769 - val_mse: 22363686.0000\n",
            "Epoch 276/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1227.2346 - mae: 1227.2346 - mse: 16456628.0000\n",
            "Epoch 276: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1353.3103 - mae: 1353.3103 - mse: 17721138.0000 - val_loss: 1891.1525 - val_mae: 1891.1525 - val_mse: 24057858.0000\n",
            "Epoch 277/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1273.1492 - mae: 1273.1492 - mse: 16618965.0000\n",
            "Epoch 277: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1294.5046 - mae: 1294.5046 - mse: 17893188.0000 - val_loss: 1598.7678 - val_mae: 1598.7678 - val_mse: 23399828.0000\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1256.7330 - mae: 1256.7330 - mse: 17955936.0000\n",
            "Epoch 278: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1256.7330 - mae: 1256.7330 - mse: 17955936.0000 - val_loss: 1618.1406 - val_mae: 1618.1406 - val_mse: 24467336.0000\n",
            "Epoch 279/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1116.0437 - mae: 1116.0437 - mse: 15637025.0000\n",
            "Epoch 279: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1243.4686 - mae: 1243.4686 - mse: 18001616.0000 - val_loss: 1654.9629 - val_mae: 1654.9629 - val_mse: 24916342.0000\n",
            "Epoch 280/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1141.5889 - mae: 1141.5889 - mse: 15716475.0000\n",
            "Epoch 280: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1267.0422 - mae: 1267.0422 - mse: 17795704.0000 - val_loss: 1563.2993 - val_mae: 1563.2993 - val_mse: 23098124.0000\n",
            "Epoch 281/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1262.8495 - mae: 1262.8495 - mse: 15649876.0000\n",
            "Epoch 281: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1347.1454 - mae: 1347.1454 - mse: 17800002.0000 - val_loss: 1671.4622 - val_mae: 1671.4622 - val_mse: 23408716.0000\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1250.0247 - mae: 1250.0247 - mse: 17876380.0000\n",
            "Epoch 282: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1250.0247 - mae: 1250.0247 - mse: 17876380.0000 - val_loss: 1612.9791 - val_mae: 1612.9791 - val_mse: 23480100.0000\n",
            "Epoch 283/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1119.9365 - mae: 1119.9365 - mse: 15796919.0000\n",
            "Epoch 283: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1214.5845 - mae: 1214.5845 - mse: 17838208.0000 - val_loss: 1630.7113 - val_mae: 1630.7113 - val_mse: 23394682.0000\n",
            "Epoch 284/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1165.4296 - mae: 1165.4296 - mse: 16562496.0000\n",
            "Epoch 284: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1235.0568 - mae: 1235.0568 - mse: 17858142.0000 - val_loss: 1656.0812 - val_mae: 1656.0812 - val_mse: 24339582.0000\n",
            "Epoch 285/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1162.4071 - mae: 1162.4071 - mse: 16448027.0000\n",
            "Epoch 285: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1220.1439 - mae: 1220.1439 - mse: 17781606.0000 - val_loss: 1487.0992 - val_mae: 1487.0992 - val_mse: 21773690.0000\n",
            "Epoch 286/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1163.4222 - mae: 1163.4222 - mse: 16511729.0000\n",
            "Epoch 286: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1300.8734 - mae: 1300.8734 - mse: 18138358.0000 - val_loss: 1669.0769 - val_mae: 1669.0769 - val_mse: 24075230.0000\n",
            "Epoch 287/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1213.0217 - mae: 1213.0217 - mse: 16511631.0000\n",
            "Epoch 287: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1257.2948 - mae: 1257.2948 - mse: 17881794.0000 - val_loss: 1574.9062 - val_mae: 1574.9062 - val_mse: 22533404.0000\n",
            "Epoch 288/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1222.3726 - mae: 1222.3726 - mse: 17402100.0000\n",
            "Epoch 288: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1249.1222 - mae: 1249.1222 - mse: 17943336.0000 - val_loss: 1673.2441 - val_mae: 1673.2441 - val_mse: 23680590.0000\n",
            "Epoch 289/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1184.5808 - mae: 1184.5808 - mse: 16332031.0000\n",
            "Epoch 289: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1280.5945 - mae: 1280.5945 - mse: 18112034.0000 - val_loss: 1488.1584 - val_mae: 1488.1584 - val_mse: 21628564.0000\n",
            "Epoch 290/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1198.1794 - mae: 1198.1794 - mse: 16966418.0000\n",
            "Epoch 290: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1270.0103 - mae: 1270.0103 - mse: 18382678.0000 - val_loss: 1640.7942 - val_mae: 1640.7942 - val_mse: 23733332.0000\n",
            "Epoch 291/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1236.4937 - mae: 1236.4937 - mse: 17251546.0000\n",
            "Epoch 291: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1295.6829 - mae: 1295.6829 - mse: 18376654.0000 - val_loss: 1600.7582 - val_mae: 1600.7582 - val_mse: 23371966.0000\n",
            "Epoch 292/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1143.9291 - mae: 1143.9291 - mse: 15760307.0000\n",
            "Epoch 292: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1239.6307 - mae: 1239.6307 - mse: 17928198.0000 - val_loss: 1515.5358 - val_mae: 1515.5358 - val_mse: 22258522.0000\n",
            "Epoch 293/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1195.6298 - mae: 1195.6298 - mse: 16641787.0000\n",
            "Epoch 293: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1235.7167 - mae: 1235.7167 - mse: 17877092.0000 - val_loss: 1553.4343 - val_mae: 1553.4343 - val_mse: 22917374.0000\n",
            "Epoch 294/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1211.9243 - mae: 1211.9243 - mse: 16731907.0000\n",
            "Epoch 294: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1276.2820 - mae: 1276.2820 - mse: 17862850.0000 - val_loss: 1640.9659 - val_mae: 1640.9659 - val_mse: 21800678.0000\n",
            "Epoch 295/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1335.9081 - mae: 1335.9081 - mse: 16880524.0000\n",
            "Epoch 295: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1388.5243 - mae: 1388.5243 - mse: 18030748.0000 - val_loss: 1616.4365 - val_mae: 1616.4365 - val_mse: 22744078.0000\n",
            "Epoch 296/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1169.4784 - mae: 1169.4784 - mse: 16038616.0000\n",
            "Epoch 296: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1268.0076 - mae: 1268.0076 - mse: 17859488.0000 - val_loss: 1651.9352 - val_mae: 1651.9352 - val_mse: 25106642.0000\n",
            "Epoch 297/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1164.5487 - mae: 1164.5487 - mse: 16770713.0000\n",
            "Epoch 297: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1219.7949 - mae: 1219.7949 - mse: 17830774.0000 - val_loss: 1668.4678 - val_mae: 1668.4678 - val_mse: 25255194.0000\n",
            "Epoch 298/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1159.4562 - mae: 1159.4562 - mse: 15873334.0000\n",
            "Epoch 298: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1271.3409 - mae: 1271.3409 - mse: 17987802.0000 - val_loss: 1677.1927 - val_mae: 1677.1927 - val_mse: 24694890.0000\n",
            "Epoch 299/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1137.2509 - mae: 1137.2509 - mse: 15541554.0000\n",
            "Epoch 299: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1290.2343 - mae: 1290.2343 - mse: 18346324.0000 - val_loss: 1759.7371 - val_mae: 1759.7371 - val_mse: 21271048.0000\n",
            "Epoch 300/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1200.1240 - mae: 1200.1240 - mse: 15723207.0000\n",
            "Epoch 300: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1298.1615 - mae: 1298.1615 - mse: 18092756.0000 - val_loss: 1657.0646 - val_mae: 1657.0646 - val_mse: 23626512.0000\n",
            "Epoch 301/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1164.4862 - mae: 1164.4862 - mse: 15878590.0000\n",
            "Epoch 301: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.8617 - mae: 1280.8617 - mse: 18094802.0000 - val_loss: 1691.4125 - val_mae: 1691.4125 - val_mse: 25079218.0000\n",
            "Epoch 302/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1364.8362 - mae: 1364.8362 - mse: 16867394.0000\n",
            "Epoch 302: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1349.2592 - mae: 1349.2592 - mse: 17962480.0000 - val_loss: 1649.3518 - val_mae: 1649.3518 - val_mse: 25139482.0000\n",
            "Epoch 303/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1241.2880 - mae: 1241.2880 - mse: 17317014.0000\n",
            "Epoch 303: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1266.5094 - mae: 1266.5094 - mse: 17862056.0000 - val_loss: 1756.8071 - val_mae: 1756.8071 - val_mse: 23485046.0000\n",
            "Epoch 304/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1156.4309 - mae: 1156.4309 - mse: 15695998.0000\n",
            "Epoch 304: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1264.6034 - mae: 1264.6034 - mse: 17934254.0000 - val_loss: 1602.6351 - val_mae: 1602.6351 - val_mse: 22923652.0000\n",
            "Epoch 305/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1145.0906 - mae: 1145.0906 - mse: 15689494.0000\n",
            "Epoch 305: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.4956 - mae: 1252.4956 - mse: 17770762.0000 - val_loss: 1572.3187 - val_mae: 1572.3187 - val_mse: 23297580.0000\n",
            "Epoch 306/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1264.1184 - mae: 1264.1184 - mse: 16620225.0000\n",
            "Epoch 306: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1286.7568 - mae: 1286.7568 - mse: 17831614.0000 - val_loss: 1587.0461 - val_mae: 1587.0461 - val_mse: 24260872.0000\n",
            "Epoch 307/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1153.4474 - mae: 1153.4474 - mse: 15769995.0000\n",
            "Epoch 307: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1235.4874 - mae: 1235.4874 - mse: 17832848.0000 - val_loss: 1663.2367 - val_mae: 1663.2367 - val_mse: 24365004.0000\n",
            "Epoch 308/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1151.2510 - mae: 1151.2510 - mse: 15861206.0000\n",
            "Epoch 308: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1251.2767 - mae: 1251.2767 - mse: 17952590.0000 - val_loss: 1540.4065 - val_mae: 1540.4065 - val_mse: 22310336.0000\n",
            "Epoch 309/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1139.2948 - mae: 1139.2948 - mse: 15610231.0000\n",
            "Epoch 309: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1266.4821 - mae: 1266.4821 - mse: 18071188.0000 - val_loss: 1626.8387 - val_mae: 1626.8387 - val_mse: 23123552.0000\n",
            "Epoch 310/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1178.3114 - mae: 1178.3114 - mse: 15579815.0000\n",
            "Epoch 310: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1287.5610 - mae: 1287.5610 - mse: 18049686.0000 - val_loss: 1562.7058 - val_mae: 1562.7058 - val_mse: 23386962.0000\n",
            "Epoch 311/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1099.4771 - mae: 1099.4771 - mse: 15011410.0000\n",
            "Epoch 311: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1247.8551 - mae: 1247.8551 - mse: 17853528.0000 - val_loss: 1628.7107 - val_mae: 1628.7107 - val_mse: 22562496.0000\n",
            "Epoch 312/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1121.0144 - mae: 1121.0144 - mse: 15756030.0000\n",
            "Epoch 312: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.3160 - mae: 1252.3160 - mse: 18236462.0000 - val_loss: 1556.7024 - val_mae: 1556.7024 - val_mse: 21840820.0000\n",
            "Epoch 313/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1167.6730 - mae: 1167.6730 - mse: 16518655.0000\n",
            "Epoch 313: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1234.0114 - mae: 1234.0114 - mse: 17892736.0000 - val_loss: 1595.6536 - val_mae: 1595.6536 - val_mse: 22545396.0000\n",
            "Epoch 314/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1160.5231 - mae: 1160.5231 - mse: 15816883.0000\n",
            "Epoch 314: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1228.0616 - mae: 1228.0616 - mse: 17778464.0000 - val_loss: 1538.9426 - val_mae: 1538.9426 - val_mse: 22768666.0000\n",
            "Epoch 315/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1145.5692 - mae: 1145.5692 - mse: 15611386.0000\n",
            "Epoch 315: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1224.2654 - mae: 1224.2654 - mse: 17783164.0000 - val_loss: 1594.2007 - val_mae: 1594.2007 - val_mse: 23583086.0000\n",
            "Epoch 316/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1116.8510 - mae: 1116.8510 - mse: 15676685.0000\n",
            "Epoch 316: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1211.5365 - mae: 1211.5365 - mse: 17799988.0000 - val_loss: 1493.7166 - val_mae: 1493.7166 - val_mse: 21441374.0000\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1261.3038 - mae: 1261.3038 - mse: 18046388.0000\n",
            "Epoch 317: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1261.3038 - mae: 1261.3038 - mse: 18046388.0000 - val_loss: 1497.4935 - val_mae: 1497.4935 - val_mse: 22018008.0000\n",
            "Epoch 318/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1214.1823 - mae: 1214.1823 - mse: 15137930.0000\n",
            "Epoch 318: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1312.7253 - mae: 1312.7253 - mse: 17819454.0000 - val_loss: 1508.3336 - val_mae: 1508.3336 - val_mse: 22299074.0000\n",
            "Epoch 319/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1140.6761 - mae: 1140.6761 - mse: 15833802.0000\n",
            "Epoch 319: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1229.3589 - mae: 1229.3589 - mse: 17796794.0000 - val_loss: 1507.8304 - val_mae: 1507.8304 - val_mse: 22382432.0000\n",
            "Epoch 320/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1108.9446 - mae: 1108.9446 - mse: 15793358.0000\n",
            "Epoch 320: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1202.7428 - mae: 1202.7428 - mse: 17758456.0000 - val_loss: 1549.2928 - val_mae: 1549.2928 - val_mse: 22590420.0000\n",
            "Epoch 321/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1198.6753 - mae: 1198.6753 - mse: 17003582.0000\n",
            "Epoch 321: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1262.7103 - mae: 1262.7103 - mse: 18079888.0000 - val_loss: 1856.1256 - val_mae: 1856.1256 - val_mse: 23912702.0000\n",
            "Epoch 322/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1355.8101 - mae: 1355.8101 - mse: 16890798.0000\n",
            "Epoch 322: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1419.1438 - mae: 1419.1438 - mse: 18932240.0000 - val_loss: 1722.3756 - val_mae: 1722.3756 - val_mse: 23973380.0000\n",
            "Epoch 323/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1267.1370 - mae: 1267.1370 - mse: 16881654.0000\n",
            "Epoch 323: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1307.6759 - mae: 1307.6759 - mse: 18081534.0000 - val_loss: 1728.3135 - val_mae: 1728.3135 - val_mse: 24290550.0000\n",
            "Epoch 324/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1194.9918 - mae: 1194.9918 - mse: 16257368.0000\n",
            "Epoch 324: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1256.2190 - mae: 1256.2190 - mse: 18052982.0000 - val_loss: 1613.5728 - val_mae: 1613.5726 - val_mse: 23322664.0000\n",
            "Epoch 325/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1184.9504 - mae: 1184.9504 - mse: 16528271.0000\n",
            "Epoch 325: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1230.2175 - mae: 1230.2175 - mse: 17801568.0000 - val_loss: 1595.6956 - val_mae: 1595.6956 - val_mse: 22574944.0000\n",
            "Epoch 326/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1168.2520 - mae: 1168.2520 - mse: 15773233.0000\n",
            "Epoch 326: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1266.1080 - mae: 1266.1080 - mse: 17948824.0000 - val_loss: 1526.9808 - val_mae: 1526.9808 - val_mse: 20906768.0000\n",
            "Epoch 327/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1203.3959 - mae: 1203.3959 - mse: 16292770.0000\n",
            "Epoch 327: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1282.6155 - mae: 1282.6155 - mse: 18127874.0000 - val_loss: 1688.7158 - val_mae: 1688.7158 - val_mse: 23406242.0000\n",
            "Epoch 328/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1118.8064 - mae: 1118.8064 - mse: 15093743.0000\n",
            "Epoch 328: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1240.8469 - mae: 1240.8469 - mse: 17806662.0000 - val_loss: 1561.8145 - val_mae: 1561.8145 - val_mse: 23197144.0000\n",
            "Epoch 329/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1128.5831 - mae: 1128.5831 - mse: 15362783.0000\n",
            "Epoch 329: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1255.0537 - mae: 1255.0537 - mse: 17881050.0000 - val_loss: 1523.9601 - val_mae: 1523.9601 - val_mse: 21927156.0000\n",
            "Epoch 330/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1240.4960 - mae: 1240.4960 - mse: 17256830.0000\n",
            "Epoch 330: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1266.4470 - mae: 1266.4470 - mse: 17793466.0000 - val_loss: 1818.4213 - val_mae: 1818.4213 - val_mse: 23465522.0000\n",
            "Epoch 331/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1246.5042 - mae: 1246.5042 - mse: 15587679.0000\n",
            "Epoch 331: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1338.6650 - mae: 1338.6650 - mse: 18138620.0000 - val_loss: 1657.8423 - val_mae: 1657.8423 - val_mse: 23339570.0000\n",
            "Epoch 332/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1161.8707 - mae: 1161.8707 - mse: 15800943.0000\n",
            "Epoch 332: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.3217 - mae: 1252.3217 - mse: 17757210.0000 - val_loss: 1807.1327 - val_mae: 1807.1327 - val_mse: 25815926.0000\n",
            "Epoch 333/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1259.9181 - mae: 1259.9181 - mse: 16637975.0000\n",
            "Epoch 333: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1335.9786 - mae: 1335.9786 - mse: 18739418.0000 - val_loss: 1683.4568 - val_mae: 1683.4568 - val_mse: 23306574.0000\n",
            "Epoch 334/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1231.6761 - mae: 1231.6761 - mse: 17008330.0000\n",
            "Epoch 334: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1282.6146 - mae: 1282.6146 - mse: 18220066.0000 - val_loss: 1565.0347 - val_mae: 1565.0347 - val_mse: 22084192.0000\n",
            "Epoch 335/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1247.8683 - mae: 1247.8683 - mse: 15825289.0000\n",
            "Epoch 335: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1370.5935 - mae: 1370.5935 - mse: 18085550.0000 - val_loss: 1705.6519 - val_mae: 1705.6519 - val_mse: 21896860.0000\n",
            "Epoch 336/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1190.1906 - mae: 1190.1906 - mse: 15273833.0000\n",
            "Epoch 336: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1277.7930 - mae: 1277.7930 - mse: 17978200.0000 - val_loss: 1524.7001 - val_mae: 1524.7001 - val_mse: 23303740.0000\n",
            "Epoch 337/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1082.7212 - mae: 1082.7212 - mse: 15308177.0000\n",
            "Epoch 337: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1224.8273 - mae: 1224.8273 - mse: 17800482.0000 - val_loss: 1591.7731 - val_mae: 1591.7731 - val_mse: 23234318.0000\n",
            "Epoch 338/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1195.8055 - mae: 1195.8055 - mse: 17053404.0000\n",
            "Epoch 338: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.7483 - mae: 1252.7483 - mse: 18179854.0000 - val_loss: 1682.8295 - val_mae: 1682.8295 - val_mse: 23736014.0000\n",
            "Epoch 339/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1220.0170 - mae: 1220.0170 - mse: 16739973.0000\n",
            "Epoch 339: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1291.3091 - mae: 1291.3091 - mse: 18086444.0000 - val_loss: 1554.0046 - val_mae: 1554.0046 - val_mse: 22111320.0000\n",
            "Epoch 340/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1177.1508 - mae: 1177.1508 - mse: 15318535.0000\n",
            "Epoch 340: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1284.0238 - mae: 1284.0238 - mse: 17897638.0000 - val_loss: 1599.3986 - val_mae: 1599.3986 - val_mse: 23134428.0000\n",
            "Epoch 341/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1164.7126 - mae: 1164.7126 - mse: 16345397.0000\n",
            "Epoch 341: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1257.4474 - mae: 1257.4474 - mse: 18126318.0000 - val_loss: 1536.2072 - val_mae: 1536.2072 - val_mse: 22680672.0000\n",
            "Epoch 342/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1146.6660 - mae: 1146.6660 - mse: 15866594.0000\n",
            "Epoch 342: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1240.8979 - mae: 1240.8979 - mse: 18078594.0000 - val_loss: 1578.4635 - val_mae: 1578.4635 - val_mse: 22480180.0000\n",
            "Epoch 343/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1213.4523 - mae: 1213.4523 - mse: 17345626.0000\n",
            "Epoch 343: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1235.5587 - mae: 1235.5587 - mse: 17888588.0000 - val_loss: 1569.7969 - val_mae: 1569.7969 - val_mse: 22814550.0000\n",
            "Epoch 344/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1196.4117 - mae: 1196.4117 - mse: 16566873.0000\n",
            "Epoch 344: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1255.3805 - mae: 1255.3805 - mse: 17886908.0000 - val_loss: 1646.1250 - val_mae: 1646.1250 - val_mse: 24496484.0000\n",
            "Epoch 345/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1210.2504 - mae: 1210.2504 - mse: 16880916.0000\n",
            "Epoch 345: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1258.8286 - mae: 1258.8286 - mse: 18039814.0000 - val_loss: 1808.8236 - val_mae: 1808.8236 - val_mse: 25068558.0000\n",
            "Epoch 346/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1186.6627 - mae: 1186.6627 - mse: 15962253.0000\n",
            "Epoch 346: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1280.7330 - mae: 1280.7330 - mse: 18207412.0000 - val_loss: 1678.8986 - val_mae: 1678.8986 - val_mse: 23187476.0000\n",
            "Epoch 347/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1296.4648 - mae: 1296.4648 - mse: 16789624.0000\n",
            "Epoch 347: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1353.8726 - mae: 1353.8726 - mse: 18821994.0000 - val_loss: 1556.7476 - val_mae: 1556.7476 - val_mse: 21851186.0000\n",
            "Epoch 348/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1131.9041 - mae: 1131.9041 - mse: 15058152.0000\n",
            "Epoch 348: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1267.1683 - mae: 1267.1683 - mse: 17922546.0000 - val_loss: 1663.5240 - val_mae: 1663.5240 - val_mse: 22877102.0000\n",
            "Epoch 349/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1195.8774 - mae: 1195.8774 - mse: 16602570.0000\n",
            "Epoch 349: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1253.2351 - mae: 1253.2351 - mse: 17824742.0000 - val_loss: 1632.2189 - val_mae: 1632.2189 - val_mse: 21861310.0000\n",
            "Epoch 350/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1207.0443 - mae: 1207.0443 - mse: 16581304.0000\n",
            "Epoch 350: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1233.3940 - mae: 1233.3940 - mse: 17780674.0000 - val_loss: 1592.1863 - val_mae: 1592.1865 - val_mse: 22327136.0000\n",
            "Epoch 351/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1162.5000 - mae: 1162.5000 - mse: 15371481.0000\n",
            "Epoch 351: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1284.1399 - mae: 1284.1399 - mse: 18015556.0000 - val_loss: 1739.4650 - val_mae: 1739.4650 - val_mse: 21181880.0000\n",
            "Epoch 352/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1194.6351 - mae: 1194.6351 - mse: 14848524.0000\n",
            "Epoch 352: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1346.9043 - mae: 1346.9043 - mse: 17916264.0000 - val_loss: 1650.7395 - val_mae: 1650.7395 - val_mse: 22344160.0000\n",
            "Epoch 353/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1294.3992 - mae: 1294.3992 - mse: 16821708.0000\n",
            "Epoch 353: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1329.2670 - mae: 1329.2670 - mse: 18073224.0000 - val_loss: 1595.8267 - val_mae: 1595.8267 - val_mse: 22905100.0000\n",
            "Epoch 354/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1116.2141 - mae: 1116.2141 - mse: 15218740.0000\n",
            "Epoch 354: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1273.4430 - mae: 1273.4430 - mse: 18091162.0000 - val_loss: 1572.4205 - val_mae: 1572.4205 - val_mse: 20893924.0000\n",
            "Epoch 355/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1203.8599 - mae: 1203.8599 - mse: 15029804.0000\n",
            "Epoch 355: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1338.3960 - mae: 1338.3960 - mse: 18172758.0000 - val_loss: 1575.2037 - val_mae: 1575.2037 - val_mse: 23426854.0000\n",
            "Epoch 356/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1152.3229 - mae: 1152.3229 - mse: 15881594.0000\n",
            "Epoch 356: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1248.0864 - mae: 1248.0864 - mse: 18044816.0000 - val_loss: 1561.5729 - val_mae: 1561.5729 - val_mse: 22751512.0000\n",
            "Epoch 357/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1226.3817 - mae: 1226.3817 - mse: 16711636.0000\n",
            "Epoch 357: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1293.0897 - mae: 1293.0897 - mse: 17897934.0000 - val_loss: 1668.3490 - val_mae: 1668.3490 - val_mse: 23648134.0000\n",
            "Epoch 358/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1234.0555 - mae: 1234.0555 - mse: 15289537.0000\n",
            "Epoch 358: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1316.9908 - mae: 1316.9908 - mse: 17954020.0000 - val_loss: 1608.3207 - val_mae: 1608.3207 - val_mse: 23032974.0000\n",
            "Epoch 359/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1172.9889 - mae: 1172.9889 - mse: 16079195.0000\n",
            "Epoch 359: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1268.8779 - mae: 1268.8779 - mse: 18112498.0000 - val_loss: 1565.3831 - val_mae: 1565.3831 - val_mse: 22286052.0000\n",
            "Epoch 360/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1163.6764 - mae: 1163.6764 - mse: 15946218.0000\n",
            "Epoch 360: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1252.6757 - mae: 1252.6757 - mse: 18032650.0000 - val_loss: 1706.2668 - val_mae: 1706.2668 - val_mse: 23148900.0000\n",
            "Epoch 361/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1210.4241 - mae: 1210.4241 - mse: 16499002.0000\n",
            "Epoch 361: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1296.0272 - mae: 1296.0272 - mse: 17927812.0000 - val_loss: 1676.9865 - val_mae: 1676.9865 - val_mse: 23623096.0000\n",
            "Epoch 362/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1271.8232 - mae: 1271.8232 - mse: 15889785.0000\n",
            "Epoch 362: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1331.3542 - mae: 1331.3542 - mse: 17820258.0000 - val_loss: 1766.7684 - val_mae: 1766.7684 - val_mse: 24634908.0000\n",
            "Epoch 363/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1342.0599 - mae: 1342.0599 - mse: 17758414.0000\n",
            "Epoch 363: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1364.0126 - mae: 1364.0126 - mse: 18290406.0000 - val_loss: 1846.7012 - val_mae: 1846.7012 - val_mse: 25957012.0000\n",
            "Epoch 364/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1231.0061 - mae: 1231.0061 - mse: 16817714.0000\n",
            "Epoch 364: val_loss did not improve from 1464.49683\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1295.7941 - mae: 1295.7941 - mse: 18010310.0000 - val_loss: 1646.7976 - val_mae: 1646.7976 - val_mse: 21333810.0000\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1340.7765 - mae: 1340.7765 - mse: 18709584.0000\n",
            "Epoch 365: val_loss improved from 1464.49683 to 1457.75745, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1340.7765 - mae: 1340.7765 - mse: 18709584.0000 - val_loss: 1457.7574 - val_mae: 1457.7574 - val_mse: 20607280.0000\n",
            "Epoch 366/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1182.5385 - mae: 1182.5385 - mse: 16553062.0000\n",
            "Epoch 366: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1226.6324 - mae: 1226.6324 - mse: 17830836.0000 - val_loss: 1515.2887 - val_mae: 1515.2887 - val_mse: 21714102.0000\n",
            "Epoch 367/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1189.9645 - mae: 1189.9645 - mse: 16729883.0000\n",
            "Epoch 367: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1240.3580 - mae: 1240.3580 - mse: 17841236.0000 - val_loss: 1637.4484 - val_mae: 1637.4484 - val_mse: 21852282.0000\n",
            "Epoch 368/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1155.4938 - mae: 1155.4938 - mse: 15833406.0000\n",
            "Epoch 368: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1265.2502 - mae: 1265.2502 - mse: 17790260.0000 - val_loss: 1723.5282 - val_mae: 1723.5282 - val_mse: 23948736.0000\n",
            "Epoch 369/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1203.8597 - mae: 1203.8597 - mse: 16706829.0000\n",
            "Epoch 369: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1261.6692 - mae: 1261.6692 - mse: 17855356.0000 - val_loss: 1535.4521 - val_mae: 1535.4521 - val_mse: 22297648.0000\n",
            "Epoch 370/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1159.1609 - mae: 1159.1609 - mse: 16109930.0000\n",
            "Epoch 370: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1262.1091 - mae: 1262.1091 - mse: 17929312.0000 - val_loss: 1575.4432 - val_mae: 1575.4432 - val_mse: 22372162.0000\n",
            "Epoch 371/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1271.9243 - mae: 1271.9243 - mse: 16843884.0000\n",
            "Epoch 371: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1284.9017 - mae: 1284.9017 - mse: 17922430.0000 - val_loss: 1565.5907 - val_mae: 1565.5907 - val_mse: 22142340.0000\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1200.6411 - mae: 1200.6411 - mse: 17756084.0000\n",
            "Epoch 372: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1200.6411 - mae: 1200.6411 - mse: 17756084.0000 - val_loss: 1508.9078 - val_mae: 1508.9078 - val_mse: 22315580.0000\n",
            "Epoch 373/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1213.4221 - mae: 1213.4221 - mse: 17169472.0000\n",
            "Epoch 373: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1250.8553 - mae: 1250.8553 - mse: 17927264.0000 - val_loss: 1686.1869 - val_mae: 1686.1869 - val_mse: 21780396.0000\n",
            "Epoch 374/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1324.9988 - mae: 1324.9988 - mse: 17612434.0000\n",
            "Epoch 374: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1346.2755 - mae: 1346.2755 - mse: 18144084.0000 - val_loss: 1567.0126 - val_mae: 1567.0126 - val_mse: 21487566.0000\n",
            "Epoch 375/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1157.5262 - mae: 1157.5262 - mse: 16553935.0000\n",
            "Epoch 375: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1222.1746 - mae: 1222.1746 - mse: 17692118.0000 - val_loss: 1590.3975 - val_mae: 1590.3975 - val_mse: 23706750.0000\n",
            "Epoch 376/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1191.7902 - mae: 1191.7902 - mse: 16619051.0000\n",
            "Epoch 376: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1260.2411 - mae: 1260.2411 - mse: 17873812.0000 - val_loss: 1756.3832 - val_mae: 1756.3832 - val_mse: 23011940.0000\n",
            "Epoch 377/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1233.9136 - mae: 1233.9136 - mse: 16760183.0000\n",
            "Epoch 377: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1284.7997 - mae: 1284.7997 - mse: 17811546.0000 - val_loss: 1619.9495 - val_mae: 1619.9495 - val_mse: 23547790.0000\n",
            "Epoch 378/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1247.5160 - mae: 1247.5160 - mse: 16762888.0000\n",
            "Epoch 378: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1276.3219 - mae: 1276.3219 - mse: 17907276.0000 - val_loss: 1561.5966 - val_mae: 1561.5966 - val_mse: 21882784.0000\n",
            "Epoch 379/500\n",
            "20/27 [=====================>........] - ETA: 0s - loss: 1157.8840 - mae: 1157.8840 - mse: 16619842.0000\n",
            "Epoch 379: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1206.2156 - mae: 1206.2156 - mse: 17801688.0000 - val_loss: 1484.0076 - val_mae: 1484.0076 - val_mse: 21656490.0000\n",
            "Epoch 380/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1168.6553 - mae: 1168.6553 - mse: 16625161.0000\n",
            "Epoch 380: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1229.8287 - mae: 1229.8287 - mse: 17768434.0000 - val_loss: 1571.6516 - val_mae: 1571.6516 - val_mse: 22464606.0000\n",
            "Epoch 381/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1155.8544 - mae: 1155.8544 - mse: 15593869.0000\n",
            "Epoch 381: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1239.4363 - mae: 1239.4363 - mse: 17849076.0000 - val_loss: 1569.2949 - val_mae: 1569.2949 - val_mse: 21955560.0000\n",
            "Epoch 382/500\n",
            "19/27 [====================>.........] - ETA: 0s - loss: 1139.2939 - mae: 1139.2939 - mse: 15527692.0000\n",
            "Epoch 382: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1233.9807 - mae: 1233.9807 - mse: 17812592.0000 - val_loss: 1615.2834 - val_mae: 1615.2834 - val_mse: 23724046.0000\n",
            "Epoch 383/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1194.2800 - mae: 1194.2800 - mse: 17151746.0000\n",
            "Epoch 383: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1248.6738 - mae: 1248.6738 - mse: 18155348.0000 - val_loss: 1589.5070 - val_mae: 1589.5070 - val_mse: 22755084.0000\n",
            "Epoch 384/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1222.1903 - mae: 1222.1903 - mse: 16928564.0000\n",
            "Epoch 384: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1285.5895 - mae: 1285.5895 - mse: 18039916.0000 - val_loss: 1612.7305 - val_mae: 1612.7305 - val_mse: 24536222.0000\n",
            "Epoch 385/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1233.8665 - mae: 1233.8665 - mse: 17497696.0000\n",
            "Epoch 385: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1255.8335 - mae: 1255.8335 - mse: 18038862.0000 - val_loss: 1558.1252 - val_mae: 1558.1252 - val_mse: 22255082.0000\n",
            "Epoch 386/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1174.1932 - mae: 1174.1932 - mse: 16657685.0000\n",
            "Epoch 386: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1241.1508 - mae: 1241.1508 - mse: 17884480.0000 - val_loss: 1612.2084 - val_mae: 1612.2084 - val_mse: 22041360.0000\n",
            "Epoch 387/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1213.3495 - mae: 1213.3495 - mse: 17049602.0000\n",
            "Epoch 387: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1249.8193 - mae: 1249.8193 - mse: 17848598.0000 - val_loss: 1531.6904 - val_mae: 1531.6904 - val_mse: 22062310.0000\n",
            "Epoch 388/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1150.9536 - mae: 1150.9536 - mse: 16731933.0000\n",
            "Epoch 388: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1213.0066 - mae: 1213.0066 - mse: 17877020.0000 - val_loss: 1598.8710 - val_mae: 1598.8710 - val_mse: 23404128.0000\n",
            "Epoch 389/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1188.6376 - mae: 1188.6376 - mse: 16257088.0000\n",
            "Epoch 389: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1290.8021 - mae: 1290.8021 - mse: 18027682.0000 - val_loss: 1617.0820 - val_mae: 1617.0820 - val_mse: 22654176.0000\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1245.1957 - mae: 1245.1958 - mse: 17779828.0000\n",
            "Epoch 390: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1245.1957 - mae: 1245.1958 - mse: 17779828.0000 - val_loss: 1590.3356 - val_mae: 1590.3356 - val_mse: 23536442.0000\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1285.8130 - mae: 1285.8130 - mse: 17886742.0000\n",
            "Epoch 391: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1285.8130 - mae: 1285.8130 - mse: 17886742.0000 - val_loss: 1693.4778 - val_mae: 1693.4778 - val_mse: 24391788.0000\n",
            "Epoch 392/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1178.8425 - mae: 1178.8425 - mse: 15743590.0000\n",
            "Epoch 392: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1279.6387 - mae: 1279.6387 - mse: 17899930.0000 - val_loss: 1544.7190 - val_mae: 1544.7190 - val_mse: 21582198.0000\n",
            "Epoch 393/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1231.2798 - mae: 1231.2798 - mse: 16557950.0000\n",
            "Epoch 393: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1273.3500 - mae: 1273.3500 - mse: 17848620.0000 - val_loss: 1581.1958 - val_mae: 1581.1958 - val_mse: 23484660.0000\n",
            "Epoch 394/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1142.1910 - mae: 1142.1910 - mse: 15760585.0000\n",
            "Epoch 394: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1253.7181 - mae: 1253.7181 - mse: 17935984.0000 - val_loss: 1685.2937 - val_mae: 1685.2937 - val_mse: 24954686.0000\n",
            "Epoch 395/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1341.2694 - mae: 1341.2694 - mse: 18511294.0000\n",
            "Epoch 395: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1362.1329 - mae: 1362.1329 - mse: 19023566.0000 - val_loss: 1682.5857 - val_mae: 1682.5857 - val_mse: 23462342.0000\n",
            "Epoch 396/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1218.0101 - mae: 1218.0101 - mse: 16828174.0000\n",
            "Epoch 396: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1269.1089 - mae: 1269.1089 - mse: 18024154.0000 - val_loss: 1582.5657 - val_mae: 1582.5657 - val_mse: 22389146.0000\n",
            "Epoch 397/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1131.0017 - mae: 1131.0017 - mse: 15755397.0000\n",
            "Epoch 397: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1243.3588 - mae: 1243.3588 - mse: 18037362.0000 - val_loss: 1478.6688 - val_mae: 1478.6688 - val_mse: 21040068.0000\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1304.3749 - mae: 1304.3749 - mse: 18226266.0000\n",
            "Epoch 398: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1304.3749 - mae: 1304.3749 - mse: 18226266.0000 - val_loss: 1793.9961 - val_mae: 1793.9961 - val_mse: 24084068.0000\n",
            "Epoch 399/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1245.0653 - mae: 1245.0653 - mse: 17272164.0000\n",
            "Epoch 399: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1296.2963 - mae: 1296.2963 - mse: 18412892.0000 - val_loss: 1630.7059 - val_mae: 1630.7059 - val_mse: 23218314.0000\n",
            "Epoch 400/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1116.8815 - mae: 1116.8815 - mse: 15692066.0000\n",
            "Epoch 400: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1224.8759 - mae: 1224.8759 - mse: 17782494.0000 - val_loss: 1563.8370 - val_mae: 1563.8370 - val_mse: 22587994.0000\n",
            "Epoch 401/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1209.7659 - mae: 1209.7659 - mse: 16608342.0000\n",
            "Epoch 401: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1234.0476 - mae: 1234.0476 - mse: 17846636.0000 - val_loss: 1525.5244 - val_mae: 1525.5244 - val_mse: 22322342.0000\n",
            "Epoch 402/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1111.9403 - mae: 1111.9403 - mse: 15246145.0000\n",
            "Epoch 402: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1224.8020 - mae: 1224.8020 - mse: 17800846.0000 - val_loss: 1549.7925 - val_mae: 1549.7925 - val_mse: 22189418.0000\n",
            "Epoch 403/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1118.7948 - mae: 1118.7948 - mse: 15542837.0000\n",
            "Epoch 403: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1227.9753 - mae: 1227.9753 - mse: 17722072.0000 - val_loss: 1545.2096 - val_mae: 1545.2096 - val_mse: 22831936.0000\n",
            "Epoch 404/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1175.5585 - mae: 1175.5585 - mse: 17198124.0000\n",
            "Epoch 404: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1198.1560 - mae: 1198.1560 - mse: 17744434.0000 - val_loss: 1519.9409 - val_mae: 1519.9409 - val_mse: 22779954.0000\n",
            "Epoch 405/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1190.5127 - mae: 1190.5127 - mse: 16652906.0000\n",
            "Epoch 405: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1251.2242 - mae: 1251.2242 - mse: 17811904.0000 - val_loss: 1529.5183 - val_mae: 1529.5183 - val_mse: 22013684.0000\n",
            "Epoch 406/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1152.3859 - mae: 1152.3859 - mse: 16490076.0000\n",
            "Epoch 406: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1212.1565 - mae: 1212.1565 - mse: 17802852.0000 - val_loss: 1527.4781 - val_mae: 1527.4781 - val_mse: 22782878.0000\n",
            "Epoch 407/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1186.6989 - mae: 1186.6989 - mse: 16509212.0000\n",
            "Epoch 407: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1254.4098 - mae: 1254.4098 - mse: 17702960.0000 - val_loss: 1582.8798 - val_mae: 1582.8798 - val_mse: 23104124.0000\n",
            "Epoch 408/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1142.7518 - mae: 1142.7518 - mse: 15789113.0000\n",
            "Epoch 408: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1259.1130 - mae: 1259.1130 - mse: 17855044.0000 - val_loss: 1683.6193 - val_mae: 1683.6193 - val_mse: 24432684.0000\n",
            "Epoch 409/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1312.8357 - mae: 1312.8357 - mse: 17575988.0000\n",
            "Epoch 409: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1335.3357 - mae: 1335.3357 - mse: 18099386.0000 - val_loss: 1831.7644 - val_mae: 1831.7644 - val_mse: 22565806.0000\n",
            "Epoch 410/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1282.7173 - mae: 1282.7173 - mse: 17703438.0000\n",
            "Epoch 410: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1306.5612 - mae: 1306.5612 - mse: 18234712.0000 - val_loss: 1558.6533 - val_mae: 1558.6533 - val_mse: 22539432.0000\n",
            "Epoch 411/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1211.8582 - mae: 1211.8582 - mse: 16778408.0000\n",
            "Epoch 411: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1267.6913 - mae: 1267.6913 - mse: 17983512.0000 - val_loss: 1511.8137 - val_mae: 1511.8137 - val_mse: 22063042.0000\n",
            "Epoch 412/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1129.7841 - mae: 1129.7841 - mse: 15737816.0000\n",
            "Epoch 412: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1249.2939 - mae: 1249.2939 - mse: 17787668.0000 - val_loss: 1574.8455 - val_mae: 1574.8455 - val_mse: 21751756.0000\n",
            "Epoch 413/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1147.6664 - mae: 1147.6664 - mse: 16462987.0000\n",
            "Epoch 413: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1218.4058 - mae: 1218.4058 - mse: 17845710.0000 - val_loss: 1532.8773 - val_mae: 1532.8773 - val_mse: 22765856.0000\n",
            "Epoch 414/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1232.2910 - mae: 1232.2910 - mse: 17391996.0000\n",
            "Epoch 414: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1256.0706 - mae: 1256.0706 - mse: 17932652.0000 - val_loss: 1640.6250 - val_mae: 1640.6250 - val_mse: 22824958.0000\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1240.7418 - mae: 1240.7418 - mse: 17808458.0000\n",
            "Epoch 415: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1240.7418 - mae: 1240.7418 - mse: 17808458.0000 - val_loss: 1508.8613 - val_mae: 1508.8613 - val_mse: 21321866.0000\n",
            "Epoch 416/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1141.4420 - mae: 1141.4420 - mse: 16415475.0000\n",
            "Epoch 416: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1235.2815 - mae: 1235.2815 - mse: 17817734.0000 - val_loss: 1536.8854 - val_mae: 1536.8854 - val_mse: 21210586.0000\n",
            "Epoch 417/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1121.4084 - mae: 1121.4084 - mse: 15539331.0000\n",
            "Epoch 417: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1229.9493 - mae: 1229.9493 - mse: 17718472.0000 - val_loss: 1616.9171 - val_mae: 1616.9171 - val_mse: 23243218.0000\n",
            "Epoch 418/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1188.0543 - mae: 1188.0543 - mse: 16467421.0000\n",
            "Epoch 418: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1249.0143 - mae: 1249.0143 - mse: 17771726.0000 - val_loss: 1730.2186 - val_mae: 1730.2186 - val_mse: 24985524.0000\n",
            "Epoch 419/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1177.0162 - mae: 1177.0162 - mse: 15737834.0000\n",
            "Epoch 419: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1268.6589 - mae: 1268.6589 - mse: 17810000.0000 - val_loss: 1591.0491 - val_mae: 1591.0491 - val_mse: 22661512.0000\n",
            "Epoch 420/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1157.0148 - mae: 1157.0148 - mse: 15848158.0000\n",
            "Epoch 420: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1255.7172 - mae: 1255.7172 - mse: 17879392.0000 - val_loss: 1670.8080 - val_mae: 1670.8080 - val_mse: 23143340.0000\n",
            "Epoch 421/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1238.2566 - mae: 1238.2566 - mse: 15906613.0000\n",
            "Epoch 421: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1316.8140 - mae: 1316.8140 - mse: 17998150.0000 - val_loss: 1579.4340 - val_mae: 1579.4340 - val_mse: 22386406.0000\n",
            "Epoch 422/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1174.5054 - mae: 1174.5054 - mse: 16453707.0000\n",
            "Epoch 422: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1250.9213 - mae: 1250.9213 - mse: 18085372.0000 - val_loss: 1574.1870 - val_mae: 1574.1870 - val_mse: 22997884.0000\n",
            "Epoch 423/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1080.0773 - mae: 1080.0773 - mse: 14760604.0000\n",
            "Epoch 423: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1236.9955 - mae: 1236.9955 - mse: 17844086.0000 - val_loss: 1563.7113 - val_mae: 1563.7113 - val_mse: 22753690.0000\n",
            "Epoch 424/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1138.8749 - mae: 1138.8749 - mse: 15936022.0000\n",
            "Epoch 424: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1274.5248 - mae: 1274.5248 - mse: 17951614.0000 - val_loss: 1593.7100 - val_mae: 1593.7100 - val_mse: 22724928.0000\n",
            "Epoch 425/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1122.1450 - mae: 1122.1450 - mse: 15642466.0000\n",
            "Epoch 425: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1248.5408 - mae: 1248.5408 - mse: 18124800.0000 - val_loss: 1472.0048 - val_mae: 1472.0048 - val_mse: 21054928.0000\n",
            "Epoch 426/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1100.1288 - mae: 1100.1288 - mse: 15765070.0000\n",
            "Epoch 426: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1203.7378 - mae: 1203.7378 - mse: 18025902.0000 - val_loss: 1627.0828 - val_mae: 1627.0828 - val_mse: 23584918.0000\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1266.2560 - mae: 1266.2560 - mse: 17874948.0000\n",
            "Epoch 427: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1266.2560 - mae: 1266.2560 - mse: 17874948.0000 - val_loss: 1472.9247 - val_mae: 1472.9247 - val_mse: 21148468.0000\n",
            "Epoch 428/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1161.2794 - mae: 1161.2794 - mse: 15323761.0000\n",
            "Epoch 428: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1269.7341 - mae: 1269.7341 - mse: 17884280.0000 - val_loss: 1714.5431 - val_mae: 1714.5431 - val_mse: 23070926.0000\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1254.4623 - mae: 1254.4623 - mse: 17865230.0000\n",
            "Epoch 429: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1254.4623 - mae: 1254.4623 - mse: 17865230.0000 - val_loss: 1648.2292 - val_mae: 1648.2292 - val_mse: 23570250.0000\n",
            "Epoch 430/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1206.7589 - mae: 1206.7589 - mse: 16560072.0000\n",
            "Epoch 430: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1257.9901 - mae: 1257.9901 - mse: 17909926.0000 - val_loss: 1735.4117 - val_mae: 1735.4117 - val_mse: 22619448.0000\n",
            "Epoch 431/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1153.0544 - mae: 1153.0544 - mse: 16183322.0000\n",
            "Epoch 431: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1234.6255 - mae: 1234.6255 - mse: 18167640.0000 - val_loss: 1484.8733 - val_mae: 1484.8733 - val_mse: 22465284.0000\n",
            "Epoch 432/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1147.4133 - mae: 1147.4133 - mse: 15793609.0000\n",
            "Epoch 432: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1305.2123 - mae: 1305.2123 - mse: 17907970.0000 - val_loss: 1618.2719 - val_mae: 1618.2719 - val_mse: 22264882.0000\n",
            "Epoch 433/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1147.5579 - mae: 1147.5579 - mse: 15246523.0000\n",
            "Epoch 433: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1291.3171 - mae: 1291.3171 - mse: 17753652.0000 - val_loss: 1753.0533 - val_mae: 1753.0533 - val_mse: 23148152.0000\n",
            "Epoch 434/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1208.6987 - mae: 1208.6987 - mse: 16692332.0000\n",
            "Epoch 434: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1269.4611 - mae: 1269.4611 - mse: 17849804.0000 - val_loss: 1807.6913 - val_mae: 1807.6913 - val_mse: 23471588.0000\n",
            "Epoch 435/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1170.8064 - mae: 1170.8064 - mse: 15774935.0000\n",
            "Epoch 435: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1276.5590 - mae: 1276.5590 - mse: 17836320.0000 - val_loss: 1544.2024 - val_mae: 1544.2024 - val_mse: 21038388.0000\n",
            "Epoch 436/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1269.5219 - mae: 1269.5219 - mse: 16407053.0000\n",
            "Epoch 436: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1318.0529 - mae: 1318.0529 - mse: 17816600.0000 - val_loss: 1746.0312 - val_mae: 1746.0312 - val_mse: 22609380.0000\n",
            "Epoch 437/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1274.5647 - mae: 1274.5647 - mse: 17206442.0000\n",
            "Epoch 437: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1299.6638 - mae: 1299.6637 - mse: 17750234.0000 - val_loss: 1872.8634 - val_mae: 1872.8634 - val_mse: 22833948.0000\n",
            "Epoch 438/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1181.1493 - mae: 1181.1493 - mse: 15202094.0000\n",
            "Epoch 438: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1260.4829 - mae: 1260.4829 - mse: 17779348.0000 - val_loss: 1522.0734 - val_mae: 1522.0734 - val_mse: 22062548.0000\n",
            "Epoch 439/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1145.7134 - mae: 1145.7134 - mse: 16462790.0000\n",
            "Epoch 439: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1207.2743 - mae: 1207.2743 - mse: 17781208.0000 - val_loss: 1569.5358 - val_mae: 1569.5358 - val_mse: 23733920.0000\n",
            "Epoch 440/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1179.5223 - mae: 1179.5223 - mse: 16446591.0000\n",
            "Epoch 440: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1253.2938 - mae: 1253.2938 - mse: 17768038.0000 - val_loss: 1743.3112 - val_mae: 1743.3112 - val_mse: 23567398.0000\n",
            "Epoch 441/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1147.2596 - mae: 1147.2596 - mse: 15117423.0000\n",
            "Epoch 441: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1326.9246 - mae: 1326.9246 - mse: 17822248.0000 - val_loss: 1829.6244 - val_mae: 1829.6244 - val_mse: 24826878.0000\n",
            "Epoch 442/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1313.6539 - mae: 1313.6539 - mse: 17038276.0000\n",
            "Epoch 442: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1324.5327 - mae: 1324.5327 - mse: 18248154.0000 - val_loss: 1735.4423 - val_mae: 1735.4423 - val_mse: 23273766.0000\n",
            "Epoch 443/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1170.5955 - mae: 1170.5955 - mse: 16121016.0000\n",
            "Epoch 443: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1269.4406 - mae: 1269.4406 - mse: 17906744.0000 - val_loss: 1576.8247 - val_mae: 1576.8247 - val_mse: 22925312.0000\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1279.7419 - mae: 1279.7419 - mse: 17812540.0000\n",
            "Epoch 444: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1279.7419 - mae: 1279.7419 - mse: 17812540.0000 - val_loss: 1686.2738 - val_mae: 1686.2738 - val_mse: 21787470.0000\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1249.9808 - mae: 1249.9808 - mse: 17736416.0000\n",
            "Epoch 445: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1249.9808 - mae: 1249.9808 - mse: 17736416.0000 - val_loss: 1655.3152 - val_mae: 1655.3152 - val_mse: 23940740.0000\n",
            "Epoch 446/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1128.8744 - mae: 1128.8744 - mse: 15751318.0000\n",
            "Epoch 446: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1229.9613 - mae: 1229.9613 - mse: 17906208.0000 - val_loss: 1469.0372 - val_mae: 1469.0372 - val_mse: 21360736.0000\n",
            "Epoch 447/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1143.0681 - mae: 1143.0681 - mse: 15674118.0000\n",
            "Epoch 447: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1252.8425 - mae: 1252.8425 - mse: 18091256.0000 - val_loss: 1616.3127 - val_mae: 1616.3127 - val_mse: 23353388.0000\n",
            "Epoch 448/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1292.8884 - mae: 1292.8884 - mse: 16742782.0000\n",
            "Epoch 448: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1334.7708 - mae: 1334.7708 - mse: 18471992.0000 - val_loss: 1697.1295 - val_mae: 1697.1295 - val_mse: 24024834.0000\n",
            "Epoch 449/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1281.6405 - mae: 1281.6405 - mse: 17488090.0000\n",
            "Epoch 449: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1302.1094 - mae: 1302.1094 - mse: 18029018.0000 - val_loss: 1584.3866 - val_mae: 1584.3866 - val_mse: 23694400.0000\n",
            "Epoch 450/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1182.6067 - mae: 1182.6067 - mse: 16581663.0000\n",
            "Epoch 450: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1231.1846 - mae: 1231.1846 - mse: 17822764.0000 - val_loss: 1623.6189 - val_mae: 1623.6189 - val_mse: 23399714.0000\n",
            "Epoch 451/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1121.2826 - mae: 1121.2826 - mse: 16007800.0000\n",
            "Epoch 451: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1233.1997 - mae: 1233.1997 - mse: 17889908.0000 - val_loss: 1648.0312 - val_mae: 1648.0312 - val_mse: 22655536.0000\n",
            "Epoch 452/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1209.3125 - mae: 1209.3125 - mse: 16754116.0000\n",
            "Epoch 452: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1262.6366 - mae: 1262.6366 - mse: 17846012.0000 - val_loss: 1680.1036 - val_mae: 1680.1036 - val_mse: 24381448.0000\n",
            "Epoch 453/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1130.1882 - mae: 1130.1882 - mse: 15170044.0000\n",
            "Epoch 453: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1249.1875 - mae: 1249.1875 - mse: 17874300.0000 - val_loss: 1513.4854 - val_mae: 1513.4854 - val_mse: 21662942.0000\n",
            "Epoch 454/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1120.0164 - mae: 1120.0164 - mse: 15554732.0000\n",
            "Epoch 454: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1253.3075 - mae: 1253.3075 - mse: 18193814.0000 - val_loss: 1520.6497 - val_mae: 1520.6497 - val_mse: 22534586.0000\n",
            "Epoch 455/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1125.5153 - mae: 1125.5153 - mse: 15894086.0000\n",
            "Epoch 455: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1233.5580 - mae: 1233.5580 - mse: 18004564.0000 - val_loss: 1490.4293 - val_mae: 1490.4293 - val_mse: 22145388.0000\n",
            "Epoch 456/500\n",
            "13/27 [=============>................] - ETA: 0s - loss: 1069.3374 - mae: 1069.3374 - mse: 15120545.0000\n",
            "Epoch 456: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1204.0746 - mae: 1204.0746 - mse: 17668788.0000 - val_loss: 1560.5299 - val_mae: 1560.5299 - val_mse: 23534494.0000\n",
            "Epoch 457/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1254.4899 - mae: 1254.4899 - mse: 17701726.0000\n",
            "Epoch 457: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1277.8416 - mae: 1277.8416 - mse: 18236516.0000 - val_loss: 1682.4633 - val_mae: 1682.4633 - val_mse: 23437772.0000\n",
            "Epoch 458/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1143.3834 - mae: 1143.3834 - mse: 15842622.0000\n",
            "Epoch 458: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1231.5771 - mae: 1231.5771 - mse: 17879822.0000 - val_loss: 1530.7026 - val_mae: 1530.7026 - val_mse: 22022668.0000\n",
            "Epoch 459/500\n",
            "12/27 [============>.................] - ETA: 0s - loss: 1157.1569 - mae: 1157.1569 - mse: 16416771.0000\n",
            "Epoch 459: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1206.0576 - mae: 1206.0576 - mse: 17723748.0000 - val_loss: 1556.5737 - val_mae: 1556.5737 - val_mse: 23323004.0000\n",
            "Epoch 460/500\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 1196.7096 - mae: 1196.7096 - mse: 17093630.0000\n",
            "Epoch 460: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1239.4106 - mae: 1239.4106 - mse: 17909112.0000 - val_loss: 1617.7604 - val_mae: 1617.7604 - val_mse: 22498802.0000\n",
            "Epoch 461/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1138.2378 - mae: 1138.2378 - mse: 15679889.0000\n",
            "Epoch 461: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1223.5874 - mae: 1223.5874 - mse: 17755996.0000 - val_loss: 1469.9375 - val_mae: 1469.9375 - val_mse: 21343208.0000\n",
            "Epoch 462/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1095.9320 - mae: 1095.9320 - mse: 16000047.0000\n",
            "Epoch 462: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1199.5742 - mae: 1199.5742 - mse: 17807744.0000 - val_loss: 1544.1526 - val_mae: 1544.1526 - val_mse: 22317900.0000\n",
            "Epoch 463/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1109.9216 - mae: 1109.9216 - mse: 15616308.0000\n",
            "Epoch 463: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1229.0958 - mae: 1229.0958 - mse: 17957886.0000 - val_loss: 1570.4240 - val_mae: 1570.4240 - val_mse: 22258612.0000\n",
            "Epoch 464/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1230.8146 - mae: 1230.8146 - mse: 17161526.0000\n",
            "Epoch 464: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1286.1769 - mae: 1286.1769 - mse: 18236244.0000 - val_loss: 1575.4358 - val_mae: 1575.4358 - val_mse: 23703430.0000\n",
            "Epoch 465/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1196.2008 - mae: 1196.2008 - mse: 16364217.0000\n",
            "Epoch 465: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1286.8933 - mae: 1286.8933 - mse: 18134536.0000 - val_loss: 1543.0073 - val_mae: 1543.0073 - val_mse: 23335860.0000\n",
            "Epoch 466/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1155.1400 - mae: 1155.1400 - mse: 16815824.0000\n",
            "Epoch 466: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1215.7985 - mae: 1215.7985 - mse: 17959074.0000 - val_loss: 1534.1134 - val_mae: 1534.1134 - val_mse: 22613906.0000\n",
            "Epoch 467/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1234.8364 - mae: 1234.8364 - mse: 17234328.0000\n",
            "Epoch 467: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1264.7203 - mae: 1264.7203 - mse: 17777378.0000 - val_loss: 1815.4348 - val_mae: 1815.4348 - val_mse: 24444114.0000\n",
            "Epoch 468/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1220.4962 - mae: 1220.4962 - mse: 16991142.0000\n",
            "Epoch 468: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1278.4481 - mae: 1278.4481 - mse: 18127532.0000 - val_loss: 1601.0348 - val_mae: 1601.0348 - val_mse: 22519430.0000\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1243.0077 - mae: 1243.0077 - mse: 18046430.0000\n",
            "Epoch 469: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1243.0077 - mae: 1243.0077 - mse: 18046430.0000 - val_loss: 1491.6661 - val_mae: 1491.6661 - val_mse: 20785738.0000\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1287.4739 - mae: 1287.4739 - mse: 17864246.0000\n",
            "Epoch 470: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1287.4739 - mae: 1287.4739 - mse: 17864246.0000 - val_loss: 1769.4775 - val_mae: 1769.4775 - val_mse: 22580930.0000\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1349.3673 - mae: 1349.3673 - mse: 18611392.0000\n",
            "Epoch 471: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1349.3673 - mae: 1349.3673 - mse: 18611392.0000 - val_loss: 1565.4291 - val_mae: 1565.4291 - val_mse: 21510048.0000\n",
            "Epoch 472/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1169.3904 - mae: 1169.3904 - mse: 15729492.0000\n",
            "Epoch 472: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1270.6169 - mae: 1270.6169 - mse: 18039422.0000 - val_loss: 1578.1057 - val_mae: 1578.1057 - val_mse: 23282672.0000\n",
            "Epoch 473/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1190.9294 - mae: 1190.9294 - mse: 16774292.0000\n",
            "Epoch 473: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1247.9060 - mae: 1247.9060 - mse: 17974454.0000 - val_loss: 1552.7358 - val_mae: 1552.7358 - val_mse: 22539046.0000\n",
            "Epoch 474/500\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 1204.5697 - mae: 1204.5697 - mse: 16729581.0000\n",
            "Epoch 474: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1275.7196 - mae: 1275.7196 - mse: 17865914.0000 - val_loss: 1574.7466 - val_mae: 1574.7466 - val_mse: 22925182.0000\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1403.9467 - mae: 1403.9467 - mse: 17927446.0000\n",
            "Epoch 475: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1403.9467 - mae: 1403.9467 - mse: 17927446.0000 - val_loss: 1625.9351 - val_mae: 1625.9351 - val_mse: 21834912.0000\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1266.0978 - mae: 1266.0978 - mse: 17814264.0000\n",
            "Epoch 476: val_loss did not improve from 1457.75745\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1266.0978 - mae: 1266.0978 - mse: 17814264.0000 - val_loss: 1479.3453 - val_mae: 1479.3453 - val_mse: 21523686.0000\n",
            "Epoch 477/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1165.9535 - mae: 1165.9535 - mse: 16483390.0000\n",
            "Epoch 477: val_loss improved from 1457.75745 to 1452.02527, saving model to ./tmp/ckpt/fcchealthcosts.model.keras\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 1242.3942 - mae: 1242.3942 - mse: 17875928.0000 - val_loss: 1452.0253 - val_mae: 1452.0253 - val_mse: 21307962.0000\n",
            "Epoch 478/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1091.6312 - mae: 1091.6312 - mse: 15918264.0000\n",
            "Epoch 478: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1194.1429 - mae: 1194.1429 - mse: 17748322.0000 - val_loss: 1525.7871 - val_mae: 1525.7871 - val_mse: 22997926.0000\n",
            "Epoch 479/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1137.6582 - mae: 1137.6582 - mse: 16545776.0000\n",
            "Epoch 479: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1199.7384 - mae: 1199.7384 - mse: 17762850.0000 - val_loss: 1624.0219 - val_mae: 1624.0219 - val_mse: 22843170.0000\n",
            "Epoch 480/500\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 1183.3116 - mae: 1183.3116 - mse: 16820422.0000\n",
            "Epoch 480: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1247.4353 - mae: 1247.4353 - mse: 17983074.0000 - val_loss: 1463.5181 - val_mae: 1463.5181 - val_mse: 20830844.0000\n",
            "Epoch 481/500\n",
            "18/27 [===================>..........] - ETA: 0s - loss: 1055.7839 - mae: 1055.7839 - mse: 14676270.0000\n",
            "Epoch 481: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1205.7301 - mae: 1205.7301 - mse: 17768282.0000 - val_loss: 1571.3402 - val_mae: 1571.3402 - val_mse: 22649958.0000\n",
            "Epoch 482/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1141.3829 - mae: 1141.3829 - mse: 15688773.0000\n",
            "Epoch 482: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1255.2487 - mae: 1255.2487 - mse: 17929040.0000 - val_loss: 1464.7693 - val_mae: 1464.7693 - val_mse: 20984358.0000\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1252.7968 - mae: 1252.7968 - mse: 18117308.0000\n",
            "Epoch 483: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1252.7968 - mae: 1252.7968 - mse: 18117308.0000 - val_loss: 1622.0929 - val_mae: 1622.0929 - val_mse: 22744616.0000\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1234.2933 - mae: 1234.2933 - mse: 17698556.0000\n",
            "Epoch 484: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1234.2933 - mae: 1234.2933 - mse: 17698556.0000 - val_loss: 1625.2777 - val_mae: 1625.2777 - val_mse: 23468570.0000\n",
            "Epoch 485/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1193.3236 - mae: 1193.3236 - mse: 15914317.0000\n",
            "Epoch 485: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1282.0775 - mae: 1282.0775 - mse: 18001724.0000 - val_loss: 1569.4355 - val_mae: 1569.4355 - val_mse: 22878388.0000\n",
            "Epoch 486/500\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 1151.5846 - mae: 1151.5846 - mse: 16191661.0000\n",
            "Epoch 486: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1264.2286 - mae: 1264.2286 - mse: 18025860.0000 - val_loss: 1798.1964 - val_mae: 1798.1964 - val_mse: 23611942.0000\n",
            "Epoch 487/500\n",
            "14/27 [==============>...............] - ETA: 0s - loss: 1156.9496 - mae: 1156.9496 - mse: 15748031.0000\n",
            "Epoch 487: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1227.7604 - mae: 1227.7604 - mse: 17741666.0000 - val_loss: 1556.0000 - val_mae: 1556.0000 - val_mse: 23804200.0000\n",
            "Epoch 488/500\n",
            "17/27 [=================>............] - ETA: 0s - loss: 1139.4891 - mae: 1139.4891 - mse: 15344177.0000\n",
            "Epoch 488: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1239.4402 - mae: 1239.4402 - mse: 17945138.0000 - val_loss: 1646.0170 - val_mae: 1646.0170 - val_mse: 23731052.0000\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1215.7002 - mae: 1215.7002 - mse: 17843354.0000\n",
            "Epoch 489: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1215.7002 - mae: 1215.7002 - mse: 17843354.0000 - val_loss: 1629.6846 - val_mae: 1629.6846 - val_mse: 23415956.0000\n",
            "Epoch 490/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1146.3517 - mae: 1146.3517 - mse: 16422226.0000\n",
            "Epoch 490: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1240.5582 - mae: 1240.5582 - mse: 17787042.0000 - val_loss: 1708.3235 - val_mae: 1708.3235 - val_mse: 23657912.0000\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1240.0938 - mae: 1240.0938 - mse: 18046448.0000\n",
            "Epoch 491: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1240.0938 - mae: 1240.0938 - mse: 18046448.0000 - val_loss: 1493.8212 - val_mae: 1493.8212 - val_mse: 21893178.0000\n",
            "Epoch 492/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1238.2637 - mae: 1238.2637 - mse: 17269706.0000\n",
            "Epoch 492: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1260.8700 - mae: 1260.8700 - mse: 17823586.0000 - val_loss: 1538.9358 - val_mae: 1538.9358 - val_mse: 21820770.0000\n",
            "Epoch 493/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1164.3356 - mae: 1164.3356 - mse: 15560195.0000\n",
            "Epoch 493: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1242.9532 - mae: 1242.9532 - mse: 17764360.0000 - val_loss: 1581.4707 - val_mae: 1581.4707 - val_mse: 22834810.0000\n",
            "Epoch 494/500\n",
            "16/27 [================>.............] - ETA: 0s - loss: 1264.8218 - mae: 1264.8218 - mse: 15756345.0000\n",
            "Epoch 494: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1323.6132 - mae: 1323.6132 - mse: 17834056.0000 - val_loss: 1693.3058 - val_mae: 1693.3058 - val_mse: 23100932.0000\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 1281.8623 - mae: 1281.8623 - mse: 17844892.0000\n",
            "Epoch 495: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1281.8623 - mae: 1281.8623 - mse: 17844892.0000 - val_loss: 1730.4954 - val_mae: 1730.4954 - val_mse: 22535066.0000\n",
            "Epoch 496/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1259.4120 - mae: 1259.4120 - mse: 17326994.0000\n",
            "Epoch 496: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1280.3340 - mae: 1280.3340 - mse: 17873252.0000 - val_loss: 1537.2562 - val_mae: 1537.2562 - val_mse: 23236338.0000\n",
            "Epoch 497/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1216.2335 - mae: 1216.2335 - mse: 16647124.0000\n",
            "Epoch 497: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1279.0453 - mae: 1279.0453 - mse: 17845396.0000 - val_loss: 1677.0593 - val_mae: 1677.0593 - val_mse: 23339528.0000\n",
            "Epoch 498/500\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 1206.7477 - mae: 1206.7477 - mse: 16603895.0000\n",
            "Epoch 498: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1269.0233 - mae: 1269.0233 - mse: 17829240.0000 - val_loss: 1539.1725 - val_mae: 1539.1725 - val_mse: 21357884.0000\n",
            "Epoch 499/500\n",
            "15/27 [===============>..............] - ETA: 0s - loss: 1195.6464 - mae: 1195.6464 - mse: 16440725.0000\n",
            "Epoch 499: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1304.4191 - mae: 1304.4191 - mse: 17892586.0000 - val_loss: 1696.2145 - val_mae: 1696.2145 - val_mse: 23251296.0000\n",
            "Epoch 500/500\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 1267.8973 - mae: 1267.8973 - mse: 17256350.0000\n",
            "Epoch 500: val_loss did not improve from 1452.02527\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1288.8220 - mae: 1288.8220 - mse: 17805296.0000 - val_loss: 1629.3126 - val_mae: 1629.3126 - val_mse: 24054772.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "368c4814-5127-4016-cbb0-c436429e187c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2107.9756 - mae: 2107.9756 - mse: 35385468.0000 - 36ms/epoch - 4ms/step\n",
            "Testing set Mean Abs Error: 2107.98 expenses\n",
            "You passed the challenge. Great job!\n",
            "9/9 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P.S.\n",
        "# Compute some descriptive statistics of the\n",
        "# one-hot encoded test_dataset\n",
        "test_descript_stats = test_dataset.describe()\\\n",
        "                           .transpose()\\\n",
        "                           .round(3)\n",
        "test_descript_stats"
      ],
      "metadata": {
        "id": "DuPjD-P0pn5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "9a82cb80-6c43-4d7e-a0b0-47885a04b6f9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  count    mean     std   min   25%   50%     75%   max\n",
              "age               268.0  39.888  13.680  18.0  28.0  40.0  52.000  64.0\n",
              "bmi               268.0  30.379   6.232  17.4  26.0  30.1  34.125  48.1\n",
              "children          268.0   1.101   1.184   0.0   0.0   1.0   2.000   5.0\n",
              "sex_female        268.0   0.466   0.500   0.0   0.0   0.0   1.000   1.0\n",
              "sex_male          268.0   0.534   0.500   0.0   0.0   1.0   1.000   1.0\n",
              "smoker_no         268.0   0.772   0.420   0.0   1.0   1.0   1.000   1.0\n",
              "smoker_yes        268.0   0.228   0.420   0.0   0.0   0.0   0.000   1.0\n",
              "region_northeast  268.0   0.216   0.413   0.0   0.0   0.0   0.000   1.0\n",
              "region_northwest  268.0   0.272   0.446   0.0   0.0   0.0   1.000   1.0\n",
              "region_southeast  268.0   0.235   0.425   0.0   0.0   0.0   0.000   1.0\n",
              "region_southwest  268.0   0.276   0.448   0.0   0.0   0.0   1.000   1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d609650f-1ed5-43fd-9848-cffc4134c5d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>268.0</td>\n",
              "      <td>39.888</td>\n",
              "      <td>13.680</td>\n",
              "      <td>18.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>52.000</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>268.0</td>\n",
              "      <td>30.379</td>\n",
              "      <td>6.232</td>\n",
              "      <td>17.4</td>\n",
              "      <td>26.0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>34.125</td>\n",
              "      <td>48.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>268.0</td>\n",
              "      <td>1.101</td>\n",
              "      <td>1.184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_female</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.466</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_male</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker_no</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker_yes</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.228</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_northeast</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_northwest</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southeast</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southwest</th>\n",
              "      <td>268.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d609650f-1ed5-43fd-9848-cffc4134c5d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d609650f-1ed5-43fd-9848-cffc4134c5d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d609650f-1ed5-43fd-9848-cffc4134c5d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e754ceb-802c-4f14-b32e-9dfa7f441081\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e754ceb-802c-4f14-b32e-9dfa7f441081')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e754ceb-802c-4f14-b32e-9dfa7f441081 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e6f29311-5866-4fc3-a393-e9d8ae9d88d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_descript_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e6f29311-5866-4fc3-a393-e9d8ae9d88d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_descript_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}